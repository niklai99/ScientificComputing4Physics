{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Scientific Computing for Physics Students","text":"<p>This page serves as a central hub for all homework assignments (tasks) given throughout the course. Each task can be accessed from the Task Section below, or from the navigation bar at the top-left of the webpage, beneath the course title. Within each task, you will find multiple pages dedicated to different sub-tasks.</p>"},{"location":"#homework-task-overview","title":"Homework / Task Overview","text":"<p>Below are links to the tasks (micro-projects) completed throughout the course:</p> <ul> <li>Task 1: <ul> <li>Docker Installation and AlmaLinux9 setup </li> <li>AlmaLinux9 setup for Python and C/C++ development </li> <li>Testing the AlmaLinux9 container with Python and C++ code</li> </ul> </li> <li>Task 2: <ul> <li>Introduction to Task 2</li> <li>Vector Sum</li> <li>Matrix Multiplication</li> <li>Questions Regarding Task 2</li> </ul> </li> <li>Task 3:<ul> <li>Introduction to Task 3</li> <li>Docker installation and setup</li> <li>Building the project</li> <li>Code overview<ul> <li>File I/O</li> <li>Vector sum implementations</li> </ul> </li> </ul> </li> <li>Task 4:<ul> <li>Introduction to Task 4</li> <li>Docker installation and setup</li> <li>Building the project</li> <li>Code overview<ul> <li>Sampling and Data I/O</li> <li>Trapezoidal and Simpson integration methods</li> <li>Romberg integration method</li> <li>Comparison with Python</li> <li>Results and discussion</li> </ul> </li> </ul> </li> <li>Task 5:<ul> <li>Introduction to Task 5</li> <li>Docker installation and setup</li> <li>Building the project</li> <li>Task 5a: summation methods<ul> <li>Naive and GSL summation methods</li> <li>Pairwise summation method</li> <li>Kahan summation method</li> <li>Neumaier summation method</li> </ul> </li> <li>Task 5b: daxpy with random vectors</li> </ul> </li> <li>Task 6:<ul> <li>Introduction to Task 6</li> <li>Docker installation and setup</li> <li>Building the project</li> <li>Code overview<ul> <li>C2C FFT implementation</li> <li>R2C FFT implementation</li> <li>Full spectrum reconstruction using Hermitian symmetry</li> </ul> </li> </ul> </li> <li>Task 7:<ul> <li>Introduction to Task 7</li> <li>Docker installation and setup</li> <li>Building the project</li> </ul> </li> <li>Task 8:<ul> <li>Introduction to Task 8</li> <li>Docker installation and setup</li> <li>Building the project</li> <li>Code documentation</li> </ul> </li> <li>Task 9:<ul> <li>Introduction to Task 9</li> <li>Docker installation and setup</li> <li>Building the project</li> <li>Code documentation</li> </ul> </li> </ul>"},{"location":"#syllabus","title":"Syllabus","text":""},{"location":"#target-skills-and-knowledge","title":"Target Skills and Knowledge","text":"<p>Upon successful completion of this course, students will be able to:</p> <ol> <li>Effectively handle and combine scientific computing tools.</li> <li>Independently research and gather necessary information for coding projects.</li> <li>Design and develop code tailored to specific research needs.</li> <li>Critically evaluate and efficiently use the most suitable tools for given tasks, balancing ease of use and optimization.</li> <li>Demonstrate a fundamental understanding of computer science concepts, enabling autonomous further learning as needed.</li> <li>Apply programming skills specifically oriented towards scientific applications.</li> <li>Analyze and solve complex scientific problems using computational methods.</li> <li>Articulate the trade-offs between different computational approaches in scientific contexts.</li> </ol>"},{"location":"#examination-methods","title":"Examination Methods","text":"<p>An oral examination where students present and defend multiple micro-projects developed throughout the course, demonstrating their understanding and application of key concepts.</p>"},{"location":"#assessment-criteria","title":"Assessment Criteria","text":"<p>Critically analyze and evaluate coding micro-projects presented during the course, identifying potential pitfalls and proposing effective design strategies to overcome them.</p>"},{"location":"#course-unit-contents","title":"Course Unit Contents","text":"<p>Coding forms the core of scientific computing, embodying a dual nature: one deeply rooted in established practices, and another driven by constant innovation. Throughout this course, we will strive to strike a balance between these two aspects.</p>"},{"location":"#topics","title":"Topics","text":"<ol> <li> <p>Linux as a Development Environment </p> <ul> <li>Introducing CloudVeneto  </li> <li>Setting Up the Development Environment (in CloudVeneto)  </li> <li>Managing distros (apt and yum)  </li> <li>Shell scripting in Bash  </li> <li>Remote development (SSH)</li> </ul> </li> <li> <p>Overview of Hardware Architecture </p> <ul> <li>CPU, memory, and storage  </li> <li>Data representation (binary, hexadecimal)  </li> <li>Processes, threads, and multitasking  </li> <li>Floating-point representations</li> </ul> </li> <li> <p>Introduction to Programming Concepts </p> <ul> <li>Procedural vs. interpreted languages  </li> <li>Basics of compiling vs. interpreting  </li> <li>Object-Oriented Programming</li> </ul> </li> <li> <p>Data Structures </p> <ul> <li>Arrays, matrices, lists, stacks, queues, trees, heaps, hashing, graphs  </li> <li>Saving data (txt, binary, HDF5, etc.)</li> </ul> </li> <li> <p>Numerical Methods and Algorithms </p> <ul> <li>Big-O notation  </li> <li>Matrix inversion (SVD, Cholesky)  </li> <li>Root finding, interpolation, numerical integration, ODE, autodiff  </li> <li>Libraries for numerical computing</li> </ul> </li> <li> <p>Software Engineering for Scientists </p> <ul> <li>Version control (Git and GitHub)  </li> <li>Debugging and compilation flags  </li> <li>Using AI tools (ChatGPT, GitHub Copilot)  </li> <li>Data visualization (Matplotlib, Plotly, gnuplot)  </li> <li>Documentation and CI principles</li> </ul> </li> <li> <p>Fast Fourier Transforms (FFTs) </p> <ul> <li>Discrete Fourier Transform  </li> <li>FFT algorithm</li> </ul> </li> <li> <p>Introduction to Monte Carlo Techniques </p> <ul> <li>Random number generators  </li> <li>Monte Carlo integration and simulation</li> </ul> </li> <li> <p>Introduction to Machine Learning for Physicists </p> <ul> <li>ML concepts and libraries  </li> <li>Building a simple neural network</li> </ul> </li> <li> <p>Optimization Techniques         - Compiler optimizations, memory layout         - Benchmarking and profiling</p> </li> <li> <p>Parallel and High-Performance Computing         - MPI, OpenMP, and cluster environments (SLURM, HTCondor)         - HPC software (Spark, modules)</p> </li> <li> <p>GPU Programming         - GPU architecture and rationale         - Writing your first GPU kernel         - Effective use of GPU libraries</p> </li> </ol>"},{"location":"#additional-notes-about-suggested-reading","title":"Additional Notes about Suggested Reading","text":"<ul> <li>We will provide reputable resources throughout the course, ranging from foundational materials to current literature.</li> <li>You can find recommended books and references for both C/C++ and Python programming, HPC, and AI below.</li> </ul> <p>Programming with C (including parallel computing) - Effective C (2nd Edition) - CompSciForPhys - ParProgForPhys - SciCompHPC</p> <p>Programming with Python - Learn Python - Introduction to Python for Scientists</p> <p>Miscellaneous - CloudVeneto UserGuide - Julia Book: Practical Julia - Quantum computing (book) </p>"},{"location":"task1/custom_docker/","title":"Setting up the AlmaLinux9 Container for Python and C/C++ Development using a Dockerfile","text":"<p>In this section, instead of simply pulling the AlmaLinux9 image, we will create a custom Dockerfile that:</p> <ul> <li>Installs essential development tools (e.g., GCC, Make, and CMake) for compiling C++ code.</li> <li>Installs Miniconda so you can easily manage Python packages.</li> <li>Sets up a working directory (e.g., <code>/workspace</code>) and marks it as a volume. This enables you to mount a local folder to persist data even after the container is shut down.</li> </ul>"},{"location":"task1/custom_docker/#creating-the-dockerfile","title":"Creating the Dockerfile","text":"<p>Create a file named <code>Dockerfile.alma9</code> with the following content:</p> Dockerfile.alma9<pre><code># Use AlmaLinux9 as the base image\nFROM almalinux:9\n\n# Set environment variables for consistent locale settings\nENV LANG=C.UTF-8 \\\n    LC_ALL=C.UTF-8\n\n# Update system packages and install essential development tools\nRUN dnf -y update &amp;&amp; \\\n    dnf -y install bash gcc gcc-c++ make cmake curl --allowerasing &amp;&amp; \\\n    dnf clean all\n\n# Install Miniconda (ARM version for aarch64) to manage Python packages\nRUN curl -fsSL https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh -o /tmp/miniconda.sh &amp;&amp; \\\n    bash /tmp/miniconda.sh -b -p /opt/conda &amp;&amp; \\\n    rm /tmp/miniconda.sh\n\n# Add Miniconda to the PATH\nENV PATH=\"/opt/conda/bin:${PATH}\"\n\n# Create and set the working directory (e.g., /workspace)\nRUN mkdir -p /workspace\nWORKDIR /workspace\n\n# Mark /workspace as a volume so that local data can be persisted\nVOLUME [\"/workspace\"]\n\n# Define the default command to start an interactive bash shell\nCMD [\"/bin/bash\"]\n</code></pre> <p>The RUN command updates the system and installs essential packages:</p> <ul> <li><code>gcc</code> and <code>gcc-c++</code>: Provide the compilers needed to build C++ code.</li> <li><code>make</code> and <code>cmake</code>: Tools for automating builds.</li> <li><code>curl</code>: Needed to download the Miniconda installer.</li> </ul> <p>Miniconda is installed using the ARM-specific installer script Miniconda3-latest-Linux-aarch64.sh. This provides a lightweight Python environment that you can be easily extended with additional Python packages.</p> <p>Info</p> <p>If you need a specific Python version or more libraries installed by default, add them to this Dockerfile or run them inside the container using <code>conda install &lt;package_name&gt;</code>.</p> <p>Note</p> <p>The Dockerfile creates a <code>/workspace</code> directory, sets it as the current working directory, and uses a <code>VOLUME</code> instruction to indicate that this directory is intended for persistent storage. When you run the container, you can mount a local directory to <code>/workspace</code> so that any data created or modified there is preserved even after the container stops.</p>"},{"location":"task1/custom_docker/#building-and-running-the-image","title":"Building and Running the Image","text":"<ol> <li> <p>Build the Image</p> <p>Open your Terminal and run:</p> <pre><code>docker build -t alma9 -f Dockerfile.alma9 .\n</code></pre> <p>This command builds the image and tags it as <code>alma9</code>. </p> <p>DO NOT forget the dot at the end of the command!</p> <p>The single dot (.) at the end of the command sets the build context to the current directory. This means that the build expects to find the Dockerfile in the directory where the command is invoked. If the file is not there, the build fails. </p> </li> <li> <p>Run the Container</p> <p>Once the image is built, start a container interactively with:</p> <pre><code>docker run -it -v /path/to/local/workspace:/workspace --name &lt;process_name&gt; alma9\n</code></pre> <p>This command creates a container (naming it <code>&lt;process_name&gt;</code>) from your custom image and mounts your host\u2019s <code>/path/to/local/workspace</code> to the container\u2019s <code>/workspace</code> volume. Any files you create or modify inside <code>/workspace</code> will be stored on your host machine. It also works the other way around: any files in <code>/path/to/local/workspace</code> will be accessible from inside the container.</p> </li> </ol>"},{"location":"task1/custom_docker/#setting-up-the-miniconda-environment","title":"Setting up the Miniconda Environment","text":"<p>Once inside the container, you can create and manage Python environments using Miniconda.</p> <ol> <li> <p>Create a New Conda Environment</p> <p>Run the following command to create a new Conda environment named <code>python_env</code>:</p> <pre><code>conda create -n python_env python numpy pandas matplotlib scipy\n</code></pre> <p>This creates a new environment with the latest versions of Python. It also installs the popular scientific computing libraries NumPy, Pandas, Matplotlib, and SciPy.</p> </li> <li> <p>Activate the Conda Environment</p> <p>Activate the environment with:</p> <pre><code>conda activate python_env\n</code></pre> <p>The prompt should change to show the active environment.</p> </li> </ol>"},{"location":"task1/install_docker/","title":"Docker Installation and AlmaLinux9 Container Setup on macOS (Apple Silicon)","text":"<p>This guide provides step-by-step instructions to install Docker Desktop on macOS devices equipped with Apple Silicon (M1, M2, etc.) and to set up a reproducible containerized environment using AlmaLinux9.</p>"},{"location":"task1/install_docker/#1-installing-docker-on-macos-apple-silicon","title":"1. Installing Docker on macOS (Apple Silicon)","text":""},{"location":"task1/install_docker/#prerequisites","title":"Prerequisites","text":"<ul> <li>A Mac with an Apple Silicon chip (M1, M2, etc.)</li> <li>macOS (the latest version is always recommended)</li> <li>An active Internet connection</li> </ul>"},{"location":"task1/install_docker/#installation-steps","title":"Installation Steps","text":"<p>Do you have Rosetta installed?</p> <p>Before we get into the Docker installation, make sure you have Rosetta installed on your machine.</p> <p>To check whether Rosetta is installed, open a terminal and run:</p> <pre><code>lsbom -f /Library/Apple/System/Library/Receipts/com.apple.pkg.RosettaUpdateAuto.bom\n</code></pre> <p>You should see at least three files listed as output. If not, it is likely that Rosetta is not installed. Then, install Rosetta with:</p> <pre><code>softwareupdate --install-rosetta\n</code></pre> <p>Info</p> <p>Rosetta 2 is Apple's dynamic binary translator that enables applications compiled for Intel\u2019s x86_64 architecture to run on Apple Silicon (arm64) devices. While Docker Desktop is largely available as a native ARM application on these systems, some components\u2014such as certain command-line utilities or legacy container images\u2014may still be provided only in x86_64 format (e.g., amd64). Installing Rosetta 2 ensures that these non-native binaries are automatically translated and executed correctly, thereby maintaining full compatibility and ensuring a smooth installation and operational experience on your Mac.</p> <ol> <li> <p>Download Docker Desktop </p> <ul> <li>Visit the Docker Desktop setup page and download the version for Apple Silicon.</li> </ul> </li> <li> <p>Install Docker Desktop</p> <ul> <li>Open the downloaded <code>.dmg</code> file.</li> <li>Drag the <code>Docker.app</code> icon into the Applications folder.</li> <li>Launch Docker Desktop from the Applications folder.</li> <li>Follow the on-screen instructions and accept the license agreement.<ul> <li>A step-by-step installation guide is detailed in the Docker Desktop setup page for macOS.</li> </ul> </li> </ul> </li> <li> <p>Verify the Installation </p> <ul> <li> <p>With the Docker Desktop app running, open the Terminal and run:</p> <pre><code>docker --version\n</code></pre> </li> <li> <p>You should see output indicating the Docker version installed:</p> <pre><code>Client:\n    Version:           27.5.1\n    API version:       1.47\n    Go version:        go1.22.11\n    Git commit:        9f9e405\n    Built:             Wed Jan 22 13:37:19 2025\n    OS/Arch:           darwin/arm64\n    Context:           desktop-linux\n\nServer: Docker Desktop 4.38.0 (181591)\n    Engine:\n    Version:          27.5.1\n    API version:      1.47 (minimum version 1.24)\n    Go version:       go1.22.11\n    Git commit:       4c9b3b0\n    Built:            Wed Jan 22 13:41:25 2025\n    OS/Arch:          linux/arm64\n    Experimental:     false\n    containerd:\n    Version:          1.7.25\n    GitCommit:        bcc810d6b9066471b0b6fa75f557a15a1cbf31bb\n    runc:\n    Version:          1.1.12\n    GitCommit:        v1.1.12-0-g51d5e946\n    docker-init:\n    Version:          0.19.0\n    GitCommit:        de40ad0\n</code></pre> </li> </ul> </li> </ol>"},{"location":"task1/install_docker/#2-starting-with-almalinux9","title":"2. Starting with AlmaLinux9","text":"<p>AlmaLinux9 is available as a pre-built image on Docker Hub. You can quickly begin using it by pulling the image and running a container interactively.</p>"},{"location":"task1/install_docker/#step-1-pull-the-almalinux-image","title":"Step 1: Pull the AlmaLinux image","text":"<p>To pull the AlmaLinux9 image from Docker Hub, open your Terminal and execute the following command:</p> <pre><code>docker pull almalinux:9\n</code></pre> <p>The output you should get is:</p> <pre><code>9: Pulling from library/almalinux\n5286574881d2: Pull complete \nDigest: sha256:6d78b43b103e7ca90c43a790e73bdd421cec5ae0269b6051ef6836f4070b7476\nStatus: Downloaded newer image for almalinux:9\ndocker.io/library/almalinux:9\n</code></pre>"},{"location":"task1/install_docker/#step-2-run-an-interactive-container","title":"Step 2: Run an Interactive Container","text":"<p>Once the image is available locally, start a new container by running:</p> <pre><code>docker run -it almalinux:9 /bin/bash\n</code></pre> <ul> <li> <p>Flags:</p> <ul> <li><code>-i</code> (interactive): Keeps the standard input open, allowing you to interact with the container.</li> <li><code>-t</code> (tty): Allocates a pseudo-terminal, so you receive a shell prompt.</li> </ul> </li> <li> <p>Command Override: </p> <ul> <li>The command <code>/bin/bash</code> is passed to override the default command in the image, so you are dropped directly into a bash shell.</li> </ul> </li> </ul>"},{"location":"task1/install_docker/#step-3-verify-your-container-environment","title":"Step 3: Verify Your Container Environment","text":"<p>Within the container, you can verify the operating system by running:</p> <pre><code>cat /etc/os-release\n</code></pre> <p>This command displays details about the AlmaLinux distribution, confirming that you are running AlmaLinux9.</p> <p>For example:</p> <pre><code>NAME=\"AlmaLinux\"\nVERSION=\"9.5 (Teal Serval)\"\nID=\"almalinux\"\nID_LIKE=\"rhel centos fedora\"\nVERSION_ID=\"9.5\"\nPLATFORM_ID=\"platform:el9\"\nPRETTY_NAME=\"AlmaLinux 9.5 (Teal Serval)\"\nANSI_COLOR=\"0;34\"\nLOGO=\"fedora-logo-icon\"\nCPE_NAME=\"cpe:/o:almalinux:almalinux:9::baseos\"\nHOME_URL=\"https://almalinux.org/\"\nDOCUMENTATION_URL=\"https://wiki.almalinux.org/\"\nBUG_REPORT_URL=\"https://bugs.almalinux.org/\"\n\nALMALINUX_MANTISBT_PROJECT=\"AlmaLinux-9\"\nALMALINUX_MANTISBT_PROJECT_VERSION=\"9.5\"\nREDHAT_SUPPORT_PRODUCT=\"AlmaLinux\"\nREDHAT_SUPPORT_PRODUCT_VERSION=\"9.5\"\nSUPPORT_END=2032-06-01\n</code></pre>"},{"location":"task1/install_docker/#step-4-exit-the-container","title":"Step 4: Exit the Container","text":"<p>When you are finished working inside an interactive container, you can exit the container gracefully.</p> <p>At the bash prompt inside the container, simply type:</p> <pre><code>exit\n</code></pre> <p>Then press Enter. This command terminates the shell session, which in turn stops the container.</p> <p>Alternatively, you can press control+D on your keyboard. This shortcut sends an end-of-file (EOF) signal, which also terminates the interactive shell session.</p> <p>Tip</p> <p>If you want to keep the container running without terminating it, you can detach by pressing Ctrl+P followed by Ctrl+Q. To reattach later, run: <code>docker attach &lt;container_id_or_name&gt;</code> or use <code>docker exec -it &lt;container_id_or_name&gt; /bin/bash</code> if you simply want a new shell in a running container.</p>"},{"location":"task1/test_py_cpp/","title":"Testing the AlmaLinux9 Container with Simple Python and C++ Code","text":"<p>To ensure that your AlmaLinux9 container works correctly, we will test it with simple Python and C++ scripts.</p> <p>Small Assignment</p> <p>Suppose you have:</p> <ul> <li>\\( a = 3 \\): a real-valued scalar</li> <li>\\( x = (1,1,1,\\dots,1) \\): a real-valued vector of dimension \\(N = 20\\)</li> <li>\\( y = (4,4,4,\\dots,4) \\): another real-valued vector of dimension \\(N = 20\\)</li> </ul> <p>Write a program that calculates \\( z = a \\cdot x + y \\) and prints its values to a text file.</p>"},{"location":"task1/test_py_cpp/#python-code","title":"Python code","text":"<p>Find the Python code in GitHub here.</p> scalar_prod_python.py<pre><code>import os\nimport numpy as np\n\n# Define the output file\nOUTPUT_DIR = \"output\"\nOUTPUT_FILE = \"out_python.txt\"\npath_to_output = os.path.join(OUTPUT_DIR, OUTPUT_FILE)\n\n# Define the input variables\na = 3\nx = np.full(20, 1)\ny = np.full(20, 4)\n\n# Calculate the result z = a*x + y\nz = a * x + y # z is a vector of dimension N = 20 with all elements equal to 7\n\n# Write the result to a text file\nwith open(path_to_output, \"w\") as f:\n    f.write(\"z = \" + str(z))\n</code></pre>"},{"location":"task1/test_py_cpp/#running-the-python-script","title":"Running the Python script","text":"<ol> <li> <p>Make sure your conda environment is activated (if you\u2019re using Miniconda):</p> <pre><code>conda activate python_env\n</code></pre> </li> <li> <p>Install NumPy (if not already installed):</p> <pre><code>pip install numpy\n</code></pre> </li> <li> <p>Run the Python script:</p> <pre><code>python scalar_prod_python.py\n</code></pre> </li> <li> <p>Check the output file <code>out_python.txt</code> in the <code>output</code> directory.</p> <pre><code>cat output/out_python.txt\n</code></pre> </li> </ol>"},{"location":"task1/test_py_cpp/#c-code","title":"C++ code","text":"<p>Find the C++ code in GitHub here.</p> scalar_prod_cpp.cpp<pre><code>#include &lt;iostream&gt;\n#include &lt;fstream&gt;\n#include &lt;vector&gt;\n#include &lt;string&gt;\n\nconst std::string OUTPUT_DIR = \"output\";\nconst std::string OUTPUT_FILE = OUTPUT_DIR + \"/output_cpp.txt\";\n\nint main() {\n    // Define the input values\n    double a = 3;\n    std::vector&lt;double&gt; x(20, 1.0);\n    std::vector&lt;double&gt; y(20, 4.0);\n\n    // Calculate z = a*x + y\n    std::vector&lt;double&gt; z(20);\n    for (int i = 0; i &lt; 20; i++) {\n        z[i] = a * x[i] + y[i];\n    }\n\n    // Write the result to a text file\n    std::ofstream ofs(OUTPUT_FILE);\n    if (!ofs) {\n        std::cerr &lt;&lt; \"Error: Unable to open the output file\\n\";\n        return 1;\n    }\n    for (double val : z) {\n        ofs &lt;&lt; val &lt;&lt; std::endl;\n    }\n    ofs.close();\n\n    return 0;\n}\n</code></pre>"},{"location":"task1/test_py_cpp/#compiling-and-running-the-c-program","title":"Compiling and running the C++ program","text":"<ol> <li> <p>Compile the C++ code:</p> <pre><code>g++ -o scalar_prod_cpp scalar_prod_cpp.cpp\n</code></pre> </li> <li> <p>Run the executable:</p> <pre><code>./scalar_prod_cpp\n</code></pre> </li> <li> <p>Check the output file <code>output_cpp.txt</code> in the <code>output</code> directory:</p> <pre><code>cat output/output_cpp.txt\n</code></pre> </li> </ol> <p>Tip</p> <p>If you want to store these files (both Python and C++ scripts) on your host machine permanently, place them in the shared directory you mounted (e.g., <code>/workspace</code>) so they persist after the container stops.</p>"},{"location":"task2/intro/","title":"Introduction to Task 2","text":"<p>This document introduces Task\u00a02, which demonstrates the implementation and testing of two numerical operations: a vector sum and a matrix multiplication. These operations are implemented in both Python and C++.</p> <p>Prerequisites</p> <ul> <li>Docker must be installed and an AlmaLinux9 container set up for Python and C++ development.  </li> <li>Follow the Docker and container setup instructions in Task\u00a01 before proceeding with Task\u00a02.</li> </ul> <p>In Task\u00a02, you will find:</p> <ul> <li> <p>A Vector Sum implementation that computes:  </p> \\[ d = a \\cdot x + y, \\] <p>where \\(a\\) is a scalar and \\(x\\) and \\(y\\) are vectors.</p> </li> <li> <p>A Matrix Multiplication implementation that computes:  </p> \\[ C = A \\, B, \\quad \\text{with} \\quad C_{ij} = \\sum_{k=1}^{N} a_{ik} \\, b_{kj}, \\] <p>where \\(A\\), \\(B\\), and \\(C\\) are \\(N \\times N\\) matrices.</p> </li> </ul> <p>Each operation comes with separate test suites that measure execution time and validate correctness.  </p>"},{"location":"task2/matrix_mult/","title":"Matrix Multiplication","text":"<p>This page demonstrates the matrix multiplication operation in both Python and C++. The function computes</p> \\[ C = A \\times B \\quad \\text{with} \\quad C_{ij} = \\sum_{k=1}^{N} a_{ik} \\, b_{kj}, \\] <p>where \\(A\\) and \\(B\\) are both \\(N \\times N\\) matrices, and \\(C\\) is the resulting \\(N \\times N\\) matrix. The matrix multiplication operation is nevertheless implemented in its general form, where the dimensions of \\(A\\) and \\(B\\) are \\(m \\times n\\) and \\(n \\times p\\), respectively. The function raises an exception if the inner dimensions of \\(A\\) and \\(B\\) do not match.</p> <p>Test suites measure execution time and verify that the resulting matrix is correct. </p>"},{"location":"task2/matrix_mult/#python-implementation","title":"Python implementation","text":"matrix_mult_python.py<pre><code>import numpy as np\n\ndef matrix_mult(A: np.ndarray, B: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Compute the matrix multiplication C = A @ B.\n\n    Parameters:\n        A (np.ndarray): A matrix of shape (m, n).\n        B (np.ndarray): A matrix of shape (n, p).\n\n    Returns:\n        np.ndarray: The resulting matrix C of shape (m, p).\n\n    Raises:\n        ValueError: If the inner dimensions of A and B do not match.\n    \"\"\"\n    if A.shape[1] != B.shape[0]:\n        raise ValueError(\"Inner dimensions of A and B must match.\")\n    return A @ B\n</code></pre> test_matrix_mult_python.py<pre><code>import time\nimport math\nimport numpy as np\nfrom matrix_mult_python import matrix_mult\n\ndef run_matrix_mult_test(n: int, n_iter: int = 1):\n    \"\"\"\n    Run the matrix multiplication for n x n matrices, measure the execution time\n    over n_iter iterations, and verify that each element of C equals n * (a_val * b_val).\n\n    Parameters:\n        n (int): The dimension of the square matrices.\n        n_iter (int): The number of iterations for timing measurement (default is 1).\n\n    Raises:\n        AssertionError: If any element of the computed matrix does not match the expected value.\n    \"\"\"\n    a_val = 3.0\n    b_val = 7.1\n    expected_value = n * (a_val * b_val)  # Each element should equal n * (a_val * b_val).\n    tolerance = 1e-7\n\n    # Create constant matrices A and B of size (n, n)\n    A = np.full((n, n), a_val)\n    B = np.full((n, n), b_val)\n\n    times = []\n    for i in range(n_iter):\n        start_time = time.perf_counter()\n        C = matrix_mult(A, B)\n        elapsed_time = time.perf_counter() - start_time\n        times.append(elapsed_time)\n\n        if not np.allclose(C, expected_value, atol=tolerance):\n            raise AssertionError(f\"Test failed for n = {n} on iteration {i+1}\")\n\n    avg_time = sum(times) / n_iter\n    rms_time = math.sqrt(sum((t - avg_time) ** 2 for t in times) / n_iter)\n    min_time = min(times)\n    max_time = max(times)\n\n    print(f\"Test passed for n = {n} over {n_iter} iterations:\")\n    print(f\"  Average time: {avg_time:.6f} seconds\")\n    print(f\"  RMS: {rms_time:.6f} seconds\")\n    print(f\"  Min time: {min_time:.6f} seconds\")\n    print(f\"  Max time: {max_time:.6f} seconds\")\n\ndef main():\n    run_matrix_mult_test(10, n_iter=100000)\n    run_matrix_mult_test(100, n_iter=100000)\n    run_matrix_mult_test(10000, n_iter=10)\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"task2/matrix_mult/#run-the-python-tests","title":"Run the Python tests","text":"<pre><code>python test_matrix_mult_python.py\n</code></pre>"},{"location":"task2/matrix_mult/#results","title":"Results","text":"<pre><code>Test passed for n = 10 over 100000 iterations:\n  Average time: 1.49e-06 seconds\n  RMS: 3.03e-06 seconds\n  Min time: 1.33e-06 seconds\n  Max time: 9.42e-04 seconds\nTest passed for n = 100 over 100000 iterations:\n  Average time: 6.31e-05 seconds\n  RMS: 3.19e-04 seconds\n  Min time: 3.75e-05 seconds\n  Max time: 4.70e-02 seconds\nTest passed for n = 10000 over 10 iterations:\n  Average time: 9.293362 seconds\n  RMS: 0.729940 seconds\n  Min time: 8.384377 seconds\n  Max time: 10.786640 seconds\n</code></pre>"},{"location":"task2/matrix_mult/#c-implementation","title":"C++ implementation","text":"matrix_mult_cpp.cpp<pre><code>#ifndef MATRIX_MULT_CPP_HPP\n#define MATRIX_MULT_CPP_HPP\n\n#include &lt;vector&gt;\n#include &lt;stdexcept&gt;\n#include &lt;cstddef&gt;\n#include &lt;cassert&gt;\n\n/**\n * @brief Compute the matrix multiplication C = A * B.\n *\n * Matrices are represented as a single contiguous vector in row-major order.\n * Given matrix A of dimensions m x n and matrix B of dimensions n x p,\n * this function computes the product C (of dimensions m x p) and stores it in C_out.\n * The output vector C_out is resized accordingly.\n *\n * @param A The left matrix (m x n), stored in row-major order.\n * @param B The right matrix (n x p), stored in row-major order.\n * @param C_out Output matrix (m x p), stored in row-major order.\n * @param m Number of rows in A.\n * @param n Number of columns in A (and rows in B).\n * @param p Number of columns in B.\n * @throws std::invalid_argument if the dimensions of A or B are inconsistent.\n */\ninline void matrix_mult(const std::vector&lt;double&gt;&amp; A,\n                        const std::vector&lt;double&gt;&amp; B,\n                        std::vector&lt;double&gt;&amp; C_out,\n                        std::size_t m,\n                        std::size_t n,\n                        std::size_t p)\n{\n    if (A.size() != m * n || B.size() != n * p) {\n        throw std::invalid_argument(\"Matrix dimensions do not match the provided sizes.\");\n    }\n\n    // Resize output vector to hold the result (m x p) and initialize with zeros.\n    C_out.assign(m * p, 0.0);\n\n    // Use loop reordering to improve cache locality.\n    for (std::size_t i = 0; i &lt; m; ++i) {\n        for (std::size_t k = 0; k &lt; n; ++k) {\n            double a_ik = A[i * n + k];\n            for (std::size_t j = 0; j &lt; p; ++j) {\n                C_out[i * p + j] += a_ik * B[k * p + j];\n            }\n        }\n    }\n}\n\n#endif // MATRIX_MULT_CPP_HPP\n</code></pre> test_matrix_mult_cpp.cpp<pre><code>#include \"matrix_mult_cpp.hpp\"\n#include &lt;iostream&gt;\n#include &lt;chrono&gt;\n#include &lt;vector&gt;\n#include &lt;cassert&gt;\n#include &lt;cmath&gt;\n#include &lt;numeric&gt;    // For std::accumulate\n#include &lt;algorithm&gt;  // For std::min_element and std::max_element\n\n/**\n * @brief Run the matrix multiplication test.\n *\n * This function creates two constant n x n matrices A and B (stored as contiguous vectors),\n * measures the execution time of their multiplication over n_iter iterations, and verifies that\n * each element of the resulting matrix equals n * (a_val * b_val) within a small tolerance.\n *\n * @param n The dimension of the square matrices.\n * @param n_iter The number of iterations for timing measurement.\n */\nvoid run_matrix_mult_test(std::size_t n, int n_iter = 1) {\n    const double a_val = 3.0;\n    const double b_val = 7.1;\n    const double expected_value = n * (a_val * b_val);  // Expected value: n * (a_val * b_val)\n    const double tolerance = 1e-7;\n\n    // Create matrices A and B as contiguous vectors in row-major order.\n    std::vector&lt;double&gt; A(n * n, a_val);\n    std::vector&lt;double&gt; B(n * n, b_val);\n\n    // Pre-allocate the output matrix to be reused.\n    std::vector&lt;double&gt; C; \n    std::vector&lt;double&gt; times;\n    times.reserve(n_iter);\n\n    for (int iter = 0; iter &lt; n_iter; ++iter) {\n        auto start = std::chrono::high_resolution_clock::now();\n        matrix_mult(A, B, C, n, n, n);\n        auto end = std::chrono::high_resolution_clock::now();\n        std::chrono::duration&lt;double&gt; elapsed = end - start;\n        times.push_back(elapsed.count());\n\n        // Verify that each element in C is as expected.\n        for (const auto&amp; v : C) {\n            assert(std::fabs(v - expected_value) &lt; tolerance &amp;&amp; \"Element does not match expected value.\");\n        }\n    }\n\n    // Compute statistics: average, RMS, minimum, and maximum times.\n    double sum = std::accumulate(times.begin(), times.end(), 0.0);\n    double avg_time = sum / n_iter;\n\n    double sq_sum = 0.0;\n    for (double t : times) {\n        sq_sum += (t - avg_time) * (t - avg_time);\n    }\n    double rms_time = std::sqrt(sq_sum / n_iter);\n\n    double min_time = *std::min_element(times.begin(), times.end());\n    double max_time = *std::max_element(times.begin(), times.end());\n\n    std::cout &lt;&lt; \"Test passed for n = \" &lt;&lt; n &lt;&lt; \" over \" &lt;&lt; n_iter &lt;&lt; \" iterations:\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"  Average time: \" &lt;&lt; avg_time &lt;&lt; \" seconds\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"  RMS: \" &lt;&lt; rms_time &lt;&lt; \" seconds\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"  Min time: \" &lt;&lt; min_time &lt;&lt; \" seconds\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"  Max time: \" &lt;&lt; max_time &lt;&lt; \" seconds\" &lt;&lt; std::endl;\n}\n\nint main() {\n    // Run tests for different matrix sizes.\n    run_matrix_mult_test(10, 100);\n    run_matrix_mult_test(100, 100);\n    run_matrix_mult_test(10000, 5);\n    return 0;\n}\n</code></pre>"},{"location":"task2/matrix_mult/#compile-and-run-the-c-tests","title":"Compile and run the C++ tests","text":"Without optimization flagsWith optimization flags <ol> <li> <p>Compile the C++ code:</p> <pre><code>g++ -O0 -std=c++11 test_matrix_mult_cpp.cpp -o test_matrix_mult_cpp\n</code></pre> </li> <li> <p>Run the executable:</p> <pre><code>./test_vector_sum_cpp\n</code></pre> </li> </ol> <ol> <li> <p>Compile the C++ code:</p> <pre><code>g++ -O3 -std=c++11 test_matrix_mult_cpp.cpp -o test_matrix_mult_cpp\n</code></pre> </li> <li> <p>Run the executable:</p> <pre><code>./test_vector_sum_cpp\n</code></pre> </li> </ol>"},{"location":"task2/matrix_mult/#results_1","title":"Results","text":"Without optimization flagsWith optimization flags <pre><code>Test passed for n = 10 over 100000 iterations:\n  Average time: 3.29334e-06 seconds\n  RMS: 8.93811e-07 seconds\n  Min time: 3e-06 seconds\n  Max time: 5.75e-05 seconds\nTest passed for n = 100 over 100000 iterations:\n  Average time: 0.00281444 seconds\n  RMS: 0.000374047 seconds\n  Min time: 0.00254553 seconds\n  Max time: 0.0354478 seconds\n</code></pre> <pre><code>Test passed for n = 10 over 100000 iterations:\n  Average time: 3.67979e-07 seconds\n  RMS: 3.14219e-07 seconds\n  Min time: 2.08e-07 seconds\n  Max time: 3.9334e-05 seconds\nTest passed for n = 100 over 100000 iterations:\n  Average time: 0.000100926 seconds\n  RMS: 4.28775e-05 seconds\n  Min time: 9.5166e-05 seconds\n  Max time: 0.010053 seconds\nTest passed for n = 10000 over 5 iterations:\n  Average time: 216.812 seconds\n  RMS: 0.961168 seconds\n  Min time: 215.852 seconds\n  Max time: 218.019 seconds\n</code></pre>"},{"location":"task2/matrix_mult/#discussion","title":"Discussion","text":"<p>The plot below compares the average execution times (with RMS error bars) for the matrix multiplication operation across three implementations.</p> <p></p> <ul> <li> <p>Python (using NumPy): </p> <p>NumPy <code>@</code> operator (equivalent to <code>np.matmul(A, B)</code>) delegates the heavy lifting to highly optimized low-level, BLAS-based libraries.  Although Python itself incurs interpreter overhead, that cost is amortized when the actual multiplication is performed in compiled code. This allows Python to scale well even for larger matrices because most work is offloaded to efficient, vectorized routines.</p> </li> <li> <p>C++ (without optimization flags): </p> <p>The C++ implementation stores matrices in a single contiguous block (row-major order) and reuses a pre-allocated output vector. This improves cache locality and reduces dynamic memory allocation overhead compared to a vector-of-vectors.  Despite memory optimizations, the implementation is based on a straightforward triple-nested loop, resulting in cubic time complexity.  Without compiler optimizations, the code does not take full advantage of the CPU\u2019s capabilities. The simple triple-nested loop is not auto-vectorized or parallelized, which limits its performance compared to both the optimized C++ version and NumPy even for small matrices.</p> </li> <li> <p>C++ (with optimization flags): </p> <p>When compiled with aggressive optimization (e.g., <code>-O3</code>), the C++ code benefits from auto-vectorization, function inlining, loop unrolling, and other advanced optimizations. For small and medium-sized matrices, the optimized C++ implementation outperforms unoptimized C++ and approaches the performance of NumPy. However, for very large matrices (n = 10,000), even the optimized C++ implementation requires around 216 seconds on average. Despite aggressive low-level improvements, the naive cubic-time (\\(O(n^3)\\)) algorithm still performs an enormous number of arithmetic operations, and single-threaded execution becomes a severe bottleneck.</p> </li> </ul>"},{"location":"task2/questions/","title":"Questions Regarding Task 2: Vector Sum and Matrix Multiplication","text":"<p>Below are the teacher's questions and my corresponding answers:</p>"},{"location":"task2/questions/#q1-did-you-find-any-problems-in-running-the-codes-for-some-n-if-so-do-you-have-an-idea-why","title":"Q1: Did you find any problems in running the codes for some N? If so, do you have an idea why?","text":"<p>Answer:</p> <p>No, I did not encounter any problems running the codes for the tested values of N. Here\u2019s why:</p> <ul> <li> <p>Python:   NumPy handles large arrays by allocating memory on the heap, not on the stack. This means that even for very large values of N, the system's available RAM is the primary constraint rather than the limited stack size. Additionally, NumPy\u2019s operations are implemented in highly optimized C code, so they run efficiently and blazingly fast even for large arrays.</p> </li> <li> <p>C++:   In the C++ implementations, I used <code>std::vector</code> to allocate memory dynamically on the heap. This avoids the stack overflow issues that would occur if large arrays were allocated on the stack. If I had allocated these arrays on the stack (for example, using standard C++ arrays), then for large N the program would fail due to exceeding the available stack size.</p> </li> </ul>"},{"location":"task2/questions/#q2-were-you-able-to-test-correctly-the-sum-and-product-for-vector-sum-and-matrix-multiplication-if-so-how-if-not-what-was-the-problem","title":"Q2: Were you able to test correctly the sum and product for vector sum and matrix multiplication? If so, how? If not, what was the problem?","text":"<p>Answer:</p> <p>Yes, I was able to test the computations correctly. I verified the results as follows:</p> <ul> <li> <p>Tolerance-Based Comparison:   For both vector sum and matrix multiplication, I compared the computed results with the expected values using a tolerance-based approach. In Python, I used <code>np.allclose</code> to check that the computed results were within a small tolerance of the expected values. In C++, I used assertions with a tolerance check (using <code>std::fabs</code> to compare differences). </p> </li> <li> <p>Why Not Exact Equality?   Directly testing for exact equality (using <code>==</code>) would fail due to the inherent rounding errors in floating-point arithmetic. Floating-point operations can introduce tiny discrepancies due to limited precision. The tolerance method ensures that these minor discrepancies do not cause the tests to fail, confirming that the computations are correct within an acceptable error margin.</p> </li> </ul>"},{"location":"task2/vector_sum/","title":"Vector Sum","text":"<p>This page demonstrates the vector sum operation in both Python and C++. The function computes the vector sum</p> \\[ d = a \\cdot x + y, \\] <p>where \\(x\\) and \\(y\\) are vectors of dimension \\(N\\). The test suites measure the execution time and verify that every element equals the expected result.</p>"},{"location":"task2/vector_sum/#python-implementation","title":"Python implementation","text":"vector_sum_python.py<pre><code>import numpy as np\n\ndef vector_sum(a: float, x: np.ndarray, y: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Compute the vector sum d = a * x + y, where x and y are vectors.\n\n    Parameters:\n        a (float): Scalar multiplier.\n        x (np.ndarray): A vector.\n        y (np.ndarray): A vector.\n\n    Returns:\n        np.ndarray: The resulting vector d.\n\n    Raises:\n        ValueError: If x and y do not have the same shape.\n    \"\"\"\n    if x.shape != y.shape:\n        raise ValueError(\"Vectors x and y must have the same shape.\")\n    return a * x + y\n</code></pre> test_vector_sum_python.py<pre><code>import time\nimport math\nimport numpy as np\nfrom vector_sum_python import vector_sum\n\ndef run_vector_sum_test(n: int, n_iter: int = 1):\n    \"\"\"\n    Run the vector sum computation for vectors of size n, measure the execution time\n    over n_iter iterations, and verify that each element equals the expected value\n    within a defined tolerance.\n\n    Parameters:\n        n (int): The size of the vectors.\n        n_iter (int): The number of iterations for timing measurement (default 1).\n\n    Raises:\n        AssertionError: If any element of the computed vector does not match the expected value.\n    \"\"\"\n    a = 3\n    x_val = 0.1\n    y_val = 7.1\n    expected_value = 7.4\n    tolerance = 1e-9\n\n    # Create the input vectors of size n.\n    x_vec = np.full(n, x_val)\n    y_vec = np.full(n, y_val)\n\n    times = []\n\n    for i in range(n_iter):\n        start_time = time.perf_counter()\n        d = vector_sum(a, x_vec, y_vec)\n        elapsed_time = time.perf_counter() - start_time\n        times.append(elapsed_time)\n\n        # Verify that all elements equal the expected value within the tolerance.\n        if not np.allclose(d, expected_value, atol=tolerance):\n            raise AssertionError(f\"Test failed for N = {n} on iteration {i+1}\")\n\n    # Compute average, RMS, min, and max.\n    avg_time = sum(times) / n_iter\n    rms_time = math.sqrt(sum((t - avg_time) ** 2 for t in times) / n_iter)\n    min_time = min(times)\n    max_time = max(times)\n\n    print(f\"Test passed for N = {n} over {n_iter} iterations:\")\n    print(f\"  Average time: {avg_time:.6f} seconds\")\n    print(f\"  RMS: {rms_time:.6f} seconds\")\n    print(f\"  Min time: {min_time:.6f} seconds\")\n    print(f\"  Max time: {max_time:.6f} seconds\")\n\ndef main():\n    run_vector_sum_test(10, n_iter=100)\n    run_vector_sum_test(10**6, n_iter=100)\n    run_vector_sum_test(10**8, n_iter=10)\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"task2/vector_sum/#run-the-python-tests","title":"Run the Python tests","text":"<p>Within the container, execute</p> <pre><code>python test_vector_sum_python.py\n</code></pre>"},{"location":"task2/vector_sum/#results","title":"Results","text":"<pre><code>Test passed for N = 10 over 100 iterations:\n  Average time: 0.000002 seconds\n  RMS: 0.000003 seconds\n  Min time: 0.000002 seconds\n  Max time: 0.000033 seconds\nTest passed for N = 1000000 over 100 iterations:\n  Average time: 0.000627 seconds\n  RMS: 0.000085 seconds\n  Min time: 0.000538 seconds\n  Max time: 0.001189 seconds\nTest passed for N = 100000000 over 10 iterations:\n  Average time: 0.114004 seconds\n  RMS: 0.096845 seconds\n  Min time: 0.070962 seconds\n  Max time: 0.392504 seconds\n</code></pre>"},{"location":"task2/vector_sum/#c-implementation","title":"C++ implementation","text":"vector_sum_cpp.cpp<pre><code>#ifndef VECTOR_SUM_CPP_HPP\n#define VECTOR_SUM_CPP_HPP\n\n#include &lt;vector&gt;\n#include &lt;stdexcept&gt;\n#include &lt;cstddef&gt;\n\n/**\n * @brief Compute the vector sum d = a * x + y.\n *\n * This function accepts a scalar and two input vectors, and writes the result into\n * the output vector d. It checks that the two input vectors have the same size;\n * if not, it throws an exception. The output vector d is resized to match the input vectors.\n *\n * @param a   Scalar multiplier.\n * @param x   Vector x.\n * @param y   Vector y.\n * @param d   Output vector to store the result.\n * @throws std::invalid_argument if the sizes of x and y are not equal.\n */\ninline void vector_sum(double a, const std::vector&lt;double&gt;&amp; x, const std::vector&lt;double&gt;&amp; y, std::vector&lt;double&gt;&amp; d) {\n    if (x.size() != y.size()) {\n        throw std::invalid_argument(\"Vectors x and y must have the same size.\");\n    }\n    d.resize(x.size());\n    for (std::size_t i = 0; i &lt; x.size(); ++i) {\n        d[i] = a * x[i] + y[i];\n    }\n}\n\n#endif // VECTOR_SUM_CPP_HPP\n</code></pre> test_vector_sum_cpp.cpp<pre><code>#include \"vector_sum_cpp.hpp\"\n#include &lt;iostream&gt;\n#include &lt;chrono&gt;\n#include &lt;vector&gt;\n#include &lt;cassert&gt;\n#include &lt;cmath&gt;\n#include &lt;numeric&gt;  // For std::accumulate\n#include &lt;algorithm&gt;  // For std::min_element and std::max_element\n\n/**\n * @brief Runs the vector sum computation test.\n *\n * This function creates two vectors of size n (with constant values),\n * measures the execution time of the vector sum computation over n_iter iterations,\n * and checks that each element of the resulting vector equals the expected value within a small tolerance.\n *\n * @param n The size of the vectors.\n * @param n_iter The number of iterations for timing measurement (default is 1).\n */\nvoid run_vector_sum_test(std::size_t n, int n_iter = 1) {\n    const double a = 3;\n    const double x_val = 0.1;\n    const double y_val = 7.1;\n    const double expected_value = 7.4;\n    const double tolerance = 1e-9;\n\n    // Create the input vectors.\n    std::vector&lt;double&gt; x_vec(n, x_val);\n    std::vector&lt;double&gt; y_vec(n, y_val);\n    // Pre-allocate the output vector to be reused.\n    std::vector&lt;double&gt; d;\n\n    std::vector&lt;double&gt; times;\n    times.reserve(n_iter);\n\n    for (int iter = 0; iter &lt; n_iter; ++iter) {\n        auto start = std::chrono::high_resolution_clock::now();\n        vector_sum(a, x_vec, y_vec, d);\n        auto end = std::chrono::high_resolution_clock::now();\n        std::chrono::duration&lt;double&gt; elapsed = end - start;\n        times.push_back(elapsed.count());\n\n        // Verify that all elements match the expected value.\n        for (std::size_t i = 0; i &lt; d.size(); ++i) {\n            assert(std::fabs(d[i] - expected_value) &lt; tolerance &amp;&amp; \"Element does not match expected value.\");\n        }\n    }\n\n    // Compute average time.\n    double sum = std::accumulate(times.begin(), times.end(), 0.0);\n    double avg_time = sum / n_iter;\n\n    // Compute RMS.\n    double sq_sum = 0.0;\n    for (double t : times) {\n        sq_sum += (t - avg_time) * (t - avg_time);\n    }\n    double rms_time = std::sqrt(sq_sum / n_iter);\n\n    // Find minimum and maximum times.\n    double min_time = *std::min_element(times.begin(), times.end());\n    double max_time = *std::max_element(times.begin(), times.end());\n\n    std::cout &lt;&lt; \"Test passed for n = \" &lt;&lt; n &lt;&lt; \" over \" &lt;&lt; n_iter &lt;&lt; \" iterations:\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"  Average time: \" &lt;&lt; avg_time &lt;&lt; \" seconds\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"  RMS: \" &lt;&lt; rms_time &lt;&lt; \" seconds\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"  Min time: \" &lt;&lt; min_time &lt;&lt; \" seconds\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"  Max time: \" &lt;&lt; max_time &lt;&lt; \" seconds\" &lt;&lt; std::endl;\n}\n\nint main() {\n    // Run tests for three different vector sizes with 5 iterations each.\n    run_vector_sum_test(10, 100);\n    run_vector_sum_test(1000000, 100);   // 10^6\n    run_vector_sum_test(100000000, 10); // 10^8\n    return 0;\n}\n</code></pre>"},{"location":"task2/vector_sum/#compile-and-run-the-c-tests","title":"Compile and run the C++ tests","text":"Without optimization flagsWith optimization flags <ol> <li> <p>Compile the C++ code:</p> <pre><code>g++ -O0 -std=c++11 test_vector_sum_cpp.cpp -o test_vector_sum_cpp\n</code></pre> </li> <li> <p>Run the executable:</p> <pre><code>./test_vector_sum_cpp\n</code></pre> </li> </ol> <ol> <li> <p>Compile the C++ code:</p> <pre><code>g++ -O3 -std=c++11 test_vector_sum_cpp.cpp -o test_vector_sum_cpp\n</code></pre> </li> <li> <p>Run the executable:</p> <pre><code>./test_vector_sum_cpp\n</code></pre> </li> </ol>"},{"location":"task2/vector_sum/#results_1","title":"Results","text":"Without optimization flagsWith optimization flags <pre><code>Test passed for n = 10 over 100 iterations:\n  Average time: 9.207e-08 seconds\n  RMS: 4.34307e-08 seconds\n  Min time: 8.3e-08 seconds\n  Max time: 5e-07 seconds\nTest passed for n = 1000000 over 100 iterations:\n  Average time: 0.00464462 seconds\n  RMS: 0.000816384 seconds\n  Min time: 0.00445675 seconds\n  Max time: 0.0124259 seconds\nTest passed for n = 100000000 over 10 iterations:\n  Average time: 0.533384 seconds\n  RMS: 0.177033 seconds\n  Min time: 0.47326 seconds\n  Max time: 1.06448 seconds\n</code></pre> <pre><code>Test passed for n = 10 over 100 iterations:\n  Average time: 4.919e-08 seconds\n  RMS: 6.65792e-08 seconds\n  Min time: 4.1e-08 seconds\n  Max time: 7.09e-07 seconds\nTest passed for n = 1000000 over 100 iterations:\n  Average time: 0.000363343 seconds\n  RMS: 0.000176492 seconds\n  Min time: 0.0002985 seconds\n  Max time: 0.00170587 seconds\nTest passed for n = 100000000 over 10 iterations:\n  Average time: 0.0341018 seconds\n  RMS: 0.00540988 seconds\n  Min time: 0.0321475 seconds\n  Max time: 0.0503235 seconds\n</code></pre>"},{"location":"task2/vector_sum/#discussion","title":"Discussion","text":"<p>The plot below compares the average execution times (with RMS error bars) for the vector sum operation across three implementations.</p> <p></p> <ul> <li> <p>Python (using NumPy): </p> <p>NumPy leverages highly optimized, vectorized operations that are implemented in low-level C libraries. This means that for large vector sizes, the heavy arithmetic is executed very efficiently on the hardware. However, for very small vectors (e.g., \\(N=10\\)), the overhead of entering the NumPy routines and the Python interpreter dominates, resulting in slightly slower performance compared to optimized C++ loops.</p> </li> <li> <p>C++ (without optimization flags): </p> <p>The unoptimized C++ code uses a simple loop that incurs minimal overhead for small vectors, which is why it achieves extremely low execution times for \\(N=10\\). As the vector size increases, however, the lack of auto-vectorization and other low-level optimizations causes its performance to degrade. In addition, the use of <code>std::vector</code> for dynamic memory allocation is necessary for such large arrays (since the stack cannot hold \\(10^8\\) <code>double</code> elements), and the overhead associated with heap allocation becomes more apparent at larger scales.</p> </li> <li> <p>C++ (with optimization flags): </p> <p>When compiled with aggressive optimization (e.g., <code>-O3</code>), the C++ code benefits from auto-vectorization, function inlining, loop unrolling, and other advanced optimizations. These optimizations drastically reduce the loop overhead and improve memory access patterns. As a result, the optimized C++ implementation is the best performer across all vector sizes\u2014even for large \\(N\\)\u2014by combining minimal overhead for small vectors with excellent scalability for large vectors.</p> </li> </ul>"},{"location":"task3/build/","title":"How to Build the Project","text":""},{"location":"task3/build/#step-by-step-instructions","title":"Step-by-Step Instructions","text":"<p>Assuming you already have the project available locally and your Docker container is running with <code>/workspace</code> set as the project root, follow these steps to build the project:</p> <ol> <li> <p>Navigate to the Project Root:</p> <p>Ensure you are in the project root directory (i.e., <code>/workspace</code>). You can verify this by running:</p> <pre><code>pwd\n</code></pre> <p>It should display <code>/workspace</code> (the project root).</p> </li> <li> <p>Run the Build Script:</p> <p>From the project root, execute the build script to configure and compile the project:</p> <pre><code>bash ./scripts/buildProject.sh\n</code></pre> <p>This script will:</p> <ul> <li>Create a build directory </li> <li>Change into the build directory.</li> <li>Run CMake to generate the build system.</li> <li>Invoke make to compile the source code into executables.</li> <li>Return you to the project root once the build is complete.</li> </ul> </li> <li> <p>Run the Executables:</p> <p>You can now run the executables using the <code>run</code> command from anywhere. For example:</p> <ul> <li> <p>To generate vectors:</p> <pre><code>run generateVectors 10 \"./data/input/vector.h5\"\n</code></pre> </li> <li> <p>To compute the vector sum:</p> <pre><code>run vectorSum \"./config/config.yml\"\n</code></pre> </li> </ul> <p>More details on properly using the executables are provided in the subsequent sections of this documentation. You can skip to the next page if not interested in the build process details. </p> </li> </ol>"},{"location":"task3/build/#in-depth-build-process-explanation","title":"In-Depth Build Process Explanation","text":"<p>After running the build script, a series of automated steps are performed behind the scenes to transform the source code into executable programs. Below is an in-depth explanation of what happens during the build process and how to use the run command.</p>"},{"location":"task3/build/#build-process-overview","title":"Build Process Overview","text":"<ol> <li> <p>Build Directory Creation:</p> <p>The build script first checks for the existence of the <code>build/</code> directory in the project root. If it doesn\u2019t exist, it creates it. This out-of-source build practice keeps all generated files separate from the source code, which simplifies cleanup and avoids polluting the source tree.</p> scripts/buildProject.sh<pre><code># Determine the project root (the directory where this script is located)\nPROJECT_ROOT=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" &amp;&amp; pwd )\"\nBUILD_DIR=\"$PROJECT_ROOT/build\"\n\necho \"Building project in: $BUILD_DIR\"\n\n# Create and enter the build directory.\nmkdir -p \"$BUILD_DIR\"\ncd \"$BUILD_DIR\"\n</code></pre> </li> <li> <p>CMake Configuration:</p> <ul> <li> <p>Once inside the <code>build/</code> directory, the script runs the command </p> scripts/buildProject.sh<pre><code>echo \"Running CMake configuration...\"\n# Run CMake configuration; exit if it fails.\ncmake .. || { echo \"CMake configuration failed\"; exit 1; }\n</code></pre> </li> <li> <p>CMake reads the <code>CMakeLists.txt</code> file located in the project root. This file specifies the project\u2019s configuration:</p> <ul> <li> <p>It sets the C++ standard to C++11 and enables common compiler flags like <code>-Wall</code>, <code>-Wextra</code>, and <code>-O3</code> for optimization.</p> CMakelists.txt<pre><code>set(CMAKE_CXX_STANDARD 11)\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wall -Wextra -O3\")\n</code></pre> </li> <li> <p>It defines where the executables will be placed (specifically, in <code>build/bin</code>).</p> CMakelists.txt<pre><code>set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${PROJECT_BINARY_DIR}/bin)\nget_filename_component(BIN_DIR_ABS ${CMAKE_RUNTIME_OUTPUT_DIRECTORY} ABSOLUTE)\n</code></pre> <p>The absolute path (<code>BIN_DIR_ABS</code>) is later used in the run script.</p> </li> <li> <p>It locates and configures external dependencies such as yaml-cpp, HDF5, and GSL.</p> CMakelists.txt<pre><code>find_package(yaml-cpp REQUIRED)\nfind_package(HDF5 REQUIRED COMPONENTS CXX)\ninclude_directories(${HDF5_INCLUDE_DIRS})\nfind_package(GSL REQUIRED)\ninclude_directories(${GSL_INCLUDE_DIRS})\n</code></pre> </li> <li> <p>It defines the build targets (executables like <code>generateVectors</code> and <code>vectorSum</code>) and links them with the required libraries.</p> CMakelists.txt<pre><code>add_executable(generateVectors src/generateVectors.cpp)\nadd_executable(vectorSum src/vectorSum.cpp)\n\ntarget_link_libraries(generateVectors ${HDF5_LIBRARIES})\ntarget_link_libraries(vectorSum yaml-cpp ${HDF5_LIBRARIES} GSL::gsl GSL::gslcblas)\n</code></pre> </li> <li> <p>It configures a run script from a template (located in <code>commands/run.in</code>), replacing placeholders (such as the project root and the absolute path to <code>build/bin</code>) with actual values. </p> CMakelists.txt<pre><code>set(RUN_SCRIPT_TEMPLATE ${PROJECT_SOURCE_DIR}/commands/run.in)\nset(RUN_SCRIPT_OUTPUT ${PROJECT_BINARY_DIR}/commands/run)\nconfigure_file(${RUN_SCRIPT_TEMPLATE} ${RUN_SCRIPT_OUTPUT} @ONLY)\nexecute_process(COMMAND chmod 0755 ${RUN_SCRIPT_OUTPUT})\nadd_custom_target(copy_run ALL\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different ${RUN_SCRIPT_OUTPUT} /usr/local/bin/run\n    COMMENT \"Copying run script to /usr/local/bin\"\n)\n</code></pre> </li> <li> <p>It ensures that both executables depend on the copy_run target, so that the run script is always copied when building the project.</p> CMakelists.txt<pre><code>add_dependencies(generateVectors copy_run)\nadd_dependencies(vectorSum copy_run)\n</code></pre> </li> </ul> </li> </ul> </li> <li> <p>Compilation with Make:</p> <ul> <li> <p>After CMake has successfully configured the project, the build script invokes make:</p> scripts/buildProject.sh<pre><code>echo \"Starting build with make...\"\n# Build the project with make; exit if the build fails.\nmake || { echo \"Build failed\"; exit 1; }\n</code></pre> </li> <li> <p>Make reads the generated Makefiles (created by CMake) and compiles all source files according to the defined rules. This step builds the executables and places them in the <code>build/bin</code> directory.</p> </li> <li>The custom target defined in CMake also ensures that the run script is copied to <code>/usr/local/bin</code>, so that it is globally accessible.</li> </ul> </li> </ol>"},{"location":"task3/code_overview/","title":"Code overview","text":"<p>This page describes, step by step, how the different components of Task 3 work together to generate input vectors, select an algorithm, compute the sum \\(d = a\\,x + y\\), and write the result. </p>"},{"location":"task3/code_overview/#generating-vectors","title":"Generating Vectors","text":"<ol> <li> <p>Invoke the executable </p> <p>From the terminal , use the <code>run</code> command associated with the <code>generateVectors</code> executable:</p> <pre><code>run generateVectors &lt;N&gt; &lt;filename_prefix&gt;\n</code></pre> <p>where</p> <ul> <li><code>&lt;N&gt;</code> is the number of elements in each vector and <code>&lt;filename_prefix&gt;</code> is the prefix for the output files.</li> <li><code>&lt;filename_prefix&gt;</code> is a path and file\u2010name prefix (for example, <code>data/input/vector.txt</code>).</li> </ul> </li> <li> <p>What happens inside</p> <ul> <li>The program allocates two <code>std::vector&lt;double&gt;</code> of length <code>N</code>.</li> <li>It fills both vectors with a constant value (set in code).</li> <li> <p>It calls the <code>write_vector</code> helper, which:</p> <ol> <li>Examines the extension of <code>&lt;filename_prefix&gt;</code> (<code>.txt</code>, <code>.dat</code>, or .<code>h5</code>).</li> <li>Dispatches to the matching I/O routine (plain\u2010text, binary, or HDF5).</li> <li>Writes <code>x</code> to <code>&lt;filename_prefix&gt;_x.&lt;ext&gt;</code> and <code>y</code> to <code>&lt;filename_prefix&gt;_y.&lt;ext&gt;</code>.</li> </ol> </li> </ul> </li> <li> <p>Result</p> <ul> <li>Two files are created: <code>&lt;filename_prefix&gt;_x.&lt;ext&gt;</code> and <code>&lt;filename_prefix&gt;_y.&lt;ext&gt;</code>, containing the vectors <code>x</code> and <code>y</code> respectively.</li> </ul> </li> </ol>"},{"location":"task3/code_overview/#preparing-the-configuration","title":"Preparing the configuration","text":"<p>Before running the sum, you must create or edit a YAML file (for example, config/config.yml) with these fields:</p> config/config.yml<pre><code>input:\n  vector_x: \"data/input/vector_N10_x.h5\"\n  vector_y: \"data/input/vector_N10_y.h5\"\nN: 10\na: 3\noutput:\n    path: \"./data/output\"\n    prefix: \"result\"\n    format: \"txt\" # or \"dat\" or \"h5\"\nimplementation: \"gsl\" # Or \"default\"\n</code></pre> <ul> <li><code>input.vector_x</code>, <code>input.vector_y</code>: paths to the two vectors.</li> <li><code>N</code>: number of elements (must match how you generated the vectors).</li> <li><code>a</code>: scalar multiplier in the sum.</li> <li><code>output.path</code>: directory where the result will be saved.</li> <li><code>output.prefix</code>: prefix for the output file.</li> <li><code>output.format</code>: format for the output file (can be <code>txt</code>, <code>dat</code>, or <code>h5</code>).</li> <li><code>implementation</code>: selects the algorithm (see next section).</li> </ul>"},{"location":"task3/code_overview/#computing-the-sum","title":"Computing the sum","text":"<ol> <li> <p>Invoke the executable </p> <p>From the terminal, use the <code>run</code> command associated with the <code>vectorSum</code> executable:</p> <pre><code>run vectorSum config/config.yml\n</code></pre> </li> <li> <p>YAML parsing</p> <p>The program uses <code>yaml-cpp</code> to read all required parameters from <code>config.yml</code>.</p> </li> <li> <p>Reading input vectors</p> <p>It calls the <code>read_vector</code> helper, which checks the file extension and reads the data into two <code>std::vector&lt;double&gt;</code> objects.</p> </li> <li> <p>Choosing the implementation</p> <p>Based on the <code>implementation</code> field in the YAML config, it creates an instance of either <code>VectorSumDefault</code> or <code>VectorSumGSL</code>. Both derive from <code>VectorSumInterface</code>.</p> </li> <li> <p>Computing the sum</p> <p>The chosen implementation's <code>compute_sum</code> method is called with the vectors <code>x</code>, <code>y</code>, scalar <code>a</code>, and an output vector <code>d</code>.</p> <ul> <li>If <code>implementation</code> is <code>default</code>, it uses a simple loop to compute \\(d = a \\cdot x + y\\).</li> <li>If <code>implementation</code> is <code>gsl</code>, it uses <code>gsl_vector_axpby</code> for an in-place BLAS-optimized update.</li> </ul> </li> <li> <p>Writing the result</p> <p>The program calls the <code>write_vector</code> helper to save the output vector <code>d</code> to the specified file in the chosen format.</p> </li> </ol>"},{"location":"task3/docker/","title":"Docker Installation and Setup for Task 3","text":""},{"location":"task3/docker/#overview","title":"Overview","text":"<p>This guide explains how to build and run the Docker container that provides a virtualized environment for Task 3 of the Scientific Computing for Physics Students project. The container is based on AlmaLinux9 and includes all required development tools and libraries (yaml-cpp, HDF5, GSL, etc.), as well as a Python environment managed by Miniconda.</p> <p>Prerequisites</p> <ul> <li>Docker must be installed.</li> <li>Follow the Docker installation instructions in Task\u00a01 before proceeding with Task\u00a03.</li> </ul>"},{"location":"task3/docker/#building-the-docker-image","title":"Building the Docker Image","text":"<p>The Dockerfile is located in the <code>docker/</code> directory and is named <code>Dockerfile.alma9</code>.</p> <ol> <li>Open a terminal and navigate to the project root.</li> <li> <p>Run the following command to build the Docker image:</p> <pre><code>docker build -t sci-comp-task3 -f docker/Dockerfile.alma9 .\n</code></pre> <ol> <li><code>-t sci-comp-task3</code> tags the image with the name <code>sci-comp-task3</code>.</li> <li><code>-f docker/Dockerfile.alma9</code> specifies the location of the Dockerfile.</li> <li>The final <code>.</code> sets the build context to the project root.</li> </ol> </li> </ol>"},{"location":"task3/docker/#running-the-docker-container","title":"Running the Docker Container","text":"<p>Once the image is built, you can start a container interactively with:</p> <pre><code>docker run -it -v \"$(pwd):/workspace\" sci-comp-task3\n</code></pre> <ul> <li><code>-it</code>: Runs the container in interactive mode with a TTY.</li> <li><code>-v \"$(pwd):/workspace\"</code>: Mounts the current project root into the container at /workspace.</li> <li><code>sci-comp-task3</code>: Specifies the image name.</li> </ul> <p>Inside the container, your working directory will be <code>/workspace</code> (which is your project root), and all necessary tools and libraries will be available.</p>"},{"location":"task3/intro/","title":"Introduction to Task 3","text":"<p>Task 3 demonstrates a more complete and practical implementation of basic software and project design. It is designed both as a learning tool and as a practical framework that integrates multiple components into one cohesive system.</p>"},{"location":"task3/intro/#what-the-project-does","title":"What the Project Does","text":"<p>The project focuses on two primary operations:</p> <ol> <li> <p>Generate Vectors:    The <code>generateVectors</code> executable creates two vectors (x and y) of dimension <code>N</code> filled with constant values. These vectors can be saved in either plain text format (\".txt\" or \".dat\") or in HDF5 format (\".h5\"), depending on the file extension provided in the filename prefix.</p> </li> <li> <p>Compute Vector Sum:    The <code>vectorSum</code> executable reads the vectors from files (using the appropriate I/O method based on the file extension) and computes their sum according to the formula:</p> \\[ d = a \\cdot x + y, \\] </li> </ol> <p>Two implementations are provided for this computation:</p> <ul> <li>A default, element-by-element approach.</li> <li>An optimized version that leverages the GNU Scientific Library (GSL).</li> </ul> <p>The specific implementation used is determined at runtime via the configuration file.</p>"},{"location":"task3/intro/#what-you-will-find-in-this-repository","title":"What You Will Find in This Repository","text":"<ul> <li> <p>Source Code (<code>src/</code>):     Contains the C++ source files for generating vectors and computing the vector sum.</p> </li> <li> <p>Header Files (<code>include/</code>):     Provides declarations for the vector sum interface, both implementations (default and GSL-based), and helper functions for file I/O and path manipulations.</p> </li> <li> <p>Configuration Files (<code>config/</code>):     A YAML file (e.g., <code>config.yml</code>) that specifies input file paths, the number of elements (N), the scalar multiplier (a), output options, and the implementation choice (\"default\" or \"gsl\").</p> </li> <li> <p>Helper Scripts (<code>scripts/</code>): </p> <ul> <li><code>buildProject.sh</code>: A script to build the project from scratch.</li> <li><code>destroyProject.sh</code>: A script to completely clean the project, removing build artifacts and installed commands.</li> </ul> </li> <li> <p>Docker Environment (<code>docker/</code>):     A Dockerfile (e.g., <code>Dockerfile.alma9</code>) is included to provide a ready-to-use development environment with all required dependencies (yaml-cpp, HDF5, and GSL). This ensures that the project can be built and run consistently across different systems.</p> </li> <li> <p>Run Script Template (<code>commands/run.in</code>):     This template is used to generate a wrapper script that is installed to <code>/usr/local/bin</code> for easy invocation of project executables.</p> </li> <li> <p><code>CMakeLists.txt</code>:     The CMake build configuration file for the project.</p> </li> </ul>"},{"location":"task3/intro/#project-structure","title":"Project Structure","text":"<p>The project directory structure is as follows:</p> <pre><code>project/                 # Project root directory\n\u2502 \n\u251c\u2500\u2500 commands/                # Contains the run script template\n\u2502   \u2514\u2500\u2500 run.in                   # Script to run executables with the correct environment\n\u251c\u2500\u2500 config/                  # Configuration files\n\u2502   \u2514\u2500\u2500 config.yml/              # Example configuration file\n\u251c\u2500\u2500 docker/                  # Docker build context\n\u2502   \u2514\u2500\u2500 Dockerfile.alma9         # Dockerfile for building the project\n\u251c\u2500\u2500 include/                 # Header files\n\u2502   \u251c\u2500\u2500 HelperFunctions.hpp      # Common helper functions for file/path operations\n\u2502   \u251c\u2500\u2500 VectorIO.hpp             # I/O helper functions for reading/writing vectors\n\u2502   \u251c\u2500\u2500 VectorSumInterface.hpp   # Abstract interface for vector sum computation\n\u2502   \u251c\u2500\u2500 VectorSumDefault.hpp     # Default (elementwise) vector sum implementation\n\u2502   \u2514\u2500\u2500 VectorSumGSL.hpp         # GSL-based vector sum implementation\n\u251c\u2500\u2500 scripts/                 # Helper scripts\n\u2502   \u251c\u2500\u2500 buildProject.sh          # Script to build the project from scratch\n\u2502   \u2514\u2500\u2500 destroyProject.sh        # Script to completely clean the project\n\u251c\u2500\u2500 src/                     # Source code files\n\u2502   \u251c\u2500\u2500 generateVectors.cpp      # Code to generate input vectors (supports txt/dat/h5)\n\u2502   \u2514\u2500\u2500 vectorSum.cpp            # Code to compute vector sum (selects implementation at runtime)\n\u251c\u2500\u2500 CMakeLists.txt           # CMake build configuration file\n\u2514\u2500\u2500 README.md                # Project documentation\n</code></pre> <p>The detailed documentation for each component is provided in a respective sections of this documentation.</p>"},{"location":"task3/vector_io/","title":"File I/O (text, binary and HDF5)","text":"<p>All vector\u2010file operations live in <code>VectorIO.hpp</code>. Two inline functions, <code>read_vector</code> and <code>write_vector</code>, dispatch on the file extension (via <code>get_extension()</code>) to the correct I/O path.</p>"},{"location":"task3/vector_io/#write_vector","title":"<code>write_vector</code>","text":"<pre><code>inline bool write_vector(\n    const std::string &amp;filename,\n    const std::vector&lt;double&gt; &amp;vec\n);\n</code></pre> <ul> <li> <p>Determine the extension of the file and its size</p> <pre><code>size_t N = vec.size();\nstd::string ext = get_extension(filename);\n</code></pre> </li> <li> <p>If the file is a <code>.txt</code> file</p> <pre><code>std::ofstream out_file(filename);\nfor (size_t i = 0; i &lt; N; ++i) {\n    out_file &lt;&lt; vec[i] &lt;&lt; \"\\n\";\n}\nout_file.close();\nreturn true;\n</code></pre> </li> <li> <p>If the file is a <code>.dat</code> file:</p> <pre><code>std::ofstream out_file(filename, std::ios::binary);\nout_file.write(\n    reinterpret_cast&lt;const char*&gt;(vec.data()),\n    N * sizeof(double)\n);\nout_file.close();\nreturn true;\n</code></pre> </li> <li> <p>If the file is an HDF5 file:</p> <pre><code>H5::H5File file(filename, H5F_ACC_TRUNC);\nhsize_t dims[1] = { N };\nH5::DataSpace dataspace(1, dims);\nH5::DataSet dataset = file.createDataSet(\n    \"d\", H5::PredType::NATIVE_DOUBLE, dataspace\n);\ndataset.write(vec.data(), H5::PredType::NATIVE_DOUBLE);\nfile.close();\nreturn true;\n</code></pre> </li> </ul> <p>Any unsupported extension triggers an error message and a <code>false</code> return.</p>"},{"location":"task3/vector_io/#read_vector","title":"<code>read_vector</code>","text":"<pre><code>inline bool read_vector(\n    const std::string &amp;filename,\n    size_t N,\n    std::vector&lt;double&gt; &amp;vec\n);\n</code></pre> <ul> <li> <p>Determine the extension of the file and its size</p> <pre><code>std::string ext = get_extension(filename);\n</code></pre> </li> <li> <p>If the file is a <code>.txt</code> file</p> <pre><code>std::ifstream in_file(filename);\nvec.resize(N);\nfor (size_t i = 0; i &lt; N; ++i) {\n    in_file &gt;&gt; vec[i];\n    if (in_file.fail()) return false;\n}\nin_file.close();\nreturn true;\n</code></pre> </li> <li> <p>If the file is a <code>.dat</code> file:</p> <pre><code>std::ifstream in_file(filename, std::ios::binary);\nvec.resize(N);\nin_file.read(reinterpret_cast&lt;char*&gt;(vec.data()), N * sizeof(double));\nif (in_file.gcount() != static_cast&lt;std::streamsize&gt;(N * sizeof(double)))\n    return false;\nin_file.close();\nreturn true;\n</code></pre> </li> <li> <p>If the file is an HDF5 file:</p> <pre><code>H5::H5File file(filename, H5F_ACC_RDONLY);\nH5::DataSet dataset = file.openDataSet(ds_name);\ndataset.read(vec.data(), H5::PredType::NATIVE_DOUBLE);\nfile.close();\nreturn true;\n</code></pre> </li> </ul> <p>On any unsupported extension or I/O error, an error is logged to <code>std::cerr</code> and the function returns <code>false</code>.</p> <p>These helpers are invoked by <code>generateVectors.cpp</code> when producing the input files and by <code>vectorSum.cpp</code> when reading and writing vectors for the sum operation.</p>"},{"location":"task3/vector_sum/","title":"Vector sum implementations","text":"<p>The vector sum operation  </p> \\[ d = a \\cdot x + y, \\] <p>is implemented via a polymorphic interface in C++. This allows seamless switching between a simple element-wise loop and a GSL-optimized version.</p>"},{"location":"task3/vector_sum/#common-interface","title":"Common interface","text":"<p>All implementations derive from an abstract base class <code>VectorSumInterface</code>, declared in <code>VectorSumInterface.hpp</code>:</p> VectorSumInterface.hpp<pre><code>class VectorSumInterface {\npublic:\n    virtual ~VectorSumInterface() {}\n\n    /// Compute d = a*x + y.\n    virtual void compute_sum(\n        const std::vector&lt;double&gt;&amp; x,\n        const std::vector&lt;double&gt;&amp; y,\n        double a,\n        std::vector&lt;double&gt;&amp; d\n    ) = 0;\n};\n</code></pre> <p>This enforces a uniform method signature across all concrete classes.</p>"},{"location":"task3/vector_sum/#default-element-by-element-implementation","title":"Default (element-by-element) implementation","text":"<p>The class <code>VectorSumDefault</code> provides the straightforward loop-based approach. Its code is in <code>VectorSumDefault.hpp</code>:</p> VectorSumDefault.hpp<pre><code>class VectorSumDefault : public VectorSumInterface {\npublic:\n    void compute_sum(\n        const std::vector&lt;double&gt;&amp; x,\n        const std::vector&lt;double&gt;&amp; y,\n        double a,\n        std::vector&lt;double&gt;&amp; d\n    ) override {\n        size_t N = x.size();\n        d.resize(N);\n        for (size_t i = 0; i &lt; N; ++i) {\n            d[i] = a * x[i] + y[i];\n        }\n    }\n};\n</code></pre> <p>This version requires only the C++ standard library and works reliably for all vector sizes.</p>"},{"location":"task3/vector_sum/#gsl-based-implementation","title":"GSL-based implementation","text":"<p>For larger vectors or performance-sensitive scenarios, <code>VectorSumGSL</code> uses the GNU Scientific Library. Its implementation resides in <code>VectorSumGSL.hpp</code>:</p> VectorSumGSL.hpp<pre><code>#include &lt;gsl/gsl_vector.h&gt;\n#include &lt;gsl/gsl_blas.h&gt;\n\nclass VectorSumGSL : public VectorSumInterface {\npublic:\n    void compute_sum(\n        const std::vector&lt;double&gt;&amp; x,\n        const std::vector&lt;double&gt;&amp; y,\n        double a,\n        std::vector&lt;double&gt;&amp; d\n    ) override {\n        size_t N = x.size();\n        d.resize(N);\n\n        // Allocate GSL vectors\n        gsl_vector* vx = gsl_vector_alloc(N);\n        gsl_vector* vy = gsl_vector_alloc(N);\n        gsl_vector* vd = gsl_vector_alloc(N);\n\n        // Copy data into GSL vectors\n        for (size_t i = 0; i &lt; N; ++i) {\n            gsl_vector_set(vx, i, x[i]);\n            gsl_vector_set(vy, i, y[i]);\n        }\n\n        // Initialize vd = y\n        gsl_vector_memcpy(vd, vy);\n        // Compute vd = a * vx + 1.0 * vd  \u21d2  d = a*x + y\n        gsl_vector_axpby(a, vx, 1.0, vd);\n\n        // Copy result back to std::vector\n        for (size_t i = 0; i &lt; N; ++i) {\n            d[i] = gsl_vector_get(vd, i);\n        }\n\n        // Free GSL resources\n        gsl_vector_free(vx);\n        gsl_vector_free(vy);\n        gsl_vector_free(vd);\n    }\n};\n</code></pre> <p>This leverages gsl_vector_axpby, which internally can use optimized BLAS routines.</p>"},{"location":"task3/vector_sum/#runtime-selection-of-implementation","title":"Runtime selection of implementation","text":"<p>At execution, the implementation is chosen based on the implementation field in the <code>YAML</code> config. In <code>vectorSum.cpp</code>, a <code>std::unique_ptr&lt;VectorSumInterface&gt;</code> is created as either <code>VectorSumDefault</code> or <code>VectorSumGSL</code>:</p> vectorSum.cpp<pre><code>std::unique_ptr&lt;VectorSumInterface&gt; vs;\nif (implementation == \"default\") {\n    vs.reset(new VectorSumDefault());\n}\nelse if (implementation == \"gsl\") {\n    vs.reset(new VectorSumGSL());\n}\nelse {\n    std::cerr &lt;&lt; \"Unsupported implementation: \" &lt;&lt; implementation &lt;&lt; std::endl;\n    return 1;\n}\n\n// Compute the sum\nstd::vector&lt;double&gt; d;\nvs-&gt;compute_sum(x, y, a, d);\n</code></pre> <p>This pattern ensures that the rest of the codebase treats both cases uniformly.</p>"},{"location":"task4/build/","title":"How to Build the Project","text":""},{"location":"task4/build/#step-by-step-instructions","title":"Step-by-Step Instructions","text":"<p>Assuming you already have the project available locally and your Docker container is running with <code>/workspace</code> set as the project root, follow these steps to build the project:</p> <ol> <li> <p>Navigate to the Project Root:</p> <p>Ensure you are in the project root directory (i.e., <code>/workspace</code>). You can verify this by running:</p> <pre><code>pwd\n</code></pre> <p>It should display <code>/workspace</code> (the project root).</p> </li> <li> <p>Run the Build Script:</p> <p>From the project root, execute the build script to configure and compile the project:</p> <pre><code>bash ./scripts/buildProject.sh\n</code></pre> <p>This script will:</p> <ul> <li>Create a build directory </li> <li>Change into the build directory.</li> <li>Run CMake to generate the build system.</li> <li>Invoke make to compile the source code into executables.</li> <li>Return you to the project root once the build is complete.</li> </ul> </li> <li> <p>Run the Executables:</p> <p>You can now run the executables using the <code>run</code> command from anywhere. For example:</p> <ul> <li> <p>Save sampled function and compute integral (compiled language):</p> <pre><code>run computeIntegral &lt;N&gt; &lt;x_inf&gt; &lt;x_sup&gt; \n</code></pre> <p>or </p> <pre><code>run computeIntegral &lt;path/to/config.yml&gt;\n</code></pre> </li> <li> <p>Read sampled function and compute integral (interpreted language):</p> <pre><code>run compute_integral --N &lt;N&gt; --precision &lt;precision&gt; \n</code></pre> </li> </ul> <p>More details on properly using the executables are provided in the subsequent sections of this documentation. </p> </li> </ol>"},{"location":"task4/code_overview/","title":"Code overview","text":"<p>This section explains how the C++ tool computeIntegral performs sampling and integration, and how the Python script compute_integral.py validates those results.</p>"},{"location":"task4/code_overview/#sampling-and-integration-in-c","title":"Sampling and integration in C++","text":"<p>You run the C++ executable by supplying three options: the number of points (<code>N</code>), the lower limit (<code>x_inf</code>), and the upper limit (<code>x_sup</code>):</p> <pre><code>run computeIntegral 1000  0.0 3.14159\n</code></pre> <p>where <code>1000</code> is the number of sampling points, <code>0.0</code> is the lower limit, and <code>3.14159</code> is the upper limit.</p> <p>Alternatively, you can use the <code>config/config.yml</code> file to specify these parameters.</p> <pre><code>N: 1000\nx_inf: 0.0\nx_sup: 1.0\n</code></pre> <p>Internally, <code>computeIntegral.cpp</code> begins by parsing these arguments using:</p> <pre><code>InputParameters params = readInputs(argc, argv);\n</code></pre> <p>Here, <code>readInputs()</code> constructs an <code>InputParameters</code> struct:</p> <pre><code>struct InputParameters {\n    int N;\n    double x_inf;\n    double x_sup;\n};\n</code></pre> <p>Next, the program writes the sample points to <code>data/data_&lt;N&gt;.txt</code> using a loop:</p> <pre><code>std::ofstream out = openOutputFile(\"data/data_\" + std::to_string(params.N) + \".txt\");\n\ndouble dx = (params.x_sup - params.x_inf) / (params.N - 1);\nfor (int i = 0; i &lt; params.N; ++i) {\n    double x = params.x_inf + i * dx;\n    double y = CosExpFunction()(x);\n    out &lt;&lt; std::fixed &lt;&lt; std::setprecision(16)\n        &lt;&lt; x &lt;&lt; \" \" &lt;&lt; y &lt;&lt; \"\\n\";\n}\nout.close();\n</code></pre> <p>After sampling, these data feed into three integration routines. An Integrator object is created and its methods are invoked as follows:</p> <pre><code>Integrator integrator;\n\ndouble I_trapz  = integrator.integrateTrapz(params.x_inf, params.x_sup, params.N);\ndouble I_simp   = integrator.integrateSimpson(params.x_inf, params.x_sup, params.N);\ndouble I_romb   = integrator.integrateRomberg(params.x_inf, params.x_sup, 4, 1e-12);\n</code></pre> <p>These calls implement the Trapezoidal rule, Simpson\u2019s rule, and Romberg integration respectively (see detailed pages for algorithmic specifics). Each computed value is then written to its own file:</p> <pre><code>saveIntegralResult(DATA_DIR, \"Trapz\", params.N, OUTPUT_PRECISION, I_trapz);\nsaveIntegralResult(DATA_DIR, \"Simpson\", params.N, OUTPUT_PRECISION, I_simp);\nsaveIntegralResult(DATA_DIR, \"Romberg\", params.N, OUTPUT_PRECISION, I_romb);\n</code></pre>"},{"location":"task4/code_overview/#validation-with-python","title":"Validation with Python","text":"<p>To compare these results, you execute the Python script:</p> <pre><code>run compute_integral --N &lt;N&gt; --precision &lt;precision&gt; \n</code></pre> <p>Within <code>compute_integral.py</code>, the script loads the sampled data and reads the C++ results from the output files. </p> <p>The script then recomputes each integral in Python:</p> <pre><code>integral_trapz = trapezoid(fx_subset, x_subset)\nintegral_simpson = simpson(fx_subset, x_subset)\nintegral_romberg = romberg(interp1d(x_subset, fx_subset, kind='cubic', fill_value=\"extrapolate\"), A, B, tol=ROMBERG_TOL, rtol=ROMBERG_RTOL, divmax=ROMBERG_DIVMAX)\n</code></pre>"},{"location":"task4/docker/","title":"Docker Installation and Setup for Task 4","text":""},{"location":"task4/docker/#overview","title":"Overview","text":"<p>This guide explains how to build and run the Docker container that provides a virtualized environment for Task 4 of the Scientific Computing for Physics Students project. The container is based on AlmaLinux9 and includes all required development tools and libraries (yaml-cpp, HDF5, GSL, etc.), as well as a Python environment managed by Miniconda.</p> <p>Prerequisites</p> <ul> <li>Docker must be installed.</li> <li>Follow the Docker installation instructions in Task\u00a01 before proceeding with Task\u00a04.</li> </ul>"},{"location":"task4/docker/#building-the-docker-image","title":"Building the Docker Image","text":"<p>The Dockerfile is located in the <code>docker/</code> directory and is named <code>Dockerfile.alma9</code>.</p> <ol> <li>Open a terminal and navigate to the project root.</li> <li> <p>Run the following command to build the Docker image:</p> <pre><code>docker build -t sci-comp-task4 -f docker/Dockerfile.alma9 .\n</code></pre> <ol> <li><code>-t sci-comp-task4</code> tags the image with the name <code>sci-comp-task4</code>.</li> <li><code>-f docker/Dockerfile.alma9</code> specifies the location of the Dockerfile.</li> <li>The final <code>.</code> sets the build context to the project root.</li> </ol> </li> </ol>"},{"location":"task4/docker/#running-the-docker-container","title":"Running the Docker Container","text":"<p>Once the image is built, you can start a container interactively with:</p> <pre><code>docker run -it -v \"$(pwd):/workspace\" sci-comp-task4\n</code></pre> <ul> <li><code>-it</code>: Runs the container in interactive mode with a TTY.</li> <li><code>-v \"$(pwd):/workspace\"</code>: Mounts the current project root into the container at /workspace.</li> <li><code>sci-comp-task4</code>: Specifies the image name.</li> </ul> <p>Inside the container, your working directory will be <code>/workspace</code> (which is your project root), and all necessary tools and libraries will be available.</p>"},{"location":"task4/integration/","title":"Trapezoidal and Simpson integration","text":"<p>This page documents how the <code>Integrator</code> class implements the Trapezoidal and Simpson\u2019s rules for numerical integration. All code resides in <code>include/Integrator.hpp</code>.</p>"},{"location":"task4/integration/#trapezoidal-rule","title":"Trapezoidal Rule","text":"<p>The trapezoidal rule approximates the integral</p> \\[ \\int_a^b f(x) \\, dx  \\] <p>by summing the areas of trapezoids under the curve. In <code>Integrator::integrateTrapz()</code>:</p> Integrator.hpp<pre><code>// Trapezoidal rule integration.\ndouble integrateTrapz(double a, double b, int n) const {\n    if (n &lt; 2) {\n        throw std::invalid_argument(\n            \"Number of sampling points must be at least 2.\");\n    }\n    double h = (b - a) / (n - 1);\n    double sum = 0.5 * (function(a) + function(b));\n    for (int i = 1; i &lt; n - 1; ++i) {\n        double xi = a + i * h;\n        sum += function(xi);\n    }\n    return sum * h;\n}\n</code></pre>"},{"location":"task4/integration/#simpsons-rule","title":"Simpson's Rule","text":"<p>Simpson\u2019s rule provides a more accurate approximation by using parabolic segments. It requires an odd number of sampling points. In <code>Integrator::integrateSimpson()</code>:</p> Integrator.hpp<pre><code>// Simpson's rule integration.\ndouble integrateSimpson(double a, double b, int n) const {\n    // Ensure at least 3 points (n odd).\n    if (n &lt; 3) {\n        throw std::invalid_argument(\n            \"Number of sampling points must be at least 3.\");\n    }\n    if (n % 2 == 0) {\n        ++n;  // Make n odd by adding one point\n    }\n    double h = (b - a) / (n - 1);\n    double sum = function(a) + function(b);\n    for (int i = 1; i &lt; n - 1; ++i) {\n        double xi = a + i * h;\n        if (i % 2 == 0) {\n            sum += 2 * function(xi);\n        } else {\n            sum += 4 * function(xi);\n        }\n    }\n    return (h / 3.0) * sum;\n}\n</code></pre>"},{"location":"task4/intro/","title":"Introduction to Task 4","text":"<p>In this task, we study numerical integration of the function</p> \\[ f(x) = e^{x} \\, \\cos(x) \\] <p>over a chosen interval (e.g., \\([0, \\pi]\\)). The goal is to compare three classical methods\u2014Trapezoidal rule, Simpson\u2019s rule, and Romberg integration. We first describe the mathematical foundations, then explain how they are implemented in C++, and finally show how a Python script validates and visualizes the results.</p>"},{"location":"task4/intro/#mathematical-background","title":"Mathematical background","text":""},{"location":"task4/intro/#trapezoidal-rule","title":"Trapezoidal rule","text":"<p>The trapezoidal rule approximates the integral</p> \\[ \\int_a^b f(x) \\, dx \\] <p>by subdividing the interval \\([a, b]\\) into \\(N-1\\) subintervals of equal width \\(h = (b-a)/(N-1)\\), and approximating the area under the curve as a series of trapezoids:</p> \\[ I_{\\text{trapz}} = h \\left[\\frac{1}{2} f(a) + \\sum_{i=1}^{N-2} f(a + i h) + \\frac{1}{2} f(b) \\right] \\] <p>This method has a global error that scales as \\(O(h^2)\\), where \\(h\\) is the step size.</p>"},{"location":"task4/intro/#simpsons-rule","title":"Simpson's rule","text":"<p>Simpson\u2019s rule improves accuracy by using parabolic segments. It requires an odd number of sampling points \\(N\\). The integral is approximated as:</p> \\[ I_{\\text{simp}} = \\frac{h}{3} \\left[ f(a) + 4 \\sum_{i=1, \\text{odd}}^{N-2} f(a + i h) + 2 \\sum_{i=2, \\text{even}}^{N-3} f(a + i h) + f(b) \\right] \\] <p>This method has a global error that scales as \\(O(h^4)\\), making it significantly more accurate than the trapezoidal rule for the same number of points.\u00f9</p>"},{"location":"task4/intro/#romberg-integration","title":"Romberg integration","text":"<p>Romberg integration combines the trapezoidal rule with Richardson extrapolation to achieve high accuracy. It uses repeated trapezoidal estimates with decreasing step sizes \\(h_k = (b-a)/2^k\\) and builds a table of estimates. The Romberg table is constructed as follows:</p> \\[ R_{k,0} = T(h_k) \\] <p>with \\(T(h_k)\\) being the trapezoidal estimate with step size \\(h_k\\). Extrapolation then gives:</p> \\[ R_{k,j} = R_{k,j-1} + \\frac{R_{k,j-1} - R_{k-1,j-1}}{4^j - 1} \\] <p>for \\(j=1,2,\\ldots,k\\).</p>"},{"location":"task4/intro/#c-implementation","title":"C++ Implementation","text":"<p>The C++ program <code>computeIntegral</code> executes the following steps:</p> <ol> <li>Sampling: Generates \\(N\\) evenly spaced points \\(x_i\\) in \\([a, b]\\) and evaluates \\(f(x_i)\\).</li> <li>Integration: Applies the three numerical integration methods (trapezoidal, Simpson's, and Romberg) to compute the integral over the specified interval.</li> <li>Output: Writes the sampled points and integration results to files.</li> </ol>"},{"location":"task4/intro/#comparison-with-python","title":"Comparison with Python","text":"<p>To confirm correctness and explore convergence behavior, a Python script:</p> <ol> <li>Loads the sampled data from the C++ output files.</li> <li>Recomputes the integrals using <code>scipy.integrate.trapezoid</code> and <code>scipy.integrate.simpson</code>.</li> <li>Implements Romberg integration manually.</li> <li>Computes the relative errors for each method with respect to the analytical integral value.</li> <li>Computes the absolute errors between C++ and Python results.</li> </ol> <p>Results confirm theoretical error rates and demonstrate agreement between C++ and Python implementations.</p>"},{"location":"task4/intro/#what-you-will-find-in-this-repository","title":"What you will find in this repository","text":"<ul> <li> <p>Source Code (<code>src/</code>):     Contains the C++ source files for computing the integral using the three methods: trapezoidal, Simpson's, and Romberg.</p> </li> <li> <p>Header Files (<code>include/</code>):     Provides declarations for the integration methods, helper functions for file I/O, and path manipulations.</p> </li> <li> <p>Python Scripts (<code>python/</code>):     Contains the Python script for validating and visualizing the results of the C++ integration methods.</p> </li> <li> <p>Configuration Files (<code>config/</code>):     A YAML file (e.g., <code>config.yml</code>) that specifies the integration parameters, including the function to integrate, the interval, the number of points (N), and output options.</p> </li> <li> <p>Helper Scripts (<code>scripts/</code>): </p> <ul> <li><code>buildProject.sh</code>: A script to build the project from scratch.</li> <li><code>destroyProject.sh</code>: A script to completely clean the project, removing build artifacts and installed commands.</li> </ul> </li> <li> <p>Docker Environment (<code>docker/</code>):     A Dockerfile (e.g., <code>Dockerfile.alma9</code>) is included to provide a ready-to-use development environment with all required dependencies.</p> </li> <li> <p>Run Script Template (<code>commands/run.in</code>):     This template is used to generate a wrapper script that is installed to <code>/usr/local/bin</code> for easy invocation of project executables.</p> </li> <li> <p><code>CMakeLists.txt</code>:     The CMake build configuration file for the project.</p> </li> </ul>"},{"location":"task4/intro/#project-structure","title":"Project Structure","text":"<p>The project directory structure is as follows:</p> <pre><code>project/                 # Project root directory\n\u2502 \n\u251c\u2500\u2500 commands/                # Contains the run script template\n\u2502   \u2514\u2500\u2500 run.in                   # Script to run executables with the correct environment\n\u251c\u2500\u2500 config/                  # Configuration files\n\u2502   \u2514\u2500\u2500 config.yml/              # Example configuration file\n\u251c\u2500\u2500 docker/                  # Docker build context\n\u2502   \u2514\u2500\u2500 Dockerfile.alma9         # Dockerfile for building the project\n\u251c\u2500\u2500 include/                 # Header files\n\u2502   \u251c\u2500\u2500 HelperFunctions.hpp      # Common helper functions for file/path operations\n\u2502   \u251c\u2500\u2500 Function.hpp             # Declaration of the function to integrate\n\u2502   \u251c\u2500\u2500 Integrator.hpp           # Abstract interface for integration methods\n\u251c\u2500\u2500 python/                  # Python scripts\n\u2502   \u251c\u2500\u2500 compute_integral.py      # Python script for computing and validating integrals\n\u251c\u2500\u2500 scripts/                 # Helper scripts\n\u2502   \u251c\u2500\u2500 buildProject.sh          # Script to build the project from scratch\n\u2502   \u2514\u2500\u2500 destroyProject.sh        # Script to completely clean the project\n\u251c\u2500\u2500 src/                     # Source code files\n\u2502   \u251c\u2500\u2500 computeIntegral.cpp      # Code to compute the integral using the three methods\n\u251c\u2500\u2500 CMakeLists.txt           # CMake build configuration file\n\u2514\u2500\u2500 README.md                # Project documentation\n</code></pre>"},{"location":"task4/python/","title":"Comparison with Python","text":"<p>This page documents the Python script <code>compute_integral.py</code>, which re-runs numerical integrations on data generated by the C++ program and compares those results against the C++ outputs.</p>"},{"location":"task4/python/#numerical-integration-in-python","title":"Numerical integration in Python","text":"<p>The script imports:</p> <pre><code>from scipy.interpolate import interp1d\nfrom scipy.integrate import trapezoid, simpson\n</code></pre> <p>The trapezoidal rule is implemented using <code>scipy.integrate.trapezoid</code>, and Simpson's rule is implemented using <code>scipy.integrate.simpson</code>. Instead, Romberg integration is not directly available in SciPy, so we implement it manually.</p>"},{"location":"task4/python/#romberg-integration-in-python","title":"Romberg integration in Python","text":"<p>The Romberg integration method is implemented in Python as follows:</p> <pre><code># ============================\n# Romberg integration function\n# ============================\ndef romberg(f, a, b, tol=ROMBERG_TOL, rtol=ROMBERG_RTOL, divmax=ROMBERG_DIVMAX):\n    \"\"\"\n    Compute the Romberg integration of function f on the interval [a, b]\n    using the trapezoidal rule and Richardson extrapolation.\n    \"\"\"\n    R = []  # Romberg table: a list of lists\n    R.append([(b - a) * (f(a) + f(b)) / 2.0])\n    for i in range(1, divmax):\n        n_intervals = 2**i\n        h = (b - a) / n_intervals\n        sum_ = 0.0\n        for k in range(1, n_intervals, 2):\n            sum_ += f(a + k * h)\n        R0 = 0.5 * R[i-1][0] + h * sum_\n        row = [R0]\n        for j in range(1, i+1):\n            factor = 4**j\n            extrap = row[j-1] + (row[j-1] - R[i-1][j-1]) / (factor - 1.0)\n            row.append(extrap)\n        R.append(row)\n        if i &gt; 0 and abs(R[i][i] - R[i-1][i-1]) &lt; tol:\n            return R[i][i]\n    return R[-1][-1]\n</code></pre>"},{"location":"task4/python/#comparison-with-c-results","title":"Comparison with C++ results","text":"<p>The script reads the sampled data from the C++ output files and computes the integrals using the same methods as in C++. The results are then compared:</p> <pre><code># Load sampled data from C++ output files\ndata = np.loadtxt(cpp_data_file)\n</code></pre> <p>The script then computes the integrals:</p> <pre><code>N_AB = int(round((B - A) / dx)) + 1\nintegral_trapz = trapezoid(fx_subset, x_subset)\nintegral_simpson = simpson(fx_subset, x_subset)\nf_interp = interp1d(x_subset, fx_subset, kind='cubic', fill_value=\"extrapolate\")\nintegral_romberg = romberg(f_interp, A, B, tol=ROMBERG_TOL, rtol=ROMBERG_RTOL, divmax=ROMBERG_DIVMAX)\n</code></pre> <p>Finally, the script computes the absolute errors between C++ and Python results:</p> <pre><code># Compute absolute differences between Python and C++ results\nabs_diff_trapz = abs(integral_trapz - cpp_integral_trapz)\nabs_diff_simpson = abs(integral_simpson - cpp_integral_simpson)\nabs_diff_romberg = abs(integral_romberg - cpp_integral_romberg)\n</code></pre>"},{"location":"task4/results/","title":"Results and discussion","text":"<p>This page presents and interprets the comparison plots for the three integration methods: Trapezoidal rule, Simpson\u2019s rule, and Romberg integration. Figures show:</p> <ol> <li>Absolute differences between C++ and Python results.</li> <li>Relative errors in the C++ implementation versus analytic solution.</li> <li>Relative errors in the Python implementation versus analytic solution.</li> </ol> <p>All plots use a log\u2013log scale and vary the number of sampling points \\(N\\) from \\(2^3\\) to \\(2^{23}\\).</p>"},{"location":"task4/results/#relative-errors-c-vs-analytic-solution","title":"Relative errors: C++ vs Analytic Solution","text":"<p>The trapezoidal rule decays as \\(O(h^2)\\), where \\(h\\) is the step size. In the log-log plot, this appears as a straight line with slope \\(-2\\). </p> <p>Simpson\u2019s rule decays as \\(O(h^4)\\), appearing as a straight line with slope \\(-4\\) until it reaches machine precision around \\(N \\approx 2^{12}\\).</p> <p>Romberg integration instead achieves machine precision for essentially all \\(N\\) values, showing rapid convergence to the analytic solution.</p> <p></p>"},{"location":"task4/results/#relative-errors-python-vs-analytic-solution","title":"Relative errors: Python vs Analytic Solution","text":"<p>The Python implementations mirror the C++ convergence rates. Slightly larger absolute errors at small \\(N\\) for Romberg's Python implementation reflect differences in floating\u2011point routines and array handling in NumPy.</p> <p></p>"},{"location":"task4/results/#absolute-differences-c-vs-python","title":"Absolute differences: C++ vs Python","text":"<p>Romberg differences plateau at around \\(10^{-15}\\), indicating both implementations reach machine precision and agree within rounding error. Simpson and Trapz differences reach \\(10^{-13}\\) for large \\(N\\). Small deviations are due to differences in loop ordering and floating\u2011point summation between C++ and NumPy.</p> <p>The two languages produce numerically consistent results at the level of machine precision.</p> <p></p>"},{"location":"task4/romberg/","title":"Romberg integration","text":"<p>This page explains the Romberg integration method implemented in <code>Integrator::integrateRomberg()</code>, which uses Richardson extrapolation on trapezoidal estimates to achieve high accuracy.</p> <p>All code is found in <code>include/Integrator.hpp</code>.</p>"},{"location":"task4/romberg/#method-outline","title":"Method outline","text":"<p>Romberg integration combines the trapezoidal rule with Richardson extrapolation to improve accuracy. It builds a table of estimates, refining them iteratively:</p> \\[ R_{k,0}=T(h_k) \\] <p>with \\(h_k=(b-a)/2^k\\) and \\(T(h_k)\\) being the trapezoidal estimate with step size \\(h_k\\). Extrapolation then gives:</p> \\[ R_{k,j} = R_{k,j-1} + \\frac{R_{k,j-1} - R_{k-1,j-1}}{4^j - 1} \\] <p>for \\(j=1,2,\\ldots,k\\).</p>"},{"location":"task4/romberg/#implementation-details","title":"Implementation details","text":"<p>The implementation in <code>Integrator::integrateRomberg()</code> constructs the Romberg table and performs extrapolation:</p> Integrator.hpp<pre><code>// Romberg integration to desired depth 'm'.\ndouble integrateRomberg(double a, double b, int maxIter = 5, double tol = 1e-12) const {\n    // Allocate a Romberg table R with dimensions maxIter x maxIter.\n    std::vector&lt;std::vector&lt;double&gt;&gt; R(maxIter, std::vector&lt;double&gt;(maxIter, 0.0));\n\n    // Initial trapezoidal rule: use 2^0 segments =&gt; n = 2 points.\n    int n = 2;\n    R[0][0] = integrateTrapz(a, b, n);\n\n    // Build the Romberg table.\n    for (int i = 1; i &lt; maxIter; ++i) {\n        // Use 2^i segments, which means n = 2^i + 1 sampling points.\n        n = (1 &lt;&lt; i) + 1;  // 1&lt;&lt;i computes 2^i.\n        R[i][0] = integrateTrapz(a, b, n);\n        // Apply Richardson extrapolation.\n        for (int j = 1; j &lt;= i; ++j) {\n            double factor = std::pow(4.0, j);\n            R[i][j] = R[i][j-1] + (R[i][j-1] - R[i-1][j-1]) / (factor - 1.0);\n        }\n        // Check for convergence between the last diagonal elements.\n        if (std::fabs(R[i][i] - R[i-1][i-1]) &lt; tol) {\n            return R[i][i];\n        }\n    }\n    return R[maxIter-1][maxIter-1];\n}\n</code></pre>"},{"location":"task4/sampling/","title":"Sampling and Data I/O","text":"<p>This page describes how the C++ executable <code>computeIntegral</code> reads input parameters, generates sampling points, evaluates the function, and writes data to disk in a text file.</p>"},{"location":"task4/sampling/#input-parameter-handling","title":"Input parameter handling","text":"<p>At program start, command\u2011line arguments are parsed by <code>readInputs</code>, returning an <code>InputParameters</code> struct:</p> <pre><code>InputParameters params;\nparams = readInputs(argc, argv);\n</code></pre> <ul> <li><code>params.N</code> specifies the number of sampling points.</li> <li><code>params.x_inf</code>, <code>params.x_sup</code>: lower and upper bounds for the integration.</li> </ul> <p>Errors during parsing throw an exception, caught and reported to <code>std::cerr</code>.</p>"},{"location":"task4/sampling/#ensuring-output-directory","title":"Ensuring output directory","text":"<p>Before writing any data, the directory <code>./data</code> is created (if missing) via:</p> <pre><code>createDataDirectory(\"./data\");\n</code></pre> <p>This helper wraps <code>mkdir -p</code> and throws on failure.</p>"},{"location":"task4/sampling/#sampling","title":"Sampling","text":"<p>The function under study is</p> <pre><code>class CosExpFunction : public Function {\n  double operator()(double x) const override {\n    return std::cos(x) * std::exp(x);\n  }\n};\n</code></pre> <p>Once an instance is created:</p> computeIntegral.cpp<pre><code>std::ofstream outFile = openOutputFile(DATA_FILE);\nCosExpFunction f;\ndouble dx = (params.x_sup - params.x_inf) / (params.N - 1);\nfor (int i = 0; i &lt; params.N; ++i) {\n    double x = params.x_inf + i * dx;\n    outFile &lt;&lt; std::fixed &lt;&lt; std::setprecision(OUTPUT_PRECISION)\n            &lt;&lt; x &lt;&lt; \" \" &lt;&lt; f(x) &lt;&lt; \"\\n\";\n}\noutFile.close();\n</code></pre> <p>After completion, the program prints the number of points and file location.</p>"},{"location":"task5/build/","title":"How to Build the Project","text":""},{"location":"task5/build/#step-by-step-instructions","title":"Step-by-Step Instructions","text":"<p>Assuming you already have the project available locally and your Docker container is running with <code>/workspace</code> set as the project root, follow these steps to build the project:</p> <ol> <li> <p>Navigate to the Project Root:</p> <p>Ensure you are in the project root directory (i.e., <code>/workspace</code>). You can verify this by running:</p> <pre><code>pwd\n</code></pre> <p>It should display <code>/workspace</code> (the project root).</p> </li> <li> <p>Run the Build Script:</p> <p>From the project root, execute the build script to configure and compile the project:</p> <pre><code>bash ./scripts/buildProject.sh\n</code></pre> <p>This script will:</p> <ul> <li>Create a build directory </li> <li>Change into the build directory.</li> <li>Run CMake to generate the build system.</li> <li>Invoke make to compile the source code into executables.</li> <li>Return you to the project root once the build is complete.</li> </ul> </li> <li> <p>Run the Executables:</p> <p>You can now run the executables using the <code>run</code> command from anywhere. For example:</p> <ul> <li> <p>Compute the sum of elements in a vector using different methods:</p> <pre><code>run computeSum\n</code></pre> </li> <li> <p>Perform daxpy operation (d=a*x + y) with random vectors:</p> <pre><code>run testDaxpy\n</code></pre> <p>or, to override default parameters:</p> <pre><code>run testDaxpy &lt;N&gt; &lt;a&gt; &lt;n_iter&gt;\n</code></pre> </li> </ul> <p>More details on properly using the executables are provided in the subsequent sections of this documentation. </p> </li> </ol>"},{"location":"task5/daxpy_overview/","title":"Summing Vectors with DAXPY","text":"<p>In Task 5b, we extend the vector summation work to the DAXPY operation</p> \\[ d = a \\cdot x + y \\] <p>where both <code>x</code> and <code>y</code> are filled with independently drawn Gaussian (normal) random numbers with mean 0 and standard deviation 1.</p>"},{"location":"task5/daxpy_overview/#random-vector-generation","title":"Random Vector Generation","text":"<p>Random vectors <code>x</code> and <code>y</code> of length <code>n</code> are produced by <code>VectorGenerator.hpp</code>. The generator uses the C++11 <code>&lt;random&gt;</code> library. A simplified excerpt from <code>VectorGenerator.hpp</code> shows the core approach:</p> VectorGenerator.hpp<pre><code>class VectorGenerator {\npublic:\n    /**\n     * @brief Generates a vector of Gaussian random numbers.\n     *\n     * This function returns a vector of size @p N, where each element is randomly generated\n     * from a normal distribution with mean 0 and standard deviation 1.\n     *\n     * @param N The number of elements to generate.\n     * @return std::vector&lt;double&gt; A vector of size @p N with Gaussian-distributed values.\n     */\n    static std::vector&lt;double&gt; generate_gaussian_vector(std::size_t N) {\n        std::vector&lt;double&gt; vec(N);\n        // Seed the random number generator using a random device.\n        static std::random_device rd;\n        static std::mt19937 gen(rd());\n        // Define the normal distribution with mean 0.0 and standard deviation 1.0.\n        std::normal_distribution&lt;double&gt; dist(0.0, 1.0);\n\n        // Fill the vector with random numbers sampled from the Gaussian distribution.\n        for (std::size_t i = 0; i &lt; N; ++i) {\n            vec[i] = dist(gen);\n        }\n        return vec;\n    }\n};\n</code></pre>"},{"location":"task5/daxpy_overview/#daxpy-implementations","title":"DAXPY Implementations","text":"<p>We use the existing Strategy Pattern from Task\u202f3. Both implementations derive from <code>VectorSumInterface</code>.</p>"},{"location":"task5/daxpy_overview/#testing-daxpy","title":"Testing DAXPY","text":"<p>The file <code>TestSuite.hpp</code> provides a template function <code>run_vector_sum_test</code> that executes a sequence of DAXPY operations and collects statistics. A representative snippet from <code>testDaxpy.cpp</code> illustrates its use:</p> <pre><code>int main(int argc, char** argv) {\n    // Parse command-line: n, a, n_iter\n    int n      = 1000000;\n    double a   = 3.0;\n    int n_iter = 100;\n\n    VectorSumDefault default_sum;\n    run_vector_sum_test(n, a, n_iter, default_sum, \"default\");\n\n    VectorSumGSL gsl_sum;\n    run_vector_sum_test(n, a, n_iter, gsl_sum, \"gsl\");\n\n    return 0;\n}\n</code></pre> <p>Within <code>run_vector_sum_test</code>, each iteration:</p> <ol> <li>Calls <code>generate_gaussian_vector</code> to create random vectors <code>x</code> and <code>y</code>.</li> <li>Executes the DAXPY operation.</li> <li>Computes the sample mean and standard deviation of the results.</li> <li>Record these statistics over all iterations.</li> </ol> <p>After <code>n_iter</code> runs, the suite prints the average mean and RMS values alongside the theoretical expectations:</p> <ul> <li>Expected mean: \\( a \\cdot \\text{mean}(x) + \\text{mean}(y) = 0 \\)</li> <li>Expected RMS: \\( \\sqrt{a^2 + 1} \\)</li> </ul> <p>We consider the test passed if the average sample mean is close to zero and the average sample standard deviation is close to the expected RMS value. The typical tolerance is on the order of the standard error:</p> <ul> <li>Mean tolerance: \\(\\sigma_d / \\sqrt{n}\\)</li> <li>RMS tolerance: \\(\\sigma_d / \\sqrt{2(n-1)}\\)</li> </ul> <p>This test ensures that the DAXPY implementations correctly handle random inputs and produce results consistent with theoretical predictions.</p>"},{"location":"task5/daxpy_overview/#executing-the-tests","title":"Executing the Tests","text":"<p>To build and run the tests, use the standard build script and then:</p> <pre><code>run testDaxpy 1000000 3.0 100\n</code></pre> <p>This command runs the DAXPY tests with: - <code>n = 1000000</code>: Length of the vectors. - <code>a = 3.0</code>: Scalar multiplier. - <code>n_iter = 100</code>: Number of iterations for averaging results.</p> <p>The output summarizes each strategy\u2019s statistical performance, confirming correctness and allowing performance comparison.</p>"},{"location":"task5/docker/","title":"Docker Installation and Setup for Task 5","text":""},{"location":"task5/docker/#overview","title":"Overview","text":"<p>This guide explains how to build and run the Docker container that provides a virtualized environment for Task 5 of the Scientific Computing for Physics Students project. The container is based on AlmaLinux9 and includes all required development tools and libraries (yaml-cpp, HDF5, GSL, etc.), as well as a Python environment managed by Miniconda.</p> <p>Prerequisites</p> <ul> <li>Docker must be installed.</li> <li>Follow the Docker installation instructions in Task\u00a01 before proceeding with Task\u00a05.</li> </ul>"},{"location":"task5/docker/#building-the-docker-image","title":"Building the Docker Image","text":"<p>The Dockerfile is located in the <code>docker/</code> directory and is named <code>Dockerfile.alma9</code>.</p> <ol> <li>Open a terminal and navigate to the project root.</li> <li> <p>Run the following command to build the Docker image:</p> <pre><code>docker build -t sci-comp-task5 -f docker/Dockerfile.alma9 .\n</code></pre> <ol> <li><code>-t sci-comp-task5</code> tags the image with the name <code>sci-comp-task5</code>.</li> <li><code>-f docker/Dockerfile.alma9</code> specifies the location of the Dockerfile.</li> <li>The final <code>.</code> sets the build context to the project root.</li> </ol> </li> </ol>"},{"location":"task5/docker/#running-the-docker-container","title":"Running the Docker Container","text":"<p>Once the image is built, you can start a container interactively with:</p> <pre><code>docker run -it -v \"$(pwd):/workspace\" sci-comp-task5\n</code></pre> <ul> <li><code>-it</code>: Runs the container in interactive mode with a TTY.</li> <li><code>-v \"$(pwd):/workspace\"</code>: Mounts the current project root into the container at /workspace.</li> <li><code>sci-comp-task5</code>: Specifies the image name.</li> </ul> <p>Inside the container, your working directory will be <code>/workspace</code> (which is your project root), and all necessary tools and libraries will be available.</p>"},{"location":"task5/for_gsl_summator/","title":"Naive and GSL Summation Methods","text":"<p>This page documents the two simplest summation strategies: the naive for\u2011loop approach and the GSL-based summator. </p>"},{"location":"task5/for_gsl_summator/#for-loop-summator","title":"For-loop Summator","text":"<p>The straightforward approach accumulates values in the order given. While easy to implement, it is vulnerable to catastrophic cancellation when summing very large and very small magnitudes in sequence.</p> ForLoopSummator.hpp<pre><code>class ForLoopSummator : public Summator {\npublic:\n    double sum(const std::vector&lt;double&gt;&amp; vec) const override {\n        double s = 0.0;\n        for (size_t i = 0; i &lt; vec.size(); ++i) {\n            s += vec[i];\n        }\n        return s;\n    }\n};\n</code></pre> <p>When summing the vector</p> <pre><code>const std::vector&lt;double&gt; vec = {1.0, 1.0e16, -1.0e16, -0.5};\n</code></pre> <p>the accumulator becomes <code>1.0</code>. Then, adding <code>1.0e16</code> results in <code>1.0e16</code>, which is then followed by subtracting <code>1.0e16</code>, leaving the accumulator at <code>0.0</code>. Finally, subtracting <code>0.5</code> yields <code>-0.5</code>, which is far from the true sum of <code>0.5</code>. This shows cancellation of small values against large ones.</p>"},{"location":"task5/for_gsl_summator/#gsl-summator","title":"GSL Summator","text":"<p>To leverage existing library routines, this class wraps the GNU Scientific Library (GSL) summation function. However, <code>gsl_vector_sum</code> internally performs a naive loop, so numerical behavior mirrors the basic approach.</p> GSLSummator.hpp<pre><code>#include &lt;gsl/gsl_vector.h&gt;\n\nclass GSLSummator : public Summator {\npublic:\n    double sum(const std::vector&lt;double&gt;&amp; vec) const override {\n        size_t N = vec.size();\n        gsl_vector* v = gsl_vector_alloc(N);\n        for (size_t i = 0; i &lt; N; ++i) {\n            gsl_vector_set(v, i, vec[i]);\n        }\n        double s = gsl_vector_sum(v);  // Uses GSL's vector-sum routine.\n        gsl_vector_free(v);\n        return s;\n    }\n};\n</code></pre> <p>Running on the test vector yields the same intermediate lost precision. When <code>gsl_vector_sum</code> loops: <code>acc = 1.0</code>, then <code>1e16</code>, then <code>0.0</code>, then <code>-0.5</code>.</p>"},{"location":"task5/intro/","title":"Introduction to Task 5","text":"<p>Task\u00a05 examines two problems in numerical computing with floating\u2011point arithmetic:</p> <ol> <li> <p>Summation Accuracy (Task\u00a05a): We evaluate how different summation algorithms handle catastrophic cancellation and rounding error when summing vectors of mixed magnitude.</p> </li> <li> <p>Randomized DAXPY Validation (Task\u00a05b): We generate Gaussian random vectors and apply the DAXPY operation. To validate the results, we compute the sample mean and standard deviation, comparing them to theoretical expectations.</p> </li> </ol>"},{"location":"task5/intro/#task-5a-summation-methods","title":"Task 5a: Summation Methods","text":"<p>Floating\u2011point addition is not associative; summing a large value followed by a much smaller one can lose the contribution of the small term. To explore this effect, we sum the test vector:</p> <pre><code>{1.0, 1e16, -1e16, -0.5}\n</code></pre> <p>whose mathematically exact sum is <code>0.5</code>, but naive accumulation yields <code>-0.5</code>. We implement and compare five strategies, all conforming to the <code>Summator</code> interface:</p> <ul> <li>Naive Summation: Directly sums the vector elements.</li> <li>GSL Summation: Uses the GNU Scientific Library's <code>gsl_sum</code> function</li> <li>Pairwise Summation: Recursively sums pairs of elements to reduce error.</li> <li>Kahan Summation: Maintains a running compensation for lost low-order bits.</li> <li>Neumaier Summation: Similar to Kahan but uses a different compensation strategy.</li> </ul> <p>The C++ driver <code>computeSum.cpp</code> instantiates each <code>Summator</code>, applies it to the test vector, and prints the results. Subsequent sections document each algorithm\u2019s design and demonstrate how only Neumaier\u2019s method recovers the correct value.</p>"},{"location":"task5/intro/#task-5b-daxpy-with-random-vectors","title":"Task 5b: DAXPY with Random Vectors","text":"<p>In Task\u00a05b, we:</p> <ol> <li>Generate two vectors of length <code>n</code> with independent samples from a Gaussian distribution with mean <code>0</code> and standard deviation <code>1</code>, using the <code>&lt;random&gt;</code> library as shown in <code>VectorGenerator.hpp</code>.</li> <li>Apply the DAXPY operation, which computes <code>y = a * x + y</code>, where <code>a</code> is a scalar, and <code>x</code> and <code>y</code> are vectors.</li> <li>Test each strategy via the harness in <code>TestSuite.hpp</code>, invoked by <code>testDaxpy.cpp</code>, over multiple iterations. For each dimension <code>d</code>, we compute the sample mean and standard deviation.</li> <li>Validate against the theoretical expectation of \\(d \\sim \\mathcal{N}(0, \\sqrt{a^2 + 1})\\).</li> </ol>"},{"location":"task5/intro/#what-you-will-find-in-this-repository","title":"What you will find in this repository","text":"<ul> <li> <p>Source Code (<code>src/</code>):     Contains the C++ source files for computing the sum using the five methods and for testing the DAXPY operation with random vectors.</p> </li> <li> <p>Header Files (<code>include/</code>):     Provides declarations for the summation methods, DAXPY operation, and vector generation.</p> </li> <li> <p>Configuration Files (<code>config/</code>):     A YAML file (e.g., <code>config.yml</code>) that specifies the integration parameters, including the function to integrate, the interval, the number of points (N), and output options.</p> </li> <li> <p>Helper Scripts (<code>scripts/</code>): </p> <ul> <li><code>buildProject.sh</code>: A script to build the project from scratch.</li> <li><code>destroyProject.sh</code>: A script to completely clean the project, removing build artifacts and installed commands.</li> </ul> </li> <li> <p>Docker Environment (<code>docker/</code>):     A Dockerfile (e.g., <code>Dockerfile.alma9</code>) is included to provide a ready-to-use development environment with all required dependencies.</p> </li> <li> <p>Run Script Template (<code>commands/run.in</code>):     This template is used to generate a wrapper script that is installed to <code>/usr/local/bin</code> for easy invocation of project executables.</p> </li> <li> <p><code>CMakeLists.txt</code>:     The CMake build configuration file for the project.</p> </li> </ul>"},{"location":"task5/intro/#project-structure","title":"Project Structure","text":"<p>The project directory structure is as follows:</p> <pre><code>project/                 # Project root directory\n\u2502 \n\u251c\u2500\u2500 commands/                # Contains the run script template\n\u2502   \u2514\u2500\u2500 run.in                   # Script to run executables with the correct environment\n\u251c\u2500\u2500 config/                  # Configuration files\n\u2502   \u2514\u2500\u2500 config.yml/              # Example configuration file\n\u251c\u2500\u2500 docker/                  # Docker build context\n\u2502   \u2514\u2500\u2500 Dockerfile.alma9         # Dockerfile for building the project\n\u251c\u2500\u2500 include/                 # Header files\n\u2502   \u251c\u2500\u2500 ForLoopSummator.hpp      # Declaration of the ForLoopSummator class\n\u2502   \u251c\u2500\u2500 GSLSummator.hpp          # Declaration of the GSLSummator class\n\u2502   \u251c\u2500\u2500 KahanSummator.hpp        # Declaration of the KahanSummator class\n\u2502   \u251c\u2500\u2500 NeumaierSummator.hpp     # Declaration of the NeumaierSummator class\n\u2502   \u251c\u2500\u2500 PairwiseSummator.hpp     # Declaration of the PairwiseSummator class\n\u2502   \u251c\u2500\u2500 Summator.hpp             # Declaration of the Summator interface\n\u2502   \u251c\u2500\u2500 TestSuite.hpp            # Declaration of the TestSuite class\n\u2502   \u251c\u2500\u2500 VectorGenerator.hpp      # Declaration of the VectorGenerator class\n\u2502   \u251c\u2500\u2500 VectorSumDefault.hpp     # Declaration of the VectorSumDefault class\n\u2502   \u251c\u2500\u2500 VectorSumGSL.hpp         # Declaration of the VectorSumGSL class\n\u2502   \u251c\u2500\u2500 VectorSumInterface.hpp   # Declaration of the VectorSum interface\n\u251c\u2500\u2500 scripts/                 # Helper scripts\n\u2502   \u251c\u2500\u2500 buildProject.sh          # Script to build the project from scratch\n\u2502   \u2514\u2500\u2500 destroyProject.sh        # Script to completely clean the project\n\u251c\u2500\u2500 src/                     # Source code files\n\u2502   \u251c\u2500\u2500 computeSum.cpp           # Code to compute the sum using the five methods\n\u2502   \u251c\u2500\u2500 testDaxpy.cpp            # Code to test the DAXPY operation with random vectors\n\u251c\u2500\u2500 CMakeLists.txt           # CMake build configuration file\n\u2514\u2500\u2500 README.md                # Project documentation\n</code></pre>"},{"location":"task5/kahan_summator/","title":"Kahan Summation","text":"<p>This page explains the Kahan summation algorithm, which greatly reduces rounding error by keeping a running compensation for lost low-order bits.</p>"},{"location":"task5/kahan_summator/#implementation","title":"Implementation","text":"<p>When adding a small value to a large accumulator, the small value\u2019s low-order bits can be lost due to finite precision. Kahan\u2019s method maintains an extra variable <code>c</code> that tracks this lost error and reintroduces it in subsequent additions.</p> KahanSummator.hpp<pre><code>class KahanSummator : public Summator {\npublic:\n    double sum(const std::vector&lt;double&gt;&amp; vec) const override {\n        double sum = 0.0;\n        double c = 0.0; // Compensation for lost low-order bits.\n        for (size_t i = 0; i &lt; vec.size(); ++i) {\n            double y = vec[i] - c;\n            double t = sum + y;\n            c = (t - sum) - y;\n            sum = t;\n        }\n        return sum;\n    }\n};\n</code></pre>"},{"location":"task5/kahan_summator/#numerical-behavior","title":"Numerical Behavior","text":"<p>When applied to the test vector</p> <pre><code>const std::vector&lt;double&gt; vec = {1.0, 1.0e16, -1.0e16, -0.5};\n</code></pre> <p>the computed sum remains <code>-0.5</code>, the same as the naive approach. </p> Step Value Added (<code>v</code>) <code>sum</code> after addition Compensation (<code>c</code>) Initial \u2014 0.0 0.0 Add <code>1.0</code> 1.0 1.0 0.0 Add <code>1e16</code> 1e16 1e16 0.0 Add <code>-1e16</code> -1e16 0.0 0.0 Add <code>-0.5</code> -0.5 -0.5 0.0"},{"location":"task5/neumaier_summator/","title":"Neumaier Summation","text":"<p>This page describes the Neumaier summation algorithm, an extension of Kahan\u2019s method that handles cases where the next term has greater magnitude than the running sum.</p>"},{"location":"task5/neumaier_summator/#implementation","title":"Implementation","text":"<p>While Kahan Summation compensates for lost low-order bits, it can still mis-handle cases where a very large term follows a smaller running total. Neumaier\u2019s algorithm adds logic to adjust the compensation when the new term is larger in magnitude than the current sum.</p> NeumaierSummator.hpp<pre><code>class NeumaierSummator : public Summator {\npublic:\n    double sum(const std::vector&lt;double&gt;&amp; vec) const override {\n        double sum = 0.0;\n        double c = 0.0;  // Running compensation for lost low-order bits.\n\n        for (size_t i = 0; i &lt; vec.size(); ++i) {\n            double t = sum + vec[i];\n            if (std::fabs(sum) &gt;= std::fabs(vec[i])) {\n                c += (sum - t) + vec[i];\n            } else {\n                c += (vec[i] - t) + sum;\n            }\n            sum = t;\n        }\n        return sum + c;  // Apply the correction once at the end.\n    }\n};\n</code></pre>"},{"location":"task5/neumaier_summator/#numerical-behavior","title":"Numerical Behavior","text":"<p>For the vector:</p> <pre><code>const std::vector&lt;double&gt; vec = {1.0, 1.0e16, -1.0e16, -0.5};\n</code></pre> <p>Neumaier summation proceeds as follows:</p> <ol> <li>Initial: <code>sum = 0.0</code>, <code>c = 0.0</code></li> <li>Add <code>1.0</code>:<ul> <li><code>t = 0.0 + 1.0 = 1.0</code></li> <li><code>c = 0.0 + (0.0 - 1.0) + 1.0 = 0.0</code></li> <li><code>sum = 1.0</code></li> </ul> </li> <li>Add <code>1e16</code>:<ul> <li><code>t = 1.0 + 1e16 = 1e16</code></li> <li>since <code>|sum| &lt; |v|</code>, update <code>c += (1e16 - 1e16) + 1.0 = 1.0</code></li> <li><code>sum = 1e16</code></li> </ul> </li> <li>Add <code>-1e16</code>:<ul> <li><code>t = 1e16 - 1e16 = 0.0</code></li> <li>since <code>|sum| &gt;= |v|</code>, update <code>c += (sum - t) + v = (1e16 - 0.0) + (-1e16) = 0.0</code></li> <li><code>sum = 0.0</code></li> </ul> </li> <li>Add <code>-0.5</code>:<ul> <li><code>t = 0.0 - 0.5 = -0.5</code></li> <li>since <code>|sum| &gt;= |v|</code>, update <code>c += (sum - t) + v = (0.0 - (-0.5)) + (-0.5) = 0.0</code></li> <li><code>sum = -0.5</code></li> </ul> </li> <li>Final Result: <code>sum + c = -0.5 + 1.0 = 0.5</code></li> </ol> <p>Thus, Neumaier\u2019s method recovers the correct sum <code>0.5</code>, by preserving the lost <code>1.0</code> in the compensation variable <code>c</code> through the first addition.</p>"},{"location":"task5/pairwise_summator/","title":"Pairwise Summation","text":"<p>This page describes the Pairwise summation strategy, which reduces rounding error by recursively combining sub-sums of similar size.</p>"},{"location":"task5/pairwise_summator/#implementation","title":"Implementation","text":"<p>Pairwise summation works by dividing the input array into two halves, summing each half separately, and then adding the two partial sums. By pairing numbers of comparable magnitude, the method limits the error growth that occurs when small values are added to a large accumulator.</p> PairwiseSummator.hpp<pre><code>class PairwiseSummator : public Summator {\npublic:\n    double sum(const std::vector&lt;double&gt;&amp; vec) const override {\n        return pairwiseSum(vec, 0, vec.size());\n    }\n\nprivate:\n    // Recursively sums the elements in vec from index [start, end).\n    double pairwiseSum(const std::vector&lt;double&gt;&amp; vec, std::size_t start, std::size_t end) const {\n        std::size_t n = end - start;\n        if (n == 0)\n            return 0.0;\n        if (n == 1)\n            return vec[start];\n        // Split the array into two halves.\n        std::size_t mid = start + n / 2;\n        double leftSum = pairwiseSum(vec, start, mid);\n        double rightSum = pairwiseSum(vec, mid, end);\n        return leftSum + rightSum;\n    }\n};\n</code></pre>"},{"location":"task5/pairwise_summator/#numerical-behavior","title":"Numerical Behavior","text":"<p>When applied to the test vector</p> <pre><code>const std::vector&lt;double&gt; vec = {1.0, 1.0e16, -1.0e16, -0.5};\n</code></pre> <p>the algorithm</p> <ol> <li>splits the vector into two halves: <code>{1.0, 1.0e16}</code> and <code>{-1.0e16, -0.5}</code></li> <li>sums left half to get <code>1.0 + 1.0e16 = 1.0e16</code></li> <li>sums right half to get <code>-1.0e16 - 0.5 = -1.0e16</code></li> <li>finally adds the two partial sums: <code>1.0e16 + (-1.0e16) = 0.0</code></li> </ol> <p>In this extreme case, the pairwise summation still results in catastrophic cancellation. However, for larger and more varied datasets, this method significantly reduces overall rounding error compared to the naive loop.</p>"},{"location":"task5/summation_overview/","title":"Summation Algorithms Overview","text":"<p>Task 5a explores how different summation algorithms handle floating\u2011point cancellation when summing the vector</p> <pre><code>const std::vector&lt;double&gt; vec = {1.0, 1.0e16, -1.0e16, -0.5};\n</code></pre> <p>whose true sum is 0.5. The code defines an abstract <code>Summator</code> interface (in <code>Summator.hpp</code>) with a single method:</p> <pre><code>virtual double sum(const std::vector&lt;double&gt;&amp; values) = 0;\n</code></pre> <p>Five concrete strategies implement this interface:</p>"},{"location":"task5/summation_overview/#1-forloop-summator","title":"1. For\u2011Loop Summator","text":"<p>A straightforward loop that accumulates each element in order:</p> ForLoopSummator.hpp<pre><code>class ForLoopSummator : public Summator {\npublic:\n    double sum(const std::vector&lt;double&gt;&amp; vec) const override {\n        double s = 0.0;\n        for (size_t i = 0; i &lt; vec.size(); ++i) {\n            s += vec[i];\n        }\n        return s;\n    }\n};\n</code></pre> <p>This approach suffers from catastrophic cancellation when a very large value overwhelms small ones.</p>"},{"location":"task5/summation_overview/#2-gsl-summator","title":"2. GSL Summator","text":"<p>Delegates to the GNU Scientific Library\u2019s <code>gsl_vector_sum</code> on a <code>gsl_vector</code> wrapper. It behaves like the naive loop under the hood and exhibits the same numerical issues.</p> GSLSummator.hpp<pre><code>class GSLSummator : public Summator {\npublic:\n    double sum(const std::vector&lt;double&gt;&amp; vec) const override {\n        size_t N = vec.size();\n        gsl_vector* v = gsl_vector_alloc(N);\n        for (size_t i = 0; i &lt; N; ++i) {\n            gsl_vector_set(v, i, vec[i]);\n        }\n        double s = gsl_vector_sum(v);  // Uses GSL's vector-sum routine.\n        gsl_vector_free(v);\n        return s;\n    }\n};\n</code></pre>"},{"location":"task5/summation_overview/#3-pairwise-summator","title":"3. Pairwise Summator","text":"<p>Recursively splits the array in half, sums each half, then adds the two partial sums. This reduces error growth by grouping similar\u2011magnitude terms:</p> PairwiseSummator.hpp<pre><code>class PairwiseSummator : public Summator {\npublic:\n    double sum(const std::vector&lt;double&gt;&amp; vec) const override {\n        return pairwiseSum(vec, 0, vec.size());\n    }\n\nprivate:\n    // Recursively sums the elements in vec from index [start, end).\n    double pairwiseSum(const std::vector&lt;double&gt;&amp; vec, std::size_t start, std::size_t end) const {\n        std::size_t n = end - start;\n        if (n == 0)\n            return 0.0;\n        if (n == 1)\n            return vec[start];\n        // Split the array into two halves.\n        std::size_t mid = start + n / 2;\n        double leftSum = pairwiseSum(vec, start, mid);\n        double rightSum = pairwiseSum(vec, mid, end);\n        return leftSum + rightSum;\n    }\n};\n</code></pre>"},{"location":"task5/summation_overview/#4-kahan-summator","title":"4. Kahan Summator","text":"<p>Implements the Kahan compensated summation algorithm, maintaining a separate compensation <code>c</code> to capture lost low\u2011order bits:</p> KahanSummator.hpp<pre><code>class KahanSummator : public Summator {\npublic:\n    double sum(const std::vector&lt;double&gt;&amp; vec) const override {\n        double sum = 0.0;\n        double c = 0.0; // Compensation for lost low-order bits.\n        for (size_t i = 0; i &lt; vec.size(); ++i) {\n            double y = vec[i] - c;\n            double t = sum + y;\n            c = (t - sum) - y;\n            sum = t;\n        }\n        return sum;\n    }\n};\n</code></pre>"},{"location":"task5/summation_overview/#5-neumaier-summator","title":"5. Neumaier Summator","text":"<p>An improved Kahan variant that handles the case where the new term has larger magnitude than the running sum:</p> NeumaierSummator.hpp<pre><code>class NeumaierSummator : public Summator {\npublic:\n    double sum(const std::vector&lt;double&gt;&amp; vec) const override {\n        double sum = 0.0;\n        double c = 0.0;  // Running compensation for lost low-order bits.\n\n        for (size_t i = 0; i &lt; vec.size(); ++i) {\n            double t = sum + vec[i];\n            if (std::fabs(sum) &gt;= std::fabs(vec[i])) {\n                c += (sum - t) + vec[i];\n            } else {\n                c += (vec[i] - t) + sum;\n            }\n            sum = t;\n        }\n        return sum + c;  // Apply the correction once at the end.\n    }\n};\n</code></pre>"},{"location":"task6/bonus/","title":"Reconstructing the full complex matrix from the half-spectrum","text":"<p>In the bonus section, we verify that when using R2C FFT we can use Hermitian symmetry to recover the full complex spectrum exactly, using a small \\(6 \\times 6\\) test matrix. The driver is <code>task06_bonus.cpp</code>.</p>"},{"location":"task6/bonus/#test-driver","title":"Test driver","text":"<p>The main function in <code>task06_bonus.cpp</code> orchestrates: generation of test data, full C2C FFT, half-spectrum R2C FFT and Hermitian reconstruction, and spectrum comparison after reconstruction with Hermitian symmetry.</p> task06_bonus.cpp<pre><code>int main() {\n    constexpr size_t ROWS = 6, COLS = 6;\n    const double tol = 1e-12;\n\n    // 1) generate A ~ N(1,1)\n    auto A = generate_gaussian_matrix(ROWS, COLS, /*mean=*/1.0, /*stddev=*/1.0);\n\n    // 2) promote to complex\n    auto Ac = promote_to_complex(A);\n\n    // 3) full padded c2c FFT\n    auto C_full = FFT::fft2d(Ac, /*invert=*/false);\n\n    // 4) trimmed real\u2192complex\n    auto R_half = FFT::fft2d_r2c_trim(A);\n\n    // 5) reconstruct the full spectrum from R_half\n    auto C_from_R = FFT::r2c_reconstruct_full(R_half);\n\n    // 6) compare element\u2010wise\n    size_t M = C_full.size(), N = C_full[0].size();\n    double max_diff = 0.0;\n    for (size_t i = 0; i &lt; M; ++i)\n        for (size_t j = 0; j &lt; N; ++j)\n            max_diff = std::max(max_diff,\n                                std::abs(C_full[i][j] - C_from_R[i][j]));\n\n    std::cout &lt;&lt; \"Max abs(C_full - C_from_R) = \" &lt;&lt; max_diff &lt;&lt; \"\\n\";\n    if (max_diff &lt; tol) {\n        std::cout &lt;&lt; \"\u2714 Bonus: reconstructed spectrum matches within tol = \"\n                  &lt;&lt; tol &lt;&lt; \"\\n\";\n        return 0;\n    } else {\n        std::cerr &lt;&lt; \"\u2718 Bonus: reconstruction error too large!\\n\";\n        return 1;\n    }\n}\n</code></pre>"},{"location":"task6/bonus/#hermitian-reconstruction","title":"Hermitian reconstruction","text":"<p>The key function <code>r2c_reconstruct_full</code> in <code>FFT.cpp</code> reconstructs the full complex spectrum C from the half-spectrum R. It uses Hermitian symmetry to fill in the missing frequencies:</p> FFT.cpp<pre><code>std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt;\nr2c_reconstruct_full(const std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt;&amp; R)\n{\n    std::size_t M      = R.size();\n    std::size_t N_half = M &amp;&amp; !R.empty() ? R[0].size() : 0;\n    std::size_t N      = 2*(N_half - 1);\n\n    // rebuild full Hermitian spectrum\n    std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt; full(\n        M, std::vector&lt;std::complex&lt;double&gt;&gt;(N));\n    for (std::size_t i = 0; i &lt; M; ++i) {\n        // first half\n        for (std::size_t j = 0; j &lt; N_half; ++j)\n            full[i][j] = R[i][j];\n        // mirror\n        for (std::size_t j = N_half; j &lt; N; ++j) {\n            std::size_t ii = (M - i) % M;\n            std::size_t jj = (N - j) % N;\n            full[i][j] = std::conj(R[ii][jj]);\n        }\n    }\n    return full;\n}\n</code></pre>"},{"location":"task6/bonus/#expected-outcome","title":"Expected outcome","text":"<p>Because Hermitian reconstruction implements exactly the inverse of the R2C trimming process, the reconstructed spectrum <code>C_from_R</code> should match the direct C2C FFT <code>C_full</code> within round-off error. On the 6\u00d76 test, typical results are:</p> <pre><code>Max abs(C_full - C_from_R) = 7.10543e-15\n</code></pre> <p>This confirms that our R2C trimming and reconstruction are mathematically correct and numerically robust.</p>"},{"location":"task6/build/","title":"How to Build the Project","text":""},{"location":"task6/build/#step-by-step-instructions","title":"Step-by-Step Instructions","text":"<p>Assuming you already have the project available locally and your Docker container is running with <code>/workspace</code> set as the project root, follow these steps to build the project:</p> <ol> <li> <p>Navigate to the Project Root:</p> <p>Ensure you are in the project root directory (i.e., <code>/workspace</code>). You can verify this by running:</p> <pre><code>pwd\n</code></pre> <p>It should display <code>/workspace</code> (the project root).</p> </li> <li> <p>Run the Build Script:</p> <p>From the project root, execute the build script to configure and compile the project:</p> <pre><code>bash ./scripts/buildProject.sh\n</code></pre> <p>This script will:</p> <ul> <li>Create a build directory </li> <li>Change into the build directory.</li> <li>Run CMake to generate the build system.</li> <li>Invoke make to compile the source code into executables.</li> <li>Return you to the project root once the build is complete.</li> </ul> </li> <li> <p>Run the Executables:</p> <p>You can now run the executables using the <code>run</code> command from anywhere. For example:</p> <ul> <li> <p>Compute the sum of elements in a vector using different methods:</p> <pre><code>run computeSum\n</code></pre> </li> <li> <p>Perform daxpy operation (d=a*x + y) with random vectors:</p> <pre><code>run testDaxpy\n</code></pre> <p>or, to override default parameters:</p> <pre><code>run testDaxpy &lt;N&gt; &lt;a&gt; &lt;n_iter&gt;\n</code></pre> </li> </ul> <p>More details on properly using the executables are provided in the subsequent sections of this documentation. </p> </li> </ol>"},{"location":"task6/c2c/","title":"Complex-to-complex FFT implementation","text":"<p>This page examines in detail how the code performs the 2D complex-to-complex FFT, including padding, the 1D FFT core, and the inverse with trimming.</p>"},{"location":"task6/c2c/#padding-to-power-of-two-dimensions","title":"Padding to power-of-two dimensions","text":"<p>Before applying the FFT, the input matrix is padded so that both dimensions are powers of two. In <code>FFT.cpp</code>, the helper <code>next_power_of_two</code> and padding loop are used:</p> FFT.cpp<pre><code>std::size_t next_power_of_two(std::size_t n) {\n    std::size_t p = 1;\n    while (p &lt; n) p &lt;&lt;= 1;\n    return p;\n}\n</code></pre> inside FFT::fft2d(...)<pre><code>std::size_t R = input.size(); // number of rows\nstd::size_t C = R ? input[0].size() : 0; // number of columns\nstd::size_t M = next_power_of_two(R);\nstd::size_t N = next_power_of_two(C);\n\n// pad to M\u00d7N\nstd::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt; a(\n    M, std::vector&lt;std::complex&lt;double&gt;&gt;(N, {0,0}));\nfor (std::size_t i = 0; i &lt; R; ++i)\n    for (std::size_t j = 0; j &lt; C; ++j)\n        a[i][j] = input[i][j];\n</code></pre> <p>This ensures optimal FFT speed and simplifies the Cooley\u2013Tukey recursion.</p>"},{"location":"task6/c2c/#1d-fft-core","title":"1D FFT core","text":"<p>The 1D FFT uses an in-place Cooley\u2013Tukey algorithm with bit reversal and iterative butterflies:</p> FFT.cpp<pre><code>void fft(std::vector&lt;std::complex&lt;double&gt;&gt;&amp; a, bool invert) {\n    const std::size_t n = a.size();\n    if (n &lt; 2) return;\n\n    // bit\u2011reversal permute\n    for (std::size_t i = 1, j = 0; i &lt; n; ++i) {\n        std::size_t bit = n &gt;&gt; 1;\n        for (; j &amp; bit; bit &gt;&gt;= 1) j ^= bit;\n        j |= bit;\n        if (i &lt; j) std::swap(a[i], a[j]);\n    }\n\n    // Cooley\u2013Tukey butterflies\n    for (std::size_t len = 2; len &lt;= n; len &lt;&lt;= 1) {\n        double ang = 2 * M_PI / double(len) * (invert ? 1 : -1);\n        std::complex&lt;double&gt; wlen(std::cos(ang), std::sin(ang));\n        for (std::size_t i = 0; i &lt; n; i += len) {\n            std::complex&lt;double&gt; w{1,0};\n            for (std::size_t k = 0; k &lt; len/2; ++k) {\n                auto u = a[i + k];\n                auto v = a[i + k + len/2] * w;\n                a[i + k]         = u + v;\n                a[i + k + len/2] = u - v;\n                w *= wlen;\n            }\n        }\n    }\n\n    // scale for inverse\n    if (invert) {\n        for (auto&amp; x : a) x /= double(n);\n    }\n}\n</code></pre> <p>This routine underlies both forward and inverse transforms.</p>"},{"location":"task6/c2c/#2d-fft-implementation","title":"2D FFT implementation","text":"<p>The 2D FFT applies fft row-wise, transposes, and applies fft again row-wise (on columns):</p> FFT.cpp<pre><code>std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt;\nfft2d(const std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt;&amp; input,\n      bool invert)\n{\n    std::size_t R = input.size();\n    std::size_t C = R ? input[0].size() : 0;\n    std::size_t M = next_power_of_two(R);\n    std::size_t N = next_power_of_two(C);\n\n    // pad to M\u00d7N\n    std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt; a(\n        M, std::vector&lt;std::complex&lt;double&gt;&gt;(N, {0,0}));\n    for (std::size_t i = 0; i &lt; R; ++i)\n        for (std::size_t j = 0; j &lt; C; ++j)\n            a[i][j] = input[i][j];\n\n    // FFT rows\n    for (std::size_t i = 0; i &lt; M; ++i)\n        a[i] = fft1d(a[i], invert);\n\n    // FFT cols\n    std::vector&lt;std::complex&lt;double&gt;&gt; tmp(M);\n    for (std::size_t j = 0; j &lt; N; ++j) {\n        for (std::size_t i = 0; i &lt; M; ++i) tmp[i] = a[i][j];\n        tmp = fft1d(tmp, invert);\n        for (std::size_t i = 0; i &lt; M; ++i) a[i][j] = tmp[i];\n    }\n\n    return a;\n}\n</code></pre> <p>This decomposes the 2D problem into  calls to the 1D FFT.</p>"},{"location":"task6/c2c/#complex-to-complex-fft","title":"Complex-to-complex FFT","text":"<p>Rather than returning a bare matrix, fft2d_c2c_trim returns a struct that encapsulates both the frequency-domain data and the original dimensions. In <code>FFT.hpp</code>:</p> FFT.hpp<pre><code>struct FFT2dC2CTrimmed {\n    std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt; freq;\n    std::size_t orig_rows, orig_cols;\n    std::size_t pad_rows, pad_cols;\n};\n\nFFT2dC2CTrimmed\nfft2d_c2c_trim(const std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt;&amp; input);\n</code></pre> <p>In <code>FFT.cpp</code>, the implementation captures the full padded transform and records the original size:</p> FFT.cpp<pre><code>FFT2dC2CTrimmed\nfft2d_c2c_trim(const std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt;&amp; input)\n{\n    const std::size_t R = input.size();\n    const std::size_t C = R ? input[0].size() : 0;\n    const std::size_t M = next_power_of_two(R);\n    const std::size_t N = next_power_of_two(C);\n\n    // 1) compute the full M\u00d7N forward transform\n    auto full = fft2d(input, /*invert=*/false);\n\n    // 2) package it all up\n    return FFT2dC2CTrimmed{ std::move(full), R, C, M, N };\n}\n</code></pre> <p>The padded transform <code>full</code> has dimensions that are powers of two, which may exceed the original. By retaining <code>orig_rows</code> and <code>orig_cols</code>, the inverse transform can know exactly how to crop the result back to the user\u2019s intended size.</p>"},{"location":"task6/c2c/#inverse-complex-to-complex-fft","title":"Inverse complex-to-complex FFT","text":"<p>To return to original dimensions, <code>ifft2d_c2c_trim</code> accepts the <code>FFT2dC2CTrimmed</code> struct and uses its metadata:</p> FFT.cpp<pre><code>std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt;\nifft2d_c2c_trim(const FFT2dC2CTrimmed&amp; t)\n{\n    // 1) full padded inverse\n    auto fullRec = fft2d(t.freq, /*invert=*/true);\n\n    // 2) crop back to original R\u00d7C\n    std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt; out(\n        t.orig_rows,\n        std::vector&lt;std::complex&lt;double&gt;&gt;(t.orig_cols)\n    );\n    for (std::size_t i = 0; i &lt; t.orig_rows; ++i)\n        for (std::size_t j = 0; j &lt; t.orig_cols; ++j)\n            out[i][j] = fullRec[i][j];\n\n    return out;\n}\n</code></pre> <p>By combining the padded spectrum and the stored original sizes, this function ensures the round-trip FFT returns exactly to the user\u2019s matrix dimensions.</p>"},{"location":"task6/code_overview/","title":"Code Overview for Task 6","text":"<p>In Task\u00a06, we implement and evaluate two-dimensional Fast Fourier Transforms (FFTs) on real-valued matrices, using both complex-to-complex (C2C) and real-to-complex (R2C) approaches. The core functionality resides in <code>FFT.cpp</code> and its header <code>FFT.hpp</code>, while the drivers <code>task06.cpp</code> and <code>task06_bonus.cpp</code> invoke these routines and report accuracy metrics.</p>"},{"location":"task6/code_overview/#main-steps","title":"Main steps","text":""},{"location":"task6/code_overview/#data-generation","title":"Data generation","text":"<p>We begin by creating a 1000\u00d71000 matrix A with entries drawn from \\(\\mathcal{N}(1,1)\\). In <code>Task06Helpers.hpp</code>, the function:</p> <pre><code>inline std::vector&lt;std::vector&lt;double&gt;&gt;\ngenerate_gaussian_matrix(size_t M,\n                         size_t N,\n                         double mean,\n                         double stddev)\n{\n    std::mt19937_64 gen{std::random_device{}()};\n    std::normal_distribution&lt;double&gt; dist{mean, stddev};\n    std::vector&lt;std::vector&lt;double&gt;&gt; A(M, std::vector&lt;double&gt;(N));\n    for (auto&amp; row : A)\n        for (auto&amp; x : row)\n            x = dist(gen);\n    return A;\n}\n</code></pre> <p>produces A, which is then passed to the FFT routines.</p>"},{"location":"task6/code_overview/#complex-to-complex-fft-roundtrip","title":"Complex-to-complex FFT roundtrip","text":"<p>In <code>FFT.cpp</code>, we implement <code>fft2d_c2c_trim</code> and <code>ifft2d_c2c_trim</code>. The forward transform:</p> <pre><code>std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt; C_trim = FFT::fft2d_c2c_trim(A);\n</code></pre> <p>computes the full 2D FFT by applying 1D FFTs first on each row and then on each column. To revert to the spatial domain we call:</p> <pre><code>std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt; Arec_c2c = FFT::ifft2d_c2c_trim(C_trim);\n</code></pre> <p>which applies the inverse FFT.</p>"},{"location":"task6/code_overview/#real-to-complex-fft-roundtrip","title":"Real-to-complex FFT roundtrip","text":"<p>To exploit symmetry and reduce storage, we use the R2C variant. The forward call:</p> <pre><code>std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt; R_half = FFT::fft2d_r2c_trim(A);\n</code></pre> <p>computes a half-spectrum of size M\u00d7(N/2+1). We then reconstruct A with:</p> <pre><code>std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt; Arec_r2c = FFT::ifft2d_r2c_trim(R_half, COLS);\n</code></pre> <p>which performs the inverse real-to-complex transform and restores the full matrix.</p>"},{"location":"task6/code_overview/#error-evaluation","title":"Error evaluation","text":"<p>In <code>Task06Helpers.hpp</code>, the function <code>evaluate_c2c_roundtrip</code> takes A and Arec and computes statistics:</p> <pre><code>auto stats_c2c = evaluate_c2c_roundtrip(A, Arec_c2c);\nprint_error_stats(\"c2c_trim round\u2011trip errors\", stats_c2c);\n</code></pre> <p>These routines calculate the root-mean-square (RMSE), median RMS error, and relative counterparts, printing results to the console.</p> <p>Similarly, for the R2C roundtrip:</p> <pre><code>auto stats_r2c = evaluate_r2c_roundtrip(A, Arec_r2c);\nprint_error_stats(\"r2c round\u2011trip errors\", stats_r2c);\n</code></pre>"},{"location":"task6/code_overview/#bonus-hermitian-symmetry","title":"Bonus: Hermitian symmetry","text":"<p>When the input matrix A is real, the FFT C exhibits Hermitian symmetry. The trimmed spectrum R can be expanded to the full complex matrix C via Hermitian symmetry. The function:</p> <pre><code>std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt; C_from_R = FFT::r2c_reconstruct_full(R_half);\n</code></pre> <p>reconstructs the full complex matrix C from the half-spectrum R_half, leveraging the symmetry property.</p>"},{"location":"task6/docker/","title":"Docker Installation and Setup for Task 6","text":""},{"location":"task6/docker/#overview","title":"Overview","text":"<p>This guide explains how to build and run the Docker container that provides a virtualized environment for Task 6 of the Scientific Computing for Physics Students project. The container is based on AlmaLinux9 and includes all required development tools and libraries (yaml-cpp, HDF5, GSL, etc.), as well as a Python environment managed by Miniconda.</p> <p>Prerequisites</p> <ul> <li>Docker must be installed.</li> <li>Follow the Docker installation instructions in Task\u00a01 before proceeding with Task\u00a06.</li> </ul>"},{"location":"task6/docker/#building-the-docker-image","title":"Building the Docker Image","text":"<p>The Dockerfile is located in the <code>docker/</code> directory and is named <code>Dockerfile.alma9</code>.</p> <ol> <li>Open a terminal and navigate to the project root.</li> <li> <p>Run the following command to build the Docker image:</p> <pre><code>docker build -t sci-comp-task6 -f docker/Dockerfile.alma9 .\n</code></pre> <ol> <li><code>-t sci-comp-task6</code> tags the image with the name <code>sci-comp-task6</code>.</li> <li><code>-f docker/Dockerfile.alma9</code> specifies the location of the Dockerfile.</li> <li>The final <code>.</code> sets the build context to the project root.</li> </ol> </li> </ol>"},{"location":"task6/docker/#running-the-docker-container","title":"Running the Docker Container","text":"<p>Once the image is built, you can start a container interactively with:</p> <pre><code>docker run -it -v \"$(pwd):/workspace\" sci-comp-task6\n</code></pre> <ul> <li><code>-it</code>: Runs the container in interactive mode with a TTY.</li> <li><code>-v \"$(pwd):/workspace\"</code>: Mounts the current project root into the container at /workspace.</li> <li><code>sci-comp-task6</code>: Specifies the image name.</li> </ul> <p>Inside the container, your working directory will be <code>/workspace</code> (which is your project root), and all necessary tools and libraries will be available.</p>"},{"location":"task6/intro/","title":"Introduction to Task 6","text":"<p>In this task, we explore the numerical accuracy and computational behavior of two-dimensional Fast Fourier Transforms (FFTs) on real-valued data. Specifically, we:</p> <ol> <li> <p>Generate a real 1000\u00d71000 matrix A whose entries are drawn from a normal distribution with mean 1 and standard deviation 1.</p> </li> <li> <p>Perform a complex-to-complex (C2C) 2D FFT on A, obtaining a frequency-domain matrix C.</p> </li> <li> <p>Reconstruct A by applying the inverse C2C FFT to C, then measure the root-mean-square error (RMSE) and median RMS error for both absolute and relative differences.</p> </li> <li> <p>Perform a real-to-complex (R2C) trimmed FFT on A, producing R, then reconstruct A via the inverse trimmed real-to-complex-to-real (C2R) FFT.</p> </li> <li> <p>Compare the C2C and R2C round-trip errors against machine precision and explain any deviations.</p> </li> <li> <p>Interpret the DC component (the [0][0] coefficient) of both transforms.</p> </li> <li> <p>(Bonus) On a smaller 6\u00d76 matrix, reconstruct the full complex spectrum from the trimmed R2C output using Hermitian symmetry.</p> </li> </ol>"},{"location":"task6/intro/#theoretical-background","title":"Theoretical Background","text":"<p>The Discrete Fourier Transform (DFT) for an M\u00d7N array  is given by</p> \\[ C[k,l] = \\sum_{i=0}^{M-1} \\sum_{j=0}^{N-1} A[i,j] e^{-2\\pi i (ki/M + lj/N)} \\] <p>and its inverse recovers A up to a normalization factor.</p> <p>The Fast Fourier Transform (FFT) computes the DFT in O(MN log(MN)) time by recursively splitting the problem into smaller DFTs (Cooley\u2013Tukey algorithm).</p> <p>For real-to-complex 2D FFTs, one exploits Hermitian symmetry to store only half the frequency-domain data (columns 0 to N/2), reducing storage and computation.</p>"},{"location":"task6/intro/#key-computational-steps","title":"Key Computational Steps","text":"<ol> <li>Matrix Generation: Create a 1000\u00d71000 matrix A with entries from a normal distribution. Matrix generation uses <code>generate_gaussian_matrix(1000,1000,1.0,1.0)</code> from <code>Task06Helpers.hpp</code>.</li> <li>C2C FFT: <code>FFT::fft2d</code> computes the full padded FFT and <code>FFT::ifft2d_c2c_trim</code> performs the inverse and crops back to the original dimensions.</li> <li>Error Evaluation calls <code>evaluate_c2c_roundtrip(A, Arec)</code> and <code>print_error_stats</code> to report:<ul> <li>RMSE(abs)</li> <li>MedianRSE(abs)</li> <li>RMSE(rel)</li> <li>MedianRSE(rel)</li> </ul> </li> <li>R2C FFT: <code>FFT::fft2d_r2c_trim</code> produces a trimmed spectrum R; <code>FFT::ifft2d_c2r_trim(R, original_cols)</code> reconstructs A.</li> </ol>"},{"location":"task6/intro/#sample-results-and-interpretation","title":"Sample Results and Interpretation","text":"<p>On a 1000\u00d71000 matrix, typical results are:</p> <pre><code>=== c2c_trim round\u2011trip errors ===\n  RMSE(abs) = 2.74066e-14\n  MedRSE(abs)= 1.58103e-14\n  RMSE(rel) = 1.54794e-11\n  MedRSE(rel)= 1.39873e-14\n\nC[0][0] = (1.00119e+06,0)  (\u2248 sum of A)\n\n=== r2c round\u2011trip errors ===\n  RMSE(abs) = 2.822e-14\n  MedRSE(abs)= 1.66533e-14\n  RMSE(rel) = 1.62722e-11\n  MedRSE(rel)= 1.49467e-14\n\nR[0][0] = (1.00119e+06,0)  (DC term again)\n</code></pre> <ul> <li>The absolute RMSE of a few \\(10^{-14}\\) indicates that we are very close to machine precision, consistent with \\(\\mathcal{O}(\\sqrt{MN\\epsilon})\\) accumulation of rounding errors.</li> <li>The relative RMSE of \\(\\sim 10^{-11}\\) reflects the additional \\(\\mathcal{O}(N \\log N)\\) operations in the FFT.</li> <li>The DC component C[0][0] and R[0][0] both equal the sum of all entries in A.</li> </ul>"},{"location":"task6/intro/#what-you-will-find-in-this-repository","title":"What you will find in this repository","text":"<ul> <li> <p>Source Code (<code>src/</code>):     Contains the C++ source files for computing the FFTs and testing the round-trip errors.</p> </li> <li> <p>Header Files (<code>include/</code>):     Provides declarations for the FFT methods and utilities.</p> </li> <li> <p>Test Files (<code>test/</code>):     Contains unit tests for the FFT implementations and error evaluations.</p> </li> <li> <p>Helper Scripts (<code>scripts/</code>): </p> <ul> <li><code>buildProject.sh</code>: A script to build the project from scratch.</li> <li><code>destroyProject.sh</code>: A script to completely clean the project, removing build artifacts and installed commands.</li> </ul> </li> <li> <p>Docker Environment (<code>docker/</code>):     A Dockerfile (e.g., <code>Dockerfile.alma9</code>) is included to provide a ready-to-use development environment with all required dependencies.</p> </li> <li> <p>Run Script Template (<code>commands/run.in</code>):     This template is used to generate a wrapper script that is installed to <code>/usr/local/bin</code> for easy invocation of project executables.</p> </li> <li> <p><code>CMakeLists.txt</code>:     The CMake build configuration file for the project.</p> </li> </ul>"},{"location":"task6/intro/#project-structure","title":"Project Structure","text":"<p>The project directory structure is as follows:</p> <pre><code>project/                 # Project root directory\n\u2502 \n\u251c\u2500\u2500 commands/                # Contains the run script template\n\u2502   \u2514\u2500\u2500 run.in                    # Script to run executables with the correct environment\n\u251c\u2500\u2500 docker/                  # Docker build context\n\u2502   \u2514\u2500\u2500 Dockerfile.alma9          # Dockerfile for building the project\n\u251c\u2500\u2500 include/                 # Header files\n\u2502   \u251c\u2500\u2500 FFT.hpp                   # Declaration of the FFT class\n\u2502   \u251c\u2500\u2500 task06_bonus.hpp          # Declaration of the bonus task functions\n\u2502   \u251c\u2500\u2500 task06.hpp                # Declaration of the Task06 class\n\u251c\u2500\u2500 scripts/                 # Helper scripts\n\u2502   \u251c\u2500\u2500 buildProject.sh           # Script to build the project from scratch\n\u2502   \u2514\u2500\u2500 destroyProject.sh         # Script to completely clean the project\n\u251c\u2500\u2500 src/                     # Source code files\n\u2502   \u251c\u2500\u2500 FFT.cpp                   # Implementation of the FFT class\n\u2502   \u251c\u2500\u2500 task06_bonus.cpp          # Implementation of the bonus task functions\n\u2502   \u251c\u2500\u2500 task06.cpp                # Main entry point for Task 6\n\u251c\u2500\u2500 test/                    # Unit tests\n\u2502   \u251c\u2500\u2500 test_fft_next_power_of_two.cpp        # Tests for FFT utility functions\n\u2502   \u251c\u2500\u2500 test_fft1d.cpp                        # Tests for 1D FFT functionality\n\u2502   \u251c\u2500\u2500 test_fft2d_c2c_trim.cpp               # Tests for 2D FFT functionality\n\u2502   \u251c\u2500\u2500 test_fft2d_c2c.cpp                    # Tests for 2D R2C FFT functionality\n\u2502   \u251c\u2500\u2500 test_fft2d_r2c_reconstruct_full.cpp   # Tests for 2D R2C FFT functionality\n\u2502   \u251c\u2500\u2500 test_fft2d_r2c_trim.cpp               # Tests for Task 6 functionality\n\u251c\u2500\u2500 CMakeLists.txt           # CMake build configuration file\n\u2514\u2500\u2500 README.md                # Project documentation  \n</code></pre>"},{"location":"task6/r2c/","title":"Real-to-complex FFT implementation","text":"<p>This page details how the code performs the two-dimensional real-to-complex FFT (R2C), highlighting the differences and optimizations relative to the C2C pathway.</p>"},{"location":"task6/r2c/#forward-r2c-fft","title":"Forward R2C FFT","text":"<p>Unlike the C2C transform, which operates on complex data, the R2C variant accepts a real-valued matrix and produces only the non-redundant half of the complex spectrum. The function signature in <code>FFT.hpp</code> is:</p> FFT.hpp<pre><code>std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt;\nfft2d_r2c_trim(const std::vector&lt;std::vector&lt;double&gt;&gt;&amp; input);\n</code></pre> <p>In <code>FFT.cpp</code>, <code>fft2d_r2c_trim</code> is implemented by:</p> FFT.cpp<pre><code>std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt;\nfft2d_r2c_trim(const std::vector&lt;std::vector&lt;double&gt;&gt;&amp; input)\n{\n    std::size_t R = input.size();\n    std::size_t C = R ? input[0].size() : 0;\n\n    // 1) promote to complex\n    std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt; ac(\n        R, std::vector&lt;std::complex&lt;double&gt;&gt;(C));\n    for (std::size_t i = 0; i &lt; R; ++i)\n        for (std::size_t j = 0; j &lt; C; ++j)\n            ac[i][j] = { input[i][j], 0.0 };\n\n    // 2) full padded forward FFT\n    auto full = fft2d(ac, /*invert=*/false);\n    std::size_t M = full.size();\n    std::size_t N = M ? full[0].size() : 0;\n    std::size_t N_half = N/2 + 1;\n\n    // 3) crop to M\u00d7(N/2+1)\n    std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt; out(\n        M, std::vector&lt;std::complex&lt;double&gt;&gt;(N_half));\n    for (std::size_t i = 0; i &lt; M; ++i)\n        for (std::size_t j = 0; j &lt; N_half; ++j)\n            out[i][j] = full[i][j];\n\n    return out;\n}\n</code></pre> <p>Extracting only the first <code>N/2 + 1</code> columns (columns 0 through <code>N/2</code>) we reduce memory and computation for real-valued data by nearly half.</p>"},{"location":"task6/r2c/#hermitian-spectrum-reconstruction","title":"Hermitian spectrum reconstruction","text":"<p>To invert the R2C transform, we must first recreate the full complex spectrum from the trimmed output. The function signature in <code>FFT.hpp</code> is:</p> FFT.hpp<pre><code>std::vector&lt;std::vector&lt;double&gt;&gt;\nifft2d_c2r_trim(const std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt;&amp; R,\n                std::size_t orig_cols);\n</code></pre> <p>Its implementation in <code>FFT.cpp</code> mirrors <code>fft2d_r2c_trim</code>:</p> FFT.cpp<pre><code>std::vector&lt;std::vector&lt;double&gt;&gt;\nifft2d_c2r_trim(const std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt;&amp; R,\n                std::size_t orig_cols)\n{\n    std::size_t M      = R.size();\n    std::size_t N_half = M &amp;&amp; !R.empty() ? R[0].size() : 0;\n    std::size_t N      = 2*(N_half - 1);\n\n    // 1) reconstruct full Hermitian M\u00d7N\n    std::vector&lt;std::vector&lt;std::complex&lt;double&gt;&gt;&gt; full(\n        M, std::vector&lt;std::complex&lt;double&gt;&gt;(N));\n    for (std::size_t i = 0; i &lt; M; ++i) {\n        for (std::size_t j = 0; j &lt; N_half; ++j)\n            full[i][j] = R[i][j];\n        for (std::size_t j = N_half; j &lt; N; ++j) {\n            std::size_t ii = (M - i) % M;\n            std::size_t jj = (N - j) % N;\n            full[i][j] = std::conj(R[ii][jj]);\n        }\n    }\n\n    // 2) full padded inverse FFT\n    auto comp = fft2d(full, /*invert=*/true);\n\n    // 3) crop to real M\u00d7orig_cols\n    std::vector&lt;std::vector&lt;double&gt;&gt; out(\n        M, std::vector&lt;double&gt;(orig_cols));\n    for (std::size_t i = 0; i &lt; M; ++i)\n        for (std::size_t j = 0; j &lt; orig_cols; ++j)\n            out[i][j] = comp[i][j].real();\n\n    return out;\n}\n</code></pre> <p>The first step reconstructs the full complex matrix by applying Hermitian symmetry, where the second half of the spectrum is filled in by conjugating and reflecting the first half. The inverse FFT is then computed on this full matrix, and finally, we crop back to the original dimensions specified by <code>orig_cols</code>. </p>"},{"location":"task7/build/","title":"How to Build the Project","text":""},{"location":"task7/build/#step-by-step-instructions","title":"Step-by-Step Instructions","text":"<p>Assuming you already have the project available locally and your Docker container is running with <code>/workspace</code> set as the project root, follow these steps to build the project:</p> <ol> <li> <p>Navigate to the Project Root:</p> <p>Ensure you are in the project root directory (i.e., <code>/workspace</code>). You can verify this by running:</p> <pre><code>pwd\n</code></pre> <p>It should display <code>/workspace</code> (the project root).</p> </li> <li> <p>Run the Build Script:</p> <p>From the project root, execute the build script to configure and compile the project:</p> <pre><code>bash ./scripts/buildProject.sh\n</code></pre> <p>This script will:</p> <ul> <li>Create a build directory </li> <li>Change into the build directory.</li> <li>Run CMake to generate the build system.</li> <li>Invoke make to compile the source code into executables.</li> <li>Return you to the project root once the build is complete.</li> </ul> </li> <li> <p>Run the Executables:</p> <p>You can now run the executables using the <code>run</code> command from anywhere. For example:</p> <ul> <li> <p>Run the <code>test_vector_sum</code> executable:</p> <pre><code>run test_vector_sum\n</code></pre> <p>This will execute the tests defined in the <code>test_vector_sum.cpp</code> file and display the results in the terminal.</p> </li> </ul> </li> </ol>"},{"location":"task7/docker/","title":"Docker Installation and Setup for Task 7","text":""},{"location":"task7/docker/#overview","title":"Overview","text":"<p>This guide explains how to build and run the Docker container that provides a virtualized environment for Task 7 of the Scientific Computing for Physics Students project. The container is based on AlmaLinux9 and includes all required development tools and libraries (yaml-cpp, HDF5, GSL, etc.), as well as a Python environment managed by Miniconda.</p> <p>Prerequisites</p> <ul> <li>Docker must be installed.</li> <li>Follow the Docker installation instructions in Task\u00a01 before proceeding with Task\u00a07.</li> </ul>"},{"location":"task7/docker/#building-the-docker-image","title":"Building the Docker Image","text":"<p>The Dockerfile is located in the <code>docker/</code> directory and is named <code>Dockerfile.alma9</code>.</p> <ol> <li>Open a terminal and navigate to the project root.</li> <li> <p>Run the following command to build the Docker image:</p> <pre><code>docker build -t sci-comp-task7 -f docker/Dockerfile.alma9 .\n</code></pre> <ol> <li><code>-t sci-comp-task7</code> tags the image with the name <code>sci-comp-task7</code>.</li> <li><code>-f docker/Dockerfile.alma9</code> specifies the location of the Dockerfile.</li> <li>The final <code>.</code> sets the build context to the project root.</li> </ol> </li> </ol>"},{"location":"task7/docker/#running-the-docker-container","title":"Running the Docker Container","text":"<p>Once the image is built, you can start a container interactively with:</p> <pre><code>docker run -it -v \"$(pwd):/workspace\" sci-comp-task7\n</code></pre> <ul> <li><code>-it</code>: Runs the container in interactive mode with a TTY.</li> <li><code>-v \"$(pwd):/workspace\"</code>: Mounts the current project root into the container at /workspace.</li> <li><code>sci-comp-task7</code>: Specifies the image name.</li> </ul> <p>Inside the container, your working directory will be <code>/workspace</code> (which is your project root), and all necessary tools and libraries will be available.</p>"},{"location":"task7/intro/","title":"Introduction to Task 7","text":"<p>In Task\u00a07, we write and document a suite of unit tests for the DAXPY-inspired function <code>vector_sum</code></p> vector_sum.hpp<pre><code>void vector_sum(double a,\n                const std::vector&lt;double&gt;&amp; x,\n                const std::vector&lt;double&gt;&amp; y,\n                std::vector&lt;double&gt;&amp; d);\n</code></pre> <p>The goals of this task are:</p> <ol> <li>Verify basic functionality:  Ensure that vector_sum produces correct results for normal inputs.</li> <li>Test edge cases:  Confirm that the function handles empty vectors and throws an exception when input sizes mismatch.</li> </ol>"},{"location":"task7/intro/#testing-strategy","title":"Testing strategy","text":"<p>We use a simple <code>main</code>-based test driver (<code>test_vector_sum.cpp</code>) with assert statements to enforce expected behavior. Three categories of tests are included:</p>"},{"location":"task7/intro/#basic-functionality-tests","title":"Basic functionality tests","text":"<p>We check that for</p> test_vector_sum.cpp<pre><code>double a = 2.0;\nstd::vector&lt;double&gt; x{1.0, 2.0, 3.0};\nstd::vector&lt;double&gt; y{4.0, 5.0, 6.0};\nstd::vector&lt;double&gt; d;\nvector_sum(a, x, y, d);\n</code></pre> <p>the output vector d has size\u00a03 and values {6.0,\u00a09.0,\u00a012.0} via:</p> test_vector_sum.cpp<pre><code>assert(d.size() == x.size());\nassert(d[0] == 6.0);\nassert(d[1] == 9.0);\nassert(d[2] == 12.0);\n</code></pre>"},{"location":"task7/intro/#empty-vectors-tests","title":"Empty vectors tests","text":"<p>We verify that calling</p> test_vector_sum.cpp<pre><code>vector_sum(5.0, std::vector&lt;double&gt;{}, std::vector&lt;double&gt;{}, d);\n</code></pre> <p>leaves the result d empty:</p> test_vector_sum.cpp<pre><code>assert(d.empty());\n</code></pre>"},{"location":"task7/intro/#mismatched-sizes-tests","title":"Mismatched sizes tests","text":"<p>We ensure that passing vectors of unequal lengths throws an exception:</p> test_vector_sum.cpp<pre><code>std::vector&lt;double&gt; x{1.0};\nstd::vector&lt;double&gt; y{1.0, 2.0};\nbool thrown = false;\ntry {\n    vector_sum(1.0, x, y, d);\n} catch (const std::invalid_argument&amp;) {\n    thrown = true;\n}\nassert(thrown);\n</code></pre>"},{"location":"task7/intro/#what-you-will-find-in-this-repository","title":"What you will find in this repository","text":"<ul> <li> <p>Header Files (<code>include/</code>):     Provides declarations for the <code>vector_sum</code> function.</p> </li> <li> <p>Test Files (<code>test/</code>):     Contains unit tests for the <code>vector_sum</code> function.</p> </li> <li> <p>Helper Scripts (<code>scripts/</code>): </p> <ul> <li><code>buildProject.sh</code>: A script to build the project from scratch.</li> <li><code>destroyProject.sh</code>: A script to completely clean the project, removing build artifacts and installed commands.</li> </ul> </li> <li> <p>Docker Environment (<code>docker/</code>):     A Dockerfile (e.g., <code>Dockerfile.alma9</code>) is included to provide a ready-to-use development environment with all required dependencies.</p> </li> <li> <p>Run Script Template (<code>commands/run.in</code>):     This template is used to generate a wrapper script that is installed to <code>/usr/local/bin</code> for easy invocation of project executables.</p> </li> <li> <p><code>CMakeLists.txt</code>:     The CMake build configuration file for the project.</p> </li> </ul>"},{"location":"task7/intro/#project-structure","title":"Project Structure","text":"<p>The project directory structure is as follows:</p> <pre><code>project/                 # Project root directory\n\u2502 \n\u251c\u2500\u2500 commands/                # Contains the run script template\n\u2502   \u2514\u2500\u2500 run.in                    # Script to run executables with the correct environment\n\u251c\u2500\u2500 docker/                  # Docker build context\n\u2502   \u2514\u2500\u2500 Dockerfile.alma9          # Dockerfile for building the project\n\u251c\u2500\u2500 include/                 # Header files\n\u2502   \u251c\u2500\u2500 vector_sum.hpp            # Declaration of the vector_sum function\n\u251c\u2500\u2500 scripts/                 # Helper scripts\n\u2502   \u251c\u2500\u2500 buildProject.sh           # Script to build the project from scratch\n\u2502   \u2514\u2500\u2500 destroyProject.sh         # Script to completely clean the project\n\u251c\u2500\u2500 test/                    # Unit tests\n\u2502   \u251c\u2500\u2500 test_vector_sum.cpp       # Tests for the vector_sum function\n\u251c\u2500\u2500 CMakeLists.txt           # CMake build configuration file\n\u2514\u2500\u2500 README.md                # Project documentation  \n</code></pre>"},{"location":"task8/build/","title":"How to Build the Project","text":""},{"location":"task8/build/#step-by-step-instructions","title":"Step-by-Step Instructions","text":"<p>Assuming you already have the project available locally and your Docker container is running with <code>/workspace</code> set as the project root, follow these steps to build the project:</p> <ol> <li> <p>Navigate to the Project Root:</p> <p>Ensure you are in the project root directory (i.e., <code>/workspace</code>). You can verify this by running:</p> <pre><code>pwd\n</code></pre> <p>It should display <code>/workspace</code> (the project root).</p> </li> <li> <p>Run the Build Script:</p> <p>From the project root, execute the build script to configure and compile the project:</p> <pre><code>bash ./scripts/buildProject.sh\n</code></pre> <p>This script will:</p> <ul> <li>Create a build directory </li> <li>Change into the build directory.</li> <li>Run CMake to generate the build system.</li> <li>Invoke make to compile the source code into executables.</li> <li>Return you to the project root once the build is complete.</li> </ul> </li> <li> <p>Run the Executables:</p> <p>You can now run the executables using the <code>run</code> command from anywhere. For example:</p> <ul> <li> <p>Compare standard daxpy with chunked daxpy:</p> <pre><code>run test_vector_sum\n</code></pre> </li> </ul> </li> </ol>"},{"location":"task8/code_overview/","title":"Chunked Vector Summation","text":"<p>In Task\u00a08, we extend the basic DAXPY operation to process the input vectors in fixed\u2010size chunks. The key function is declared in <code>vector_sum_chunked.hpp</code> as:</p> vector_sum_chunked.hpp<pre><code>inline void vector_sum_chunked(double a,\n                               const std::vector&lt;double&gt;&amp; x,\n                               const std::vector&lt;double&gt;&amp; y,\n                               std::vector&lt;double&gt;&amp; d,\n                               std::size_t chunk_size,\n                               std::vector&lt;double&gt;&amp; partial_chunk_sum)\n</code></pre> <p>This function splits the work of computing </p> \\[ d_i = a \\cdot x_i + y_i \\] <p>into consecutive blocks of size <code>chunk_size</code>. Processing in chunks brings benefits in data locality and paves the way for parallel execution, at the cost of extra control logic and a secondary reduction step.</p>"},{"location":"task8/code_overview/#parameter-validation-and-setup","title":"Parameter validation and setup","text":"<p>The first steps ensure the inputs are well\u2010formed and prepare the outputs:</p> vector_sum_chunked.hpp<pre><code>if (x.size() != y.size()) {\n    throw std::invalid_argument(\"Vectors x and y must have the same size.\");\n}\nif (chunk_size == 0) {\n    throw std::invalid_argument(\"chunk_size must be at least 1.\");\n}\n\nauto n = x.size();\nd.resize(n);\n\n// Compute how many chunks are required (ceiling division)\nstd::size_t num_chunks = (n + chunk_size - 1) / chunk_size;\n// Initialize partial sums to zero\npartial_chunk_sum.assign(num_chunks, 0.0);\n</code></pre> <ul> <li>We throw <code>std::invalid_argument</code> on mismatched input sizes or zero chunk size.</li> <li>The output vector <code>d</code> is resized to match <code>x.size()</code>.</li> <li><code>num_chunks</code> is computed as <code>(n + chunk_size - 1) / chunk_size</code>, and <code>partial_chunk_sum</code> is initialized accordingly.</li> </ul>"},{"location":"task8/code_overview/#chunk-processing-loop","title":"Chunk processing loop","text":"<p>The core loop iterates over each chunk, computes the subarray update, and records the chunk\u2019s sum:</p> vector_sum_chunked.hpp<pre><code>for (std::size_t chunk = 0; chunk &lt; num_chunks; ++chunk) {\n    std::size_t start = chunk * chunk_size;\n    std::size_t end   = std::min(start + chunk_size, n);\n    double sum = 0.0;\n    for (std::size_t i = start; i &lt; end; ++i) {\n        d[i] = a * x[i] + y[i];\n        sum += d[i];\n    }\n    partial_chunk_sum[chunk] = sum;\n}\n</code></pre> <p>Within each chunk:</p> <ul> <li>We compute the starting index <code>start</code> and the ending index <code>end</code>, ensuring the last chunk may be shorter.</li> <li>We apply the DAXPY update to each element in <code>[start, end)</code> and accumulate these into <code>sum</code>.</li> <li>We store the partial sum for this chunk in <code>partial_chunk_sum</code>.</li> </ul>"},{"location":"task8/code_overview/#testing-the-chunked-vector-sum","title":"Testing the chunked vector sum","text":"<p>Unit tests in <code>test_vector_sum.cpp</code> validate the <code>vector_sum_chunked</code> function for various scenarios, ensuring correctness and robustness, often comparing it against a standard DAXPY implementation.</p>"},{"location":"task8/code_overview/#basic-comparison","title":"Basic comparison","text":"<p>Verifies that for a simple input, the chunked version matches the standard loop:</p> test_vector_sum.cpp<pre><code>double a = 1.5;\nstd::vector&lt;double&gt; x{0,1,2,3,4,5};\nstd::vector&lt;double&gt; y{6,7,8,9,10,11};\nstd::vector&lt;double&gt; d_ref, d_chk, partial;\n\nvector_sum(a, x, y, d_ref);\nvector_sum_chunked(a, x, y, d_chk, /*chunk_size=*/3, partial);\n\nassert(d_ref == d_chk);\n\ndouble sum_ref = std::accumulate(d_ref.begin(), d_ref.end(), 0.0);\ndouble sum_par = std::accumulate(partial.begin(), partial.end(), 0.0);\nassert(std::fabs(sum_ref - sum_par) &lt; 1e-12);\n</code></pre> <p>This test confirms both the element-wise results and the aggregated partial sums are consistent.</p>"},{"location":"task8/code_overview/#non-divisible-chunk-sizes","title":"Non-divisible chunk sizes","text":"<p>Ensures correct inexact chunking when <code>chunk_size</code> does not evenly divide the vector length:</p> test_vector_sum.cpp<pre><code>double a = 2.0;\nstd::vector&lt;double&gt; x{1,2,3,4,5};\nstd::vector&lt;double&gt; y{5,4,3,2,1};\nstd::vector&lt;double&gt; d_ref, d_chk, partial;\n\nvector_sum(a, x, y, d_ref);\nvector_sum_chunked(a, x, y, d_chk, /*chunk_size=*/2, partial);\n\nassert(d_ref == d_chk);\ndouble sum_ref = std::accumulate(d_ref.begin(), d_ref.end(), 0.0);\ndouble sum_par = std::accumulate(partial.begin(), partial.end(), 0.0);\nassert(std::fabs(sum_ref - sum_par) &lt; 1e-12);\nassert(partial.size() == 3);  // chunks of sizes 2,2,1\n</code></pre>"},{"location":"task8/code_overview/#chunk-size-larger-than-vector","title":"Chunk size larger than vector","text":"<p>Tests the edge case where <code>chunk_size</code> exceeds the vector length, ensuring it processes as a single chunk:</p> test_vector_sum.cpp<pre><code>double a = -1.0;\nstd::vector&lt;double&gt; x{1,2,3};\nstd::vector&lt;double&gt; y{3,2,1};\nstd::vector&lt;double&gt; d_ref, d_chk, partial;\n\nvector_sum(a, x, y, d_ref);\nvector_sum_chunked(a, x, y, d_chk, /*chunk_size=*/10, partial);\n\nassert(d_ref == d_chk);\ndouble sum_ref = std::accumulate(d_ref.begin(), d_ref.end(), 0.0);\ndouble sum_par = std::accumulate(partial.begin(), partial.end(), 0.0);\nassert(std::fabs(sum_ref - sum_par) &lt; 1e-12);\nassert(partial.size() == 1);\n</code></pre>"},{"location":"task8/code_overview/#mismatched-vector-sizes","title":"Mismatched vector sizes","text":"<p>Tests that the function correctly throws an exception when input vectors differ in size:</p> test_vector_sum.cpp<pre><code>bool caught = false;\nstd::vector&lt;double&gt; x{1}, y{1,2}, d, partial;\ntry {\n    vector_sum_chunked(1.0, x, y, d, /*chunk_size=*/2, partial);\n} catch (const std::invalid_argument&amp;) {\n    caught = true;\n}\nassert(caught);\n</code></pre>"},{"location":"task8/code_overview/#zero-chunk-size","title":"Zero chunk size","text":"<p>Tests that a zero <code>chunk_size</code> throws an exception:</p> test_vector_sum.cpp<pre><code>bool caught = false;\nstd::vector&lt;double&gt; x{1,2}, y{3,4}, d, partial;\ntry {\n    vector_sum_chunked(1.0, x, y, d, /*chunk_size=*/0, partial);\n} catch (const std::invalid_argument&amp;) {\n    caught = true;\n}\nassert(caught);\n</code></pre>"},{"location":"task8/docker/","title":"Docker Installation and Setup for Task 8","text":""},{"location":"task8/docker/#overview","title":"Overview","text":"<p>This guide explains how to build and run the Docker container that provides a virtualized environment for Task 8 of the Scientific Computing for Physics Students project. The container is based on AlmaLinux9 and includes all required development tools and libraries (yaml-cpp, HDF5, GSL, etc.), as well as a Python environment managed by Miniconda.</p> <p>Prerequisites</p> <ul> <li>Docker must be installed.</li> <li>Follow the Docker installation instructions in Task\u00a01 before proceeding with Task\u00a08.</li> </ul>"},{"location":"task8/docker/#building-the-docker-image","title":"Building the Docker Image","text":"<p>The Dockerfile is located in the <code>docker/</code> directory and is named <code>Dockerfile.alma9</code>.</p> <ol> <li>Open a terminal and navigate to the project root.</li> <li> <p>Run the following command to build the Docker image:</p> <pre><code>docker build -t sci-comp-task8 -f docker/Dockerfile.alma9 .\n</code></pre> <ol> <li><code>-t sci-comp-task8</code> tags the image with the name <code>sci-comp-task8</code>.</li> <li><code>-f docker/Dockerfile.alma9</code> specifies the location of the Dockerfile.</li> <li>The final <code>.</code> sets the build context to the project root.</li> </ol> </li> </ol>"},{"location":"task8/docker/#running-the-docker-container","title":"Running the Docker Container","text":"<p>Once the image is built, you can start a container interactively with:</p> <pre><code>docker run -it -v \"$(pwd):/workspace\" sci-comp-task8\n</code></pre> <ul> <li><code>-it</code>: Runs the container in interactive mode with a TTY.</li> <li><code>-v \"$(pwd):/workspace\"</code>: Mounts the current project root into the container at /workspace.</li> <li><code>sci-comp-task8</code>: Specifies the image name.</li> </ul> <p>Inside the container, your working directory will be <code>/workspace</code> (which is your project root), and all necessary tools and libraries will be available.</p>"},{"location":"task8/intro/","title":"Introduction to Task 8","text":"<p>In Task 8, we enhance the basic DAXPY-style vector summation by splitting the work into fixed\u2010size chunks. Instead of one loop over all n elements:</p> <pre><code>for i in 0..n-1:\n    d[i] = a*x[i] + y[i]\n</code></pre> <p>we process blocks of size <code>chunk_size</code>, computing each block separately, and then summing the per-block results. This approach offers:</p> <ol> <li>Improved locality: Operating on a small contiguous subarray at a time can boost cache\u2010reuse.</li> <li>Parallelism readiness: Independent chunks set the stage for simple multi\u2010threading (each chunk can be processed concurrently).</li> <li>Overhead: Calculating chunk boundaries and managing a secondary \u201cpartial sums\u201d array adds control\u2010flow complexity.</li> </ol>"},{"location":"task8/intro/#chunked-summation-logic","title":"Chunked summation logic","text":"<p>The function signature in <code>vector_sum_chunked.hpp</code> is:</p> vector_sum_chunked.hpp<pre><code>void vector_sum_chunked(double a,\n                        const std::vector&lt;double&gt;&amp; x,\n                        const std::vector&lt;double&gt;&amp; y,\n                        std::vector&lt;double&gt;&amp; d,\n                        std::size_t chunk_size,\n                        std::vector&lt;double&gt;&amp; partial_chunk_sum)\n</code></pre>"},{"location":"task8/intro/#key-steps","title":"Key steps","text":"<ol> <li> <p>Validate inputs: </p> vector_sum_chunked.hpp<pre><code>if (x.size() != y.size()) {\n    throw std::invalid_argument(\"Vectors x and y must have the same size.\");\n}\nif (chunk_size == 0) {\n    throw std::invalid_argument(\"chunk_size must be at least 1.\");\n}\n</code></pre> </li> <li> <p>Determine number of chunks:</p> vector_sum_chunked.hpp<pre><code>std::size_t n = x.size();\nd.resize(n);\n\n// Number of chunks = ceil(n / chunk_size)\nstd::size_t num_chunks = (n + chunk_size - 1) / chunk_size;\npartial_chunk_sum.assign(num_chunks, 0.0);\n</code></pre> </li> <li> <p>Process each chunk:</p> vector_sum_chunked.hpp<pre><code>for (std::size_t chunk = 0; chunk &lt; num_chunks; ++chunk) {\n    std::size_t start = chunk * chunk_size;\n    std::size_t end   = std::min(start + chunk_size, n);\n    double sum = 0.0;\n\n    for (std::size_t i = start; i &lt; end; ++i) {\n        d[i] = a * x[i] + y[i];\n        sum += d[i];\n    }\n    partial_chunk_sum[chunk] = sum;\n}\n</code></pre> </li> </ol>"},{"location":"task8/intro/#findings","title":"Findings","text":"<p>In tests (see <code>test_vector_sum.cpp</code>), the chunked and original implementations produce identical <code>d</code> vectors, and the sum of all elements matches the sum of <code>partial_chunk_sum</code> within floating\u2010point tolerance. When <code>n</code> is not divisible by chunk_size, the last chunk is smaller, and when<code>chunk_size \u2265 n</code>, only one chunk is processed. Error handling is confirmed for mismatched sizes and zero chunk size via exceptions.</p>"},{"location":"task8/intro/#what-you-will-find-in-this-repository","title":"What you will find in this repository","text":"<ul> <li> <p>Header Files (<code>include/</code>):     Provides declarations for the <code>vector_sum_chunked</code> function.</p> </li> <li> <p>Test Files (<code>test/</code>):     Contains unit tests for the <code>vector_sum_chunked</code> function.</p> </li> <li> <p>Helper Scripts (<code>scripts/</code>): </p> <ul> <li><code>buildProject.sh</code>: A script to build the project from scratch.</li> <li><code>destroyProject.sh</code>: A script to completely clean the project, removing build artifacts and installed commands.</li> </ul> </li> <li> <p>Docker Environment (<code>docker/</code>):     A Dockerfile (e.g., <code>Dockerfile.alma9</code>) is included to provide a ready-to-use development environment with all required dependencies.</p> </li> <li> <p>Run Script Template (<code>commands/run.in</code>):     This template is used to generate a wrapper script that is installed to <code>/usr/local/bin</code> for easy invocation of project executables.</p> </li> <li> <p><code>CMakeLists.txt</code>:     The CMake build configuration file for the project.</p> </li> </ul>"},{"location":"task8/intro/#project-structure","title":"Project Structure","text":"<p>The project directory structure is as follows:</p> <pre><code>project/                 # Project root directory\n\u2502 \n\u251c\u2500\u2500 commands/                # Contains the run script template\n\u2502   \u2514\u2500\u2500 run.in                    # Script to run executables with the correct environment\n\u251c\u2500\u2500 docker/                  # Docker build context\n\u2502   \u2514\u2500\u2500 Dockerfile.alma9          # Dockerfile for building the project\n\u251c\u2500\u2500 include/                 # Header files\n\u2502   \u251c\u2500\u2500 vector_sum.hpp            # Declaration of the vector_sum function\n\u2502   \u251c\u2500\u2500 vector_sum_chunked.hpp    # Declaration of the vector_sum_chunked function\n\u251c\u2500\u2500 scripts/                 # Helper scripts\n\u2502   \u251c\u2500\u2500 buildProject.sh           # Script to build the project from scratch\n\u2502   \u2514\u2500\u2500 destroyProject.sh         # Script to completely clean the project\n\u251c\u2500\u2500 test/                    # Unit tests\n\u2502   \u251c\u2500\u2500 test_vector_sum.cpp       # Tests for the vector_sum_chunked function\n\u251c\u2500\u2500 CMakeLists.txt           # CMake build configuration file\n\u2514\u2500\u2500 README.md                # Project documentation  \n</code></pre>"},{"location":"task9/build/","title":"How to Build the Project","text":""},{"location":"task9/build/#step-by-step-instructions","title":"Step-by-Step Instructions","text":"<p>Assuming you already have the project available locally and your Docker container is running with <code>/workspace</code> set as the project root, follow these steps to build the project:</p> <ol> <li> <p>Navigate to the Project Root:</p> <p>Ensure you are in the project root directory (i.e., <code>/workspace</code>). You can verify this by running:</p> <pre><code>pwd\n</code></pre> <p>It should display <code>/workspace</code> (the project root).</p> </li> <li> <p>Run the Build Script:</p> <p>From the project root, execute the build script to configure and compile the project:</p> <pre><code>bash ./scripts/buildProject.sh\n</code></pre> <p>This script will:</p> <ul> <li>Create a build directory </li> <li>Change into the build directory.</li> <li>Run CMake to generate the build system.</li> <li>Invoke make to compile the source code into executables.</li> <li>Return you to the project root once the build is complete.</li> </ul> </li> <li> <p>Run the Executables:</p> <p>You can now run the executables using the <code>run</code> command from anywhere. For example:</p> <ul> <li> <p>Compare the serial implementation with the OpenMP implementation:</p> <pre><code>run test_vector_sum_omp\n</code></pre> </li> <li> <p>Compare the serial implementation with the MPI implementation:</p> <pre><code>mpirun -np 4 run test_vector_sum_mpi\n</code></pre> </li> </ul> </li> </ol>"},{"location":"task9/code_overview/","title":"Parallel DAXPY with OpenMP and MPI","text":"<p>In Task 9, we parallelize the fundamental DAXPY operation</p> \\[ d_i = a \\cdot x_i + y_i \\] <p>across multiple CPU cores using two models: OpenMP for shared\u2010memory threading, and MPI for distributed\u2010memory processes. We provide three header\u2010only implementations, each with a matching test driver that measures performance and verifies correctness against the serial baseline.</p>"},{"location":"task9/code_overview/#serial-implementation","title":"Serial implementation","text":"<p>The baseline function lives in <code>vector_sum.hpp</code>:</p> vector_sum.hpp<pre><code>inline void vector_sum(double a, \n                       const std::vector&lt;double&gt;&amp; x, \n                       const std::vector&lt;double&gt;&amp; y, \n                       std::vector&lt;double&gt;&amp; d) \n{\n    if (x.size() != y.size()) {\n        throw std::invalid_argument(\"Vectors x and y must have the same size.\");\n    }\n    std::size_t n = x.size();\n    d.resize(n);\n\n    for (std::size_t i = 0; i &lt; n; ++i) {\n        d[i] = a * x[i] + y[i];\n    }\n}\n</code></pre>"},{"location":"task9/code_overview/#openmp-implementation","title":"OpenMP implementation","text":"<p>To leverage multi\u2010core CPUs, we insert an OpenMP pragma:</p> vector_sum_omp.hpp<pre><code>inline void vector_sum_omp(double a,\n                           const std::vector&lt;double&gt;&amp; x,\n                           const std::vector&lt;double&gt;&amp; y,\n                           std::vector&lt;double&gt;&amp; d)\n{\n    if (x.size() != y.size()) {\n        throw std::invalid_argument(\"Vectors x and y must have the same size.\");\n    }\n    std::size_t n = x.size();\n    d.resize(n);\n\n    #pragma omp parallel for                // parallelize the loop with OpenMP directive\n    for (std::size_t i = 0; i &lt; n; ++i) {\n        d[i] = a * x[i] + y[i];\n    }\n}\n</code></pre>"},{"location":"task9/code_overview/#mpi-implementation","title":"MPI implementation","text":"<p>For distributed\u2010memory parallelism, <code>vector_sum_mpi</code> broadcasts the input across MPI ranks and gathers the output:</p> vector_sum_mpi.hpp<pre><code>inline void vector_sum_mpi(double a,\n                           const std::vector&lt;double&gt;&amp; x,\n                           const std::vector&lt;double&gt;&amp; y,\n                           std::vector&lt;double&gt;&amp; d)\n{\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n    std::size_t n = x.size();\n    if (x.size() != y.size()) {\n        if (rank == 0) throw std::invalid_argument(\"Vectors x and y must have the same size.\");\n        else MPI_Abort(MPI_COMM_WORLD, 1);\n    }\n\n    // split n roughly evenly\n    std::size_t base = n / size; // base number of elements per rank\n    std::size_t rem  = n % size; // remainder to distribute\n    std::size_t start = rank * base + std::min&lt;std::size_t&gt;(rank, rem); // start index for this rank\n    std::size_t count = base + (static_cast&lt;std::size_t&gt;(rank) &lt; rem ? 1 : 0); // number of elements for this rank\n\n\n    // local piece\n    std::vector&lt;double&gt; local_d(count);\n    for (std::size_t i = 0; i &lt; count; ++i) {\n        local_d[i] = a * x[start + i] + y[start + i];\n    }\n\n    // prepare for gather\n    std::vector&lt;int&gt; counts(size), displs(size); // counts and displacements for gather\n    for (int r = 0; r &lt; size; ++r) {\n        counts[r] = (n / size) + (r &lt; (int)rem ? 1 : 0); // each rank gets base + 1 if it is in the first rem ranks\n        displs[r] = r * (n / size) + std::min(r, (int)rem); // displacement for each rank\n    }\n\n    if (rank == 0) d.resize(n);\n    MPI_Gatherv(local_d.data(), count, MPI_DOUBLE,\n                d.data(), counts.data(), displs.data(), MPI_DOUBLE,\n                0, MPI_COMM_WORLD);\n}\n</code></pre> <p>The MPI daxpy implementation relies first on the broadcast of the input vectors <code>x</code> and <code>y</code> from the root process (rank 0) to all other ranks, ensuring that each rank has access to the same data. This is perfomed by the test driver <code>test_vector_sum_mpi.cpp</code> using the MBI_Bcast function:</p> test_vector_sum_mpi.cpp<pre><code>MPI_Bcast(x.data(), n, MPI_DOUBLE, 0, MPI_COMM_WORLD);\nMPI_Bcast(y.data(), n, MPI_DOUBLE, 0, MPI_COMM_WORLD);\n</code></pre> <p>where <code>n</code> is the size of the vectors. After broadcasting, each rank computes its local piece of the result using the <code>vector_sum_mpi</code> function, which performs the DAXPY operation on its local copy of <code>x</code> and <code>y</code>. Finally, the results from all ranks are gathered back to the root process using <code>MPI_Gatherv</code>, which collects the local results into a single vector <code>d</code> on rank 0.</p>"},{"location":"task9/docker/","title":"Docker Installation and Setup for Task 9","text":""},{"location":"task9/docker/#overview","title":"Overview","text":"<p>This guide explains how to build and run the Docker container that provides a virtualized environment for Task 9 of the Scientific Computing for Physics Students project. The container is based on AlmaLinux9 and includes all required development tools and libraries (yaml-cpp, HDF5, GSL, etc.), as well as a Python environment managed by Miniconda.</p> <p>Prerequisites</p> <ul> <li>Docker must be installed.</li> <li>Follow the Docker installation instructions in Task\u00a01 before proceeding with Task\u00a09.</li> </ul>"},{"location":"task9/docker/#building-the-docker-image","title":"Building the Docker Image","text":"<p>The Dockerfile is located in the <code>docker/</code> directory and is named <code>Dockerfile.alma9</code>.</p> <ol> <li>Open a terminal and navigate to the project root.</li> <li> <p>Run the following command to build the Docker image:</p> <pre><code>docker build -t sci-comp-task9 -f docker/Dockerfile.alma9 .\n</code></pre> <ol> <li><code>-t sci-comp-task9</code> tags the image with the name <code>sci-comp-task9</code>.</li> <li><code>-f docker/Dockerfile.alma9</code> specifies the location of the Dockerfile.</li> <li>The final <code>.</code> sets the build context to the project root.</li> </ol> </li> </ol>"},{"location":"task9/docker/#running-the-docker-container","title":"Running the Docker Container","text":"<p>Once the image is built, you can start a container interactively with:</p> <pre><code>docker run -it -v \"$(pwd):/workspace\" sci-comp-task9\n</code></pre> <ul> <li><code>-it</code>: Runs the container in interactive mode with a TTY.</li> <li><code>-v \"$(pwd):/workspace\"</code>: Mounts the current project root into the container at /workspace.</li> <li><code>sci-comp-task9</code>: Specifies the image name.</li> </ul> <p>Inside the container, your working directory will be <code>/workspace</code> (which is your project root), and all necessary tools and libraries will be available.</p>"},{"location":"task9/intro/","title":"Introduction to Task 9","text":"<p>In Task 9, we parallelize the core DAXPY operation</p> \\[ d_i = a \\cdot x_i + y_i \\] <p>using two complementary CPU\u2010side models: OpenMP for shared\u2010memory threading and MPI for distributed\u2010memory message passing. We then measure and compare each parallel version\u2019s execution time against the baseline serial implementation.</p>"},{"location":"task9/intro/#openmp-vs-mpi","title":"OpenMP vs MPI","text":"Aspect OpenMP MPI Memory Model Shared\u2014threads access the same address space. Distributed\u2014each rank has a separate memory space. Parallelism Scope Loop\u2010level/task\u2010level within single node. Process\u2010level across nodes (or processes). Overhead Thread spawn/synchronization cost. Process launch and communication (e.g., broadcast) cost. Use Case Multi\u2010core scaling on one machine. Multi\u2010node scaling or when explicit data\u2010partitioning is desired."},{"location":"task9/intro/#implementation-highlights","title":"Implementation highlights","text":"<ul> <li> <p>OpenMP: In <code>vector_sum_omp.hpp</code>, the core loop is decorated with:</p> vector_sum_omp.hpp<pre><code>#pragma omp parallel for\nfor (std::size_t i = 0; i &lt; n; ++i) {\n    d[i] = a * x[i] + y[i];\n}\n</code></pre> <p>This simple directive forks threads to split the index range, and at the end of the loop, threads synchronize automatically. In <code>test_vector_sum_omp.cpp</code>, we time the serial and OpenMP runs back\u2010to\u2010back and confirm <code>d_ser == d_omp</code> before reporting:</p> test_vector_sum_omp.cpp<pre><code>auto t0 = std::chrono::high_resolution_clock::now();\nvector_sum(a, x, y, d_ser);\nauto t1 = std::chrono::high_resolution_clock::now();\nvector_sum_omp(a, x, y, d_omp);\nauto t2 = std::chrono::high_resolution_clock::now();\n\nassert(d_ser == d_omp);\n</code></pre> </li> <li> <p>MPI: The MPI implementation lives in <code>vector_sum_mpi.hpp</code>. The test driver <code>test_vector_sum_mpi.cpp</code> initializes MPI, then:</p> <ol> <li>Root process (rank 0) allocates and fills <code>x</code> and <code>y</code>.</li> <li> <p>Broadcast both vectors to all ranks:</p> test_vector_sum_mpi.cpp<pre><code>MPI_Bcast(x.data(), n, MPI_DOUBLE, 0, MPI_COMM_WORLD);\nMPI_Bcast(y.data(), n, MPI_DOUBLE, 0, MPI_COMM_WORLD);\n</code></pre> </li> <li> <p>Each rank calls <code>vector_sum_mpi(a, x, y, d_mpi)</code> on its local copy.</p> </li> <li> <p>Root measures serial vs. MPI time, asserts equality, and prints:</p> test_vector_sum_mpi.cpp<pre><code>auto t0 = std::chrono::high_resolution_clock::now();\nvector_sum(a, x, y, d_ser);\nauto t1 = std::chrono::high_resolution_clock::now();\nvector_sum_mpi(a, x, y, d_mpi);\nauto t2 = std::chrono::high_resolution_clock::now();\n\nassert(d_ser == d_mpi);\n</code></pre> </li> </ol> </li> </ul>"},{"location":"task9/intro/#what-you-will-find-in-this-repository","title":"What you will find in this repository","text":"<ul> <li> <p>Header Files (<code>include/</code>):     Provides declarations for the <code>vector_sum_omp</code> and <code>vector_sum_mpi</code> functions.</p> </li> <li> <p>Test Files (<code>test/</code>):     Contains unit tests for the <code>vector_sum_omp</code> and <code>vector_sum_mpi</code> functions.</p> </li> <li> <p>Helper Scripts (<code>scripts/</code>): </p> <ul> <li><code>buildProject.sh</code>: A script to build the project from scratch.</li> <li><code>destroyProject.sh</code>: A script to completely clean the project, removing build artifacts and installed commands.</li> </ul> </li> <li> <p>Docker Environment (<code>docker/</code>):     A Dockerfile (e.g., <code>Dockerfile.alma9</code>) is included to provide a ready-to-use development environment with all required dependencies.</p> </li> <li> <p>Run Script Template (<code>commands/run.in</code>):     This template is used to generate a wrapper script that is installed to <code>/usr/local/bin</code> for easy invocation of project executables.</p> </li> <li> <p><code>CMakeLists.txt</code>:     The CMake build configuration file for the project.</p> </li> </ul>"},{"location":"task9/intro/#project-structure","title":"Project Structure","text":"<p>The project directory structure is as follows:</p> <pre><code>project/                 # Project root directory\n\u2502 \n\u251c\u2500\u2500 commands/                # Contains the run script template\n\u2502   \u2514\u2500\u2500 run.in                    # Script to run executables with the correct environment\n\u251c\u2500\u2500 docker/                  # Docker build context\n\u2502   \u2514\u2500\u2500 Dockerfile.alma9          # Dockerfile for building the project\n\u251c\u2500\u2500 include/                 # Header files\n\u2502   \u251c\u2500\u2500 vector_sum_chunked.hpp    # Declaration of the vector_sum_chunked function\n\u2502   \u251c\u2500\u2500 vector_sum_mpi.hpp        # Declaration of the vector_sum_mpi function\n\u2502   \u251c\u2500\u2500 vector_sum_omp.hpp        # Declaration of the vector_sum_omp function\n\u2502   \u251c\u2500\u2500 vector_sum.hpp            # Declaration of the vector_sum function\n\u251c\u2500\u2500 scripts/                 # Helper scripts\n\u2502   \u251c\u2500\u2500 buildProject.sh           # Script to build the project from scratch\n\u2502   \u2514\u2500\u2500 destroyProject.sh         # Script to completely clean the project\n\u251c\u2500\u2500 test/                    # Unit tests\n\u2502   \u251c\u2500\u2500 test_vector_sum_mpi.cpp   # Tests for the vector_sum_mpi function\n\u2502   \u251c\u2500\u2500 test_vector_sum_omp.cpp   # Tests for the vector_sum_omp function\n\u2502   \u251c\u2500\u2500 test_vector_sum.cpp       # Tests for the vector_sum_chunked function\n\u251c\u2500\u2500 CMakeLists.txt           # CMake build configuration file\n\u2514\u2500\u2500 README.md                # Project documentation  \n</code></pre>"}]}